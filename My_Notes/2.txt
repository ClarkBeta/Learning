
在这个系列中，我们会学习 Bits(位)，Bytes(字节)，晶体管, 逻辑门，
一直到操作系统，虚拟现实和机器人!
我们要学很多东西，但预先说明
我们 *不会* 教你怎么编程
我们会从高层次上纵览一系列计算机话题
计算机是当今世界的命脉
如果突然关掉所有的计算机
电网会关闭，车辆会相撞，飞机会坠毁
净水厂会关闭，证券市场会停止运作
装满食物的卡车不知运往何方，员工得不到薪水
甚至很多和计算机无关的东西，例如 DFTBA 的 T 恤和我现在坐的椅子
也都是在计算机管理的工厂中制造的
计算机改变了我们生活中几乎所有方面
我们也不是第一次遇到推动全球发展的科技了
工业革命中生产能力的提高
大幅提升了农业，工业，畜牧业的规模
机械化导致更好的收成，更多的食物，商品可以大批量生产
旅行和通讯变得更便宜更快，生活质量变得更好.
计算机和工业革命有一样的影响
从自动化农业和医疗设备
到全球通信和教育机会
还有 虚拟现实 和 无人驾驶汽车 等新领域
现在这个时代很可能会被后人总结成 "信息时代"
你的智能手机中有数十亿个晶体管，看起来好像很复杂
但实际上它是很简单的机器
通过一层层的抽象  来做出复杂操作
在这个系列中，我们会一层层讲解，
从最底层的1和0，到逻辑门，CPU
操作系统，整个互联网，以及更多~~
不用担心，正如在网上买T恤的人 不用知道网站代码是怎么写的
设计师不用知道数据包是怎么传输的
设计路由器的工程师不用理解晶体管的逻辑
本系列中每个视频会接着上集继续讲，但并不依赖前面的视频
等这个系列结束后
希望你能了解计算机在你的人生 以及社会中扮演什么角色
以及这个人类史上最伟大的发明（可以这样说啦）是怎么开始的，
它对未来还会有更大的影响
但深入之前，我们应该从计算的起源讲起,
虽然电子计算机才出现不久，但人类对计算的需求早就有了
公认最早的计算设备是 算盘
发明于"美索不达米亚"，大约公元前 2500 年
它是手动计算器，用来帮助加减数字
它存储着当前的计算状态，类似于如今的硬盘
人们制造算盘是因为
社会的规模已经超出个人心算的能力
一个村庄可能有上千个人和上万头牛
算盘有很多变种
但我们来看一个基础版，每行代表 10 的不同次方
最底下那行，一个珠子代表 10 的 0 次方，也就是 1，
再上面一行是 10 的 1 次方（也就是 10） \N 再上面一行是 10 的 2 次方 （以此类推）
假设最底部的 3 颗珠子，代表 3 头牛
假设再买 4 头牛，只需要向右移动 4 颗珠子，共 7 个珠子
但如果再买 5 头，珠子就不够用了
所以把所有珠子移回左边
在第二排把 1 颗珠子向右移动，代表 10
然后最底下那行，向右移动 2 颗珠子，代表 12
这种方法处理大数字很有效
假设要表示 1251
从下往上：\N第一行移 1 个，第二行移 5 个\N第三行移 2 个，第四行移 1 个
我们不用记在脑子里，算盘会记住.
在接下来 4000 年，人类发明了各种巧妙的计算设备
比如星盘，让船只可以在海上计算纬度
或计算尺，帮助计算乘法和除法
人们还创造了上百种时钟
算日出，潮汐，天体的位置，或纯粹拿来计时
这些设备让原先很费力的事变得更快，更简单，更精确
降低了门槛
加强了我们的能力
记笔记!（敲黑板）这个系列会多次提到这一点
计算机先驱 Charles Babbage 说过：
"随着知识的增长和新工具的诞生，人工劳力会越来越少"
然而，这些设备那时都不叫 "计算机"
最早使用 "计算机" 一词的文献 \N 来自 1613 年的一本书，作者 Richard Braithwait
然而指的不是机器，而是一种职业
Braithwait 说：
"我听说过的计算者里最厉害的，能把好几天的工作量大大缩减"
那时, "Computer" 指负责计算的人
"Computer" 偶尔会用机器帮忙，但大部分时候靠自己
这个职位一直到 1800 年代还存在
之后 "Computer" 逐渐开始代表机器
其中"步进计算器"最有名
由德国博学家 戈特弗里德·莱布尼茨 建造于 1694 年
莱布尼茨说过 "... 让优秀的人浪费时间算数简直侮辱尊严
农民用机器能算得一样准"
"步进计算器"有点像汽车里的里程表，不断累加里程数
它有一连串可以转动的齿轮
每个齿轮有十个齿，代表数字0到9
每当一个齿轮转过 9，它会转回 0，同时让旁边的齿轮前进 1 个齿
就像算盘超过 10 一样.
做减法时，机器会反向运作.
利用一些巧妙的机械结构
步进计算器也能做乘法和除法
乘法和除法 实际上只是多个加法和减法
举例，17除以5，我们只要减5，减5，再减5
直到不能再减 5，就知道了 17=5x3+2
步进计算器 可以自动完成这种操作
它是第一台能做"加减乘除"全部四种运算的机器
它的设计非常成功，以至于沿用了 3 个世纪.
不幸的是，即使有机械计算器
许多现实问题 依然需要很多步
算一个结果可能要几小时甚至几天
而且这些手工制作的机器非常昂贵，大部分人买不起
所以在 20 世纪以前
大部分人会用预先算好的计算表
这些计算表由之前说的 "人力计算器" 编撰
如果你想知道 867,5309 的平方根
与其花一整天来手摇 "步进计算器"
你可以花一分钟在表里找答案
速度和准确性在战场上尤为重要
因此军队很早就开始用计算解决复杂问题
如何精确瞄准炮弹是一个很难的问题
19世纪，这些炮弹的射程可以达到 1 公里以上（比半英里多一点）
因为风力，温度，大气压力会不断变化
想打中船一样大的物体也非常困难
于是出现了射程表，炮手可以查环境条件和射击距离
然后这张表会告诉他们，角度要设成多少
这些射程表很管用，二战中被广泛应用
问题是如果改了大炮或炮弹的设计，就要算一张新表
这样很耗时而且会出错
Charles Babbage 在 1822 年写了一篇论文
向皇家天文学会指出了这个问题
标题叫： "机械在天文与计算表中的应用"
让我们进入思想泡泡
Charles Babbage 提出了一种新型机械装置叫 "差分机"
一个更复杂的机器，能近似多项式.
多项式描述了几个变量之间的关系
多项式也可以用于近似对数和三角函数
这些函数手算相当麻烦
Charles Babbage 在 1823 年开始建造差分机
并在接下来二十年，试图制造和组装 25,000 个零件
总重接近 15 吨
不幸的是，该项目最终放弃了
但在 1991 年
历史学家根据 Charles Babbage 的草稿做了一个差分机
而且它还管用！
但更重要的是，在差分机的建造期间
Charles Babbage 构想了一个更复杂的机器 - 分析机
不像差分机，步进计算器 和以前的其他计算设备
分析机是 "通用计算机"
它可以做很多事情，不只是一种特定运算
甚至可以给它数据，然后按顺序执行一系列操作
它有内存 甚至一个很原始的打印机
就像差分机，这台机器太超前了，所以没有建成
然而，这种 "自动计算机" 的概念
-计算机可以自动完成一系列操作
是个跨时代的概念，预示着计算机程序的诞生
英国数学家 Ada Lovelace 给分析机写了假想的程序，她说：
"未来会诞生一门全新的，强大的，专为分析所用的语言"
因此 Ada 被认为是世上第一位程序员.
分析机激励了（可以这么讲）第一代计算机科学家
这些计算机科学家 \N 把很多 Charles Babbage 的点子融入到他们的机器
所以 Charles Babbage 经常被认为是 "计算之父"
谢啦！思想泡泡
到了 19 世纪末
科学和工程领域中的特定任务 会用上计算设备
但公司，政府，家庭中很少见到计算设备
然而，美国政府在 1890 年的人口普查中面临着严重的问题
只有计算机能提供所需的效率
美国宪法要求 10 年进行一次人口普查
目的是分配联邦资金，国会代表，等等
到 1880 年代，美国人口迅速增长，大部分因为移民
人口普查要七年时间来手工编制，等做完都过时了
而且 1890 年的人口普查，预计要 13 年完成
但人口普查可是 10 年一次啊！
人口普查局找了 Herman Hollerith，他发明了打孔卡片制表机
他的机器是 "电动机械的"
- 用传统机械来计数
结构类似莱布尼茨的乘法器，但用电动结构连接其他组件
Hollerith 的机器用打孔卡
一种纸卡，上面有网格，用打孔来表示数据.
举个例子，有一连串孔代表婚姻状况
如果你结婚了，就在 "结婚" 的位置打孔
当卡插入 Hollerith 的机器时，小金属针会到卡片上
-如果有个地方打孔了，针会穿过孔
泡入一小瓶汞，联通电路
电路会驱动电机
然后给 "已婚" 的齿轮 + 1
Hollerith 的机器速度是手动的 10 倍左右
使人口普查在短短两年半内完成
给人口普查办公室省了上百万美元
企业开始意识到计算机的价值
可以提升劳动力以及数据密集型任务 来提升利润
比如会计，保险评估和库存管理等行业
为了满足这一需求，Hollerith 成立了制表机器公司
这家公司后来在 1924 年与其它机械制造商合并
成为了 "国际商业机器公司"，简称 IBM
-你可能听过 IBM
这些电子机械的 "商业机器" 取得了巨大成功，改变了商业和政府.
到了 1900 年代中叶，世界人口的爆炸和全球贸易的兴起
要求更快，更灵活的工具来处理数据
为电子计算机的发展奠定了基础
我们下周讨论
上集讲到 20 世纪初
当时的早期计算设备都针对特定用途  比如 制表机
大大推进了政府和企业
它们帮助, 甚至代替了人工
然而人类社会的规模  在以前所未有的速度增长
20世纪上半叶，世界人口几乎翻倍
一战动员7千万人，二战1亿多人
全球贸易和运输更加紧密
工程和科学的复杂度也达到新高
- 我们甚至开始考虑造访其他行星
复杂度的增高导致数据量暴增
人们需要更多自动化 更强的计算能力
很快，柜子大小的计算机变成房间大小
维护费用高 而且容易出错
而正是这些机器 为未来的创新打下基础
最大的机电计算机之一是 哈佛马克一号
IBM 在 1944 完成建造，给二战同盟国建造的.
它有76万5千个组件，300万个连接点和500英里长的导线
为了保持内部机械装置同步
它有一个50英尺的传动轴，由一个 5 马力的电机驱动
这台机器最早的用途之一 是给"曼哈顿计划"跑模拟
这台机器的大脑是"继电器"
继电器是：用电控制的机械开关
继电器里，有根"控制线路"，控制电路是开还是关
"控制线路" 连着一个线圈
当电流流过线圈，线圈产生电磁场
吸引金属臂，从而闭合电路
你可以把继电器 想成水龙头
把控制线路 想成水龙头把
打开水龙头，水会流出来
关闭水龙头，水就没有了
继电器是一样的，只不过控制的是电子  而不是水
这个控制电路可以连到其他电路，比如马达
马达让计数齿轮 +1
就像上集中 Hollerith 的制表机一样
不幸的是，继电器内的机械臂 *有质量*
因此无法快速开关
1940 年代一个好的继电器 1 秒能翻转 50 次
看起来好像很快，但还不够快，不足以解决复杂的大问题
哈佛马克一号，1 秒能做 3 次加法或减法运算
一次乘法要花 6 秒，除法要花 15 秒
更复杂的操作 比如三角函数，可能要一分钟以上
除了速度慢，另一个限制是齿轮磨损
任何会动的机械都会随时间磨损
有些部件会完全损坏，有些则是变黏，变慢，变得不可靠
并且随着继电器数量增加，故障概率也会增加
哈佛马克一号 有大约 3500 个继电器
哪怕假设继电器的使用寿命是 10 年
也意味着平均每天得换一个故障继电器！
这个问题很严重，因为有些重要运算要运行好几天
而且还有更多其他问题要考虑
这些巨大，黑色，温暖的机器也会吸引昆虫
1947年9月，哈佛马克2型的操作员从故障继电器中，拔出一只死虫
Grace Hopper（这位我们以后还会提到）曾说
"从那时起，每当电脑出了问题，
我们就说它出了 bug（虫子）"
这就是术语 "bug" 的来源
显然，如果想进一步提高计算能力
我们需要更快更可靠的东西，来替代继电器
幸运的是，替代品已经存在了！
在 1904 年，英国物理学家 "约翰·安布罗斯·弗莱明"
开发了一种新的电子组件，叫"热电子管"
把两个电极装在一个气密的玻璃灯泡里
-这是世上第一个真空管
其中一个电极可以加热，从而发射电子
-这叫 "热电子发射"
另一个电极会吸引电子，形成"电龙头"的电流
但只有带正电才行
- 如果带负电荷或中性电荷，电子就没办法被吸引，越过真空区域
因此没有电流
电流只能单向流动的电子部件叫 "二极管"
但我们需要的是，一个能开关电流的东西
幸运的是，不久之后在 1906 年，美国发明家 "李·德富雷斯特"
他在"弗莱明"设计的两个电极之间，加入了第三个 "控制" 电极
向"控制"电极施加正电荷，它会允许电子流动
但如果施加负电荷
它会阻止电子流动
因此通过控制线路，可以断开或闭合电路
和继电器的功能一样
- 但重要的是，真空管内没有会动的组件
这意味着更少的磨损
更重要的是，每秒可以开闭数千次
因此这些"三极真空管"成为了无线电，长途电话
以及其他电子设备的基础，持续了接近半个世纪
我应该提到，真空管不是完美的
-它们有点脆弱，并且像灯泡一样会烧坏
但比起机械继电器是一次巨大进步
起初，真空管非常昂贵
收音机一般只用一个
但计算机可能要上百甚至上千个电气开关
但到了 1940 年代
它的成本和可靠性得到改进，可以用在计算机里
至少有钱人负担得起，比如政府
这标志着计算机 从机电转向电子
我们来进入思想泡泡
第一个大规模使用真空管的计算机是 "巨人1号"
由工程师 Tommy Flowers 设计，完工于1943年12月
巨人1号 在英国的"布莱切利园", 用于破解纳粹通信
听起来可能有点熟，因为 2 年前 阿兰·图灵
他经常被称为"计算机科学之父"
图灵也在"布莱切利园"做了台机电装置，叫 "Bombe"
这台机器的设计目的是  破解纳粹"英格码"通讯加密设备
但 Bombe 严格来说不算计算机
我们之后会讨论"阿兰·图灵"的贡献
总之，巨人1号有 1600 个真空管
总共造了 10 台巨人计算机，来帮助破解密码
巨人 被认为是第一个可编程的电子计算机
编程的方法是把几百根电线插入插板
有点像老电话交换机
这是为了让计算机执行正确操作
虽然"可编程" ，但还是要配置它
电子数值积分计算机 "ENIAC"
几年后在 1946 年，在"宾夕法尼亚大学"完成建造
设计者是 John Mauchly 和 J. Presper Eckert
这是世上第一个真正的通用，可编程，电子计算机
ENIAC 每秒可执行 5000 次十位数加减法
比前辈快了很多倍
它运作了十年
据估计，它完成的运算，比全人类加起来还多
因为真空管很多，所以故障很常见
ENIAC 运行半天左右就会出一次故障
谢了 思想泡泡
到 1950 年代，真空管计算机都达到了极限
美国空军的 AN/FSQ-7 计算机于 1955 年完成
是 "SAGE" 防空计算机系统的一部分
之后的视频还会提到.
为了降低成本和大小，同时提高可靠性和速度
我们需要一种新的电子开关
1947 年，贝尔实验室科学家 \N John Bardeen，Walter Brattain，William Shockley
发明了晶体管
一个全新的计算机时代诞生了！
晶体管的物理学相当复杂，牵扯到量子力学
所以我们只讲基础
晶体管 就像之前提过的"继电器"或"真空管"
-它是一个开关，可以用控制线路来控制开或关
晶体管有两个电极，\N 电极之间有一种材料隔开它们，这种材料有时候导电
有时候不导电
- 这叫"半导体"
控制线连到一个 "门" 电极
通过改变 "门" 的电荷
我们可以控制半导体材料的导电性
来允许或不允许 电流流动
- 就像之前的水龙头比喻
贝尔实验室的第一个晶体管就展示了巨大的潜力
每秒可以开关 10,000 次
而且，比起玻璃制成，小心易碎的真空管
晶体管是固态的
晶体管可以远远小于继电器或真空管
导致更小更便宜的计算机，比如1957年发布的IBM 608
- 第一个完全用晶体管，而且消费者也可以买到的计算机
它有 3000 个晶体管，每秒执行 4500 次加法
每秒能执行 80 次左右的乘除法
IBM 很快把所有产品都转向了晶体管
把晶体管计算机带入办公室，最终引入家庭
如今，计算机里的晶体管小于 50 纳米
- 而一张纸的厚度大概是 10 万纳米
晶体管不仅小，还超级快
- 每秒可以切换上百万次，并且能工作几十年
很多晶体管和半导体的开发在"圣克拉拉谷"
这个地方在加州，位于"旧金山"和"圣荷西"之间
而生产半导体最常见的材料是 "硅"
所以这个地区被称为 "硅谷"
甚至 William Shockley 都搬了过去，创立了"肖克利半导体"
里面的员工后来成立了"仙童半导体"
这里面的员工后来创立了英特尔 - 当今世界上最大的计算机芯片制造商
好了，我们从"继电器"到"真空管"到"晶体管"
我们可以让电路开闭得非常非常快
但我们是如何用晶体管做计算的？
我们没有马达和齿轮啊？
我们接下来几集会讲
感谢观看 下周见

今天我们开始"抽象"的旅程
不用管底层细节，把精力用来构建更复杂的系统
上集，我们谈了计算机最早是机电设备
一般用十进制计数
- 比如用齿轮数来代表十进制
- 再到晶体管计算机
幸运的是，只用 开/关 两种状态也可以代表信息
这叫 二进制
- 意思是"用两种状态表示"
就像自行车有两个轮，双足动物有两条腿
你可能觉得两种状态不多，你是对的！
但如果只需要表示 true 和 false，两个值就够了
电路闭合，电流流过，代表 "真"
电路断开，无电流流过，代表"假"
二进制也可以写成 1 和 0 而不是 true 和 false
- 只是不同的表达方式罢了
- 我们下集会讲更多细节
晶体管的确可以不只是 开/关，还可以让不同大小的电流通过
一些早期电子计算机是三进制的，有 3 种状态
甚至五进制，5 种状态
问题是，状态越多，越难区分信号
- 如果手机快没电了或者附近有电噪音
因为有人在用微波炉，
信号可能会混在一起...
而每秒百万次变化的晶体管会让这个问题变得更糟！
所以我们把两种信号尽可能分开
- 只用"开"和"关"两种状态，可以尽可能减少这类问题
计算机用二进制的另一个原因是
有一整个数学分支存在，专门处理"真"和"假"
它已经解决了所有法则和运算
叫"布尔代数"！
乔治·布尔（George Boole）是布尔二字的由来
是一位 19 世纪自学成才的英国数学家
他有兴趣用数学式子 扩展亚里士多德基于哲学的逻辑方法
布尔用 逻辑方程 系统而正式的证明真理(truth)
他在 1847 年的第一本书"逻辑的数学分析"中介绍过
在"常规"代数里 - 你在高中学的那种 - 变量的值
是数字，可以进行加法或乘法之类的操作
但在布尔代数中，变量的值是 true 和 false，\N 能进行逻辑操作
布尔代数中有三个基本操作：NOT, AND 和 OR
这些操作非常有用，我们一个个来看
NOT 操作把布尔值反转，\N把 true 进行 NOT 就会变成 false，反之亦然
我们可以根据 NOT 操作的输入和输出，做出这个表
酷的地方是 - 用晶体管可以轻松实现这个逻辑
上集说过，晶体管只是电控制的开关
有 3 根线：2 根电极和 1 根控制线
控制线通电时
电流就可以从一个电极流到另一个电极
就像水龙头一样
- 打开水龙头，就有水流出来
关掉水龙头，就没水了
可以把控制线，当做输入 ( input ) \N 底部的电极，当做输出（output）
所以 1 个晶体管，有一个输入和一个输出
如果我们打开输入（input on) \N 输出也会打开（output on） \N 因为电流可以流过
如果关闭输入（input off） \N 输出也会关闭（output off）\N 因为电流无法通过
或者用布尔术语来说\N 输入为 真，输出为 真
输入为 假 \N 输出为 假
我们也可以把这个做成"真值表"
这个电路没什么意思，因为它没做什么事
- 输入和输出是一样的
但我们可以稍加修改，实现 NOT
与其把下面那根线当做 输出，我们可以把 输出 放到上面
如果打开 输入，电流可以流过然后 "接地"
输出就没有电流，所以输出是 off
如果用水来举例
就像家里的水都从一个大管子流走了
打开淋浴头一点水也没有
如果输入是 on，输出是 off
当输入是 off，电流没法接地，就流过了输出，所以输出是 on
如果输入是 off，输出是 on
和 NOT 操作表一样！太棒了！我们做了个有点用的电路！
我们叫它 "NOT 门" \N 之所以叫 "门"，是因为它能控制电流的路径
"AND"操作有 2 个输入，1 个输出
如果 2 个输入都是 true，输出才是 true
你可以想成是 说真话
如果完全不说谎，才是诚实
举例，看如下这个句子
2 个都是真的，所以整个是真的
因为我没穿裤子
或长裤，如果你是英国人你会用这个词……（英/美单词不同梗）
虽然前半句是真的，但是 真 "AND" 假，还是假
就算把前后顺序反过来，也依然是 假
如果我说 2 个假的事情，那么结果是假。
和上次一样，可以给"AND"做个表
为了实现 "AND 门"，我们需要 2 个晶体管连在一起
这样有 2 个输入和 1 个输出
如果只打开 A，不打开 B \N 电流无法流到 output，所以输出是 false
如果只打开 B，不打开 A ，也一样，电流无法流到 output
只有 A 和 B 都打开了，output 才有电流
最后一个是 OR （前面讲了 NOT 和 AND)
只要 2 个输入里，其中 1 个是 true，输出就是 true
比如，我叫 Margaret Hamilton"或"我穿着蓝色衣服
结果是 true，虽然我不是 Margaret Hamilton
但是我穿着蓝色衣服，所以结果是 true
对于"OR 操作"来说，\N如果 2 个 输入都是 true，输出也是 true
只有 2 个输入都是 false，OR 的结果才是 false
实现 "OR 门" 除了晶体管还要额外的线
不是串联起来。而是并联
然后左边这条线有电流输入
我们用"小拱门"代表 2 条线没连在一起，只是跨过而已
虽然看起来像连在一起
如果 A 和 B 都是 off，电流无法流过
所以输出是 off
如果打开 A，电流可以流过。输出是 on
如果只打开 B 也一样
只要 A OR B 是 on， 输出就是 on
如果 A 和 B 都 on，结果是 on
好，现在 NOT 门, AND 门, OR 门 都搞定了
我们可以进行一次抽象
NOT 门的画法是三角形前面一个圆点
AND 门用 D 表示 ，OR 门用太空船表示
"D 形状和太空船"不是标准叫法, 只是我喜欢这样叫而已
我们可以用这种方法表示它们，构建更大的组件
就不会变得很复杂
- 晶体管和电线依然在那里，我们只是用符号来代表而已
除了前面说的三个\N 另一个有用的布尔操作叫 "异或"
- 简称 XOR
XOR 就像普通 OR，但有一个区别：
如果 2 个输入都是 true，XOR 输出 false
想要 XOR 输出 true \N 一个输入必须是 true，另一个必须是 false
就像你出去吃晚饭，你点的饭要么配沙拉，要么配汤
- 你不能两个都要！
用晶体管实现 XOR 门有点烧脑子
但我可以展示一下\N 怎么用前面提到的 3 种门来做 XOR 门
我们有 2 个输入，A 和 B ，还有 1 个输出.
我们先放一个 OR 门. 因为 OR 和 XOR 的逻辑表很像
只有 1 个问题 - 当 A 和 B 都是 true 时 \N OR 的输出和想要的 XOR 输出不一样
我们想要 false
XOR 超有用的
我们下次再说它
因为超有用，\N 工程师给了它一个符号，一个 OR 门 + 一个笑脸
重要的是，现在可以把 XOR 放入"工具箱"了
不用担心 XOR 具体用了几个门
这几个门又是怎么用晶体管拼的
或电子是怎么流过半导体的
再次向上抽象
工程师设计处理器时，很少在晶体管的层面上思考，
而是用更大的组件，比如逻辑门，或者由逻辑门组成的更大组件，
我们以后会讲
就算是专业程序员
也不用考虑逻辑是怎样在物理层面实现的
我们从电信号开始，到现在第一次表示数据
- 真和假 - 开始有点"计算"的感觉了
仅用这集讲的 逻辑门
我们可以判断复杂的语句 比如：
[如果是 John Green] AND [下午 5 点后] \N OR [周末] AND [在比萨店附近]
那么 "John 想要比萨" = 真
我都说饿了，下周见

今天，我们讲计算机如何存储和表示数字
所以会有一些数学
不过别担心
你们的数学水平绝对够用了
上集我们讲了，怎么用晶体管做逻辑门
逻辑门可以判断布尔语句
布尔代数只有两个值：True 和 False
但如果只有两个值，我们怎么表达更多东西？
这就需要数学了
上集提到，1 个二进制值可以代表 1 个数
我们可以把真和假 ，当做 1 和 0
如果想表示更多东西，加位数就行了
和我们熟悉的十进制一样
十进制只有 10 个数（0到9）
要表示大于 9 的数，加位数就行了
二进制也可以这样玩
拿 263 举例
这个数字 "实际" 代表什么？
2 个 100 \N6 个 10 \N 3 个 1
加在一起，就是 263
注意每列有不同的乘数
每个乘数都比右边大十倍
因为每列有 10 个可能的数字（0到9）
如果超过 9，要在下一列进 1.
因此叫 "基于十的表示法"  或十进制
二进制也一样，只不过是基于 2 而已
因为二进制只有两个可能的数， 1 和 0
意味着每个乘数必须是右侧乘数的两倍
就不是之前的 100, 10, 1 \N 而是 4, 2, 1
拿二进制数 101 举例
意味着有\N 1个 "4"  \N 0个 "2"  \N 1个 "1"
加在一起，得到十进制的 5
为了表示更大的数字，二进制需要更多位数
拿二进制数 10110111 举例
我们可以用相同的方法转成十进制
加起来等于 183
二进制数的计算也不难
以十进制数 183 加 19 举例
首先 3 + 9，得到 12，然后位数记作 2，向前进 1
现在算 8+1+1=10，所以位数记作0，再向前进 1
最后 1+1=2，位数记作2
所以和是202
二进制也一样
和之前一样，从个位开始
1+1=2，在二进制中也是如此
但二进制中没有 2，所以位数记作 0 ，进 1
就像十进制的例子一样
1+1，再加上进位的1
等于 3，用二进制表示是 11
所以位数记作 1，再进 1，以此类推
最后得到这个数字，跟十进制 202 是一样的
二进制中，一个 1 或 0  叫一"位"
上个例子我们用了 8 位 , 8 位能表示的最小数是 0,  8位都是0
最大数是 255，8 位都是 1
能表示 256 个不同的值，2 的 8 次方
你可能听过 8 位机，8 位图像，8 位音乐
意思是计算机里\N 大部分操作都是 8 位 8 位这样处理的
但 256 个值不算多，意味着 8位游戏只能用 256 种颜色
8 位是如此常见，以至于有专门的名字：字节
1 字节 = 8 位 \N 1 bytes = 8 bits
如果有 10 个字节，意味着有 80 位
你听过 千字节（KB）兆字节（MB）千兆字节（GB）等等
不同前缀代表不同数量级
就像 1 千克 = 1000 克，1 千字节 = 1000 字节
或 8000 位
Mega 是百万字节（MB）, Giga 是十亿字节（GB）
如今你可能有 1 TB 的硬盘
8 万亿个1和0
等等，我们有另一种计算方法
二进制里，1 千字节 = 2的10次方 = 1024 字节
1000 也是千字节（KB）的正确单位
1000 和 1024 都对
你可能听过 32 位 或 64 位计算机
你现在用的电脑几乎肯定是其中一种
意思是一块块处理数据，每块是 32 位或 64 位
这可是很多位
32 位能表示的最大数，是 43 亿左右
也就是 32 个 1
所以 Instagram 照片很清晰
- 它们有上百万种颜色
因为如今都用 32 位颜色
当然，不是所有数都是正数
比如我上大学时的银行账户 T_T
我们需要有方法表示正数和负数
大部分计算机用第一位表示正负：
1 是负，0 是正
用剩下 31 位来表示符号外的数值
能表示的数的范围大约是正 20 亿到负 20 亿
虽然是很大的数，但许多情况下还不够用
全球有 70 亿人口，美国国债近 20 万亿美元
所以 64 位数很有用
64 位能表达最大数大约是 9.2×10 ^ 18
希望美国国债在一段时间内不会超过这个数！
重要的是（我们之后的视频会深入讲）
计算机必须给内存中每一个位置，做一个 "标记"
这个标记叫 "地址", 目的是为了方便存取数据
如今硬盘已经增长到 GB 和 TB，上万亿个字节！
内存地址也应该有 64 位
除了负数和正数，计算机也要处理非整数
比如 12.7 和 3.14，或"星历 43989.1"
这叫 浮点数
因为小数点可以在数字间浮动
有好几种方法 表示浮点数
最常见的是 IEEE 754 标准
你以为只有历史学家取名很烂吗？
它用类似科学计数法的方法，来存十进制值
例如，625.9 可以写成 0.6259×10 ^ 3
这里有两个重要的数：.6259 叫 "有效位数" , 3 是指数
在 32 位浮点数中
第 1 位表示数的符号——正或负
接下来 8 位存指数
剩下 23 位存有效位数
好了，聊够数了，但你的名字是字母组成的
所以我们也要表示文字
与其用特殊方式来表示字母 \N 计算机可以用数表示字母
最直接的方法是给字母编号：
A是1，B是2，C是3，以此类推
著名英国作家 弗朗西斯·培根（Francis Bacon）
曾用 5位序列 来编码英文的 26 个字母
在十六世纪传递机密信件
五位（bit）可以存 32 个可能值（2^5） - 这对26个字母够了
但不能表示 标点符号，数字和大小写字母
ASCII，美国信息交换标准代码
发明于 1963 年，ASCII 是 7 位代码，足够存 128 个不同值
范围扩大之后，可以表示大写字母，小写字母,
数字 0 到 9, @ 这样的符号, 以及标点符号
举例，小写字母 a 用数字 97 表示，大写字母 A 是 65
: 是58  \n ) 是41
ASCII 甚至有特殊命令符号
比如换行符，用来告诉计算机换行
在老计算机系统中
如果没换行符，文字会超出屏幕
因为 ASCII 是个很早的标准
所以它被广泛使用
让不同公司制作的计算机，能互相交换数据
这种通用交换信息的能力叫 "互操作性"
但有个限制：它是为英语设计的
幸运的是，一个字节有8位，而不是7位
128 到 255 的字符渐渐变得常用
这些字符以前是空的，是给各个国家自己  "保留使用的"
在美国，这些额外的数字主要用于编码附加符号
比如数学符号，图形元素和常用的重音字符
另一方面，虽然拉丁字符被普遍使用
在俄罗斯，他们用这些额外的字符表示西里尔字符
而希腊电脑用希腊字母，等等
这些保留下来给每个国家自己安排的空位，\N 对大部分国家都够用
问题是
如果在 土耳其 电脑上打开 拉脱维亚语 写的电子邮件
会显示乱码
随着计算机在亚洲兴起，这种做法彻底失效了
中文和日文这样的语言有数千个字符
根本没办法用 8 位来表示所有字符！
为了解决这个问题，每个国家都发明了多字节编码方案
但相互不兼容
日本人总是碰到编码问题，以至于专门有词来称呼：
"mojibake" 意思是 乱码
所以 Unicode 诞生了 - 统一所有编码的标准
设计于 1992 年，解决了不同国家不同标准的问题
Unicode 用一个统一编码方案
最常见的 Unicode 是 16 位的，有超过一百万个位置 -
对所有语言的每个字符都够了
100 多种字母表加起来占了 12 万个位置。
还有位置放数学符号，甚至 Emoji
就像 ASCII 用二进制来表示字母一样
其他格式 - 比如 MP3 或 GIF  -
用二进制编码声音/颜色，表示照片,电影,音乐
重要的是，这些标准归根到底是一长串位
短信，这个 YouTube 视频，互联网上的每个网页
甚至操作系统，只不过是一长串 1 和 0
下周
我们会聊计算机怎么操作二进制
初尝"计算"的滋味
感谢观看，下周见

上集，我们谈了如何用二进制表示数字
比如二进制 00101010 是十进制的 42
表示和存储数字是计算机的重要功能
但真正的目标是计算，有意义的处理数字
比如把两个数字相加
这些操作由计算机的 "算术逻辑单元 "处理
但大家会简称：ALU
ALU 是计算机的数学大脑
等你理解了 ALU 的设计和功能之后
你就理解了现代计算机的基石
ALU *就是* 计算机里负责运算的组件\N 基本其他所有部件都用到了它
先来看看这个美人
这可能是最著名的 ALU，英特尔 74181
1970 年发布时，它是第一个封装在单个芯片内的完整 ALU
这在当时是惊人的工程壮举
今天我们用上周学的布尔逻辑门
做一个简单的 ALU 电路，功能和 74181 一样
然后接下来几集，用它从头做出一台电脑
所以会有点复杂
但我觉得你们搞的定
ALU 有 2 个单元，1 个算术单元和 1 个逻辑单元
我们先讲"算术单元"，它负责计算机里的所有数字操作
比如加减法
它还做很多其他事情，比如给某个数字+1
这叫增量运算，我们之后会说
今天的重点是一切的根本 - "把两个数字相加"
我们可以用单个晶体管一个个拼，把这个电路做出来，\N 但很快就会复杂的难以理解
所以与其用晶体管，我们会像第 3 集
- 用更高层的抽象，用逻辑门来做
我们会用到 AND，OR，NOT 和 XOR 逻辑门
最简单的加法电路， \N 是拿 2 个 bit 加在一起（bit 是 0 或 1）
有 2 个输入：A 和 B， 1 个输出：就是两个数字的和
需要注意的是：A, B, 输出，这3个都是单个 Bit （ 0 或 1 ）
输入只有四种可能
前三个是\N 0 + 0 = 0 \N 1 + 0 = 1 \N 0 + 1 = 1
记住二进制里，1 与 true 相同，0 与 false 相同
这组输入和输出，和 XOR 门的逻辑完全一样
所以我们可以把 XOR 用作 1 位加法器（adder）
但第四个输入组合，1+1，是个特例 \N 1+1=2（显然）
但二进制里没有 2
上集说过，二进制 1+1 的结果是0，1进到下一位
和是 10 (二进制)
XOR 门的输出，只对了一部分， 1+1 输出 0
但我们需要一根额外的线代表 "进位"
只有输入是 1 和 1 时，进位才是 "true"
因为算出来的结果用 1 个 bit 存不下
方便的是，我们刚好有个逻辑门能做这个事！
没那么复杂 - 就两个逻辑门而已
让我们抽象化
把 "半加器" 封装成一个单独组件
两个输入   A 和 B 都是 1 位 \N 两个输出  "总和" 与 "进位"
这进入了另一层抽象
我好像说了很多次，说不定会变成一个梗
如果想处理超过 1+1 的运算，我们需要"全加器"
半加器 输出了进位
意味着，我们算下一列的时候
还有之后的每一列，我们得加 3 个位在一起，并不是 2 个
全加器复杂了一点点
全加器表格
有 3 个输入：A, B, C （都是 1 个 bit)
所以最大的可能是 1 + 1 + 1
"总和"1 "进位"1 \N 所以要两条输出线： "总和"和"进位"
我们可以用 半加器 做 全加器
我们先用半加器将 A 和 B 相加
然后把 C 输入到第二个半加器
最后用一个 OR 门检查进位是不是 true
这样就做出了一个全加器！
我们可以再提升一层抽象，把全加器作为独立组件
全加器会把 A，B，C 三个输入加起来 \N 输出 "总和" 和 "进位"
现在有了新组件，我们可以相加两个 8 位数字
叫两个数字叫 A 和 B 好了
我们从 A  和 B 的第一位开始
叫 A0 和 B0 好了
现在不用处理任何进位，因为是第一次加法
所以我们可以用半加器，来加这2个数字
输出叫 sum0
现在加 A1 和 B1
因为 A0 和 B0 的结果有可能进位
所以这次要用全加器，除了 A1 和 B1，还要连上进位
输出叫 sum1
然后，把这个全加器的进位 \N 连到下个全加器的输入，处理 A2 和 B2
以此类推，把 8 个 bit 都搞定
注意每个进位是怎么连到下一个全加器的
所以叫 "8位行波进位加法器"
注意最后一个全加器有 "进位" 的输出
如果第 9 位有进位，代表着 2 个数字的和太大了，超过了 8 位
这叫 "溢出" (overflow)
一般来说 "溢出" 的意思是, 两个数字的和太大了
超过了用来表示的位数
这会导致错误和不可预期的结果
著名的例子是，吃豆人用 8 位存当前关卡数
如果你玩到了第 256 关（ 8 位 bit 最大表示 255）
ALU 会溢出
造成一连串错误和乱码，使得该关卡无法进行
这个 bug 成了厉害吃豆人玩家的代表
如果想避免溢出
我们可以加更多全加器，可以操作 16 或 32 位数字
让溢出更难发生，但代价是更多逻辑门
另外一个缺点是，每次进位都要一点时间
当然时间不久，因为电子移动的很快
但如今的量级是每秒几十亿次运算，所以会造成影响
所以，现代计算机用的加法电路有点不同
叫 "超前进位加法器"
它更快，做的事情是一样的 - 把二进制数相加
ALU 的算术单元，也能做一些其他数学运算
一般支持这 8 个操作
就像加法器一样，这些操作也是由逻辑门构成的
有趣的是，你可能注意到没有乘法和除法
因为简单的 ALU 没有专门的电路来处理
而是把乘法用多次加法来实现
假设想算 12x5
这和把 "12" 加 5 次是一样的
所以要 5 次 ALU 操作来实现这个乘法
很多简单处理器都是这样做的
比如恒温器，电视遥控器和微波炉
慢是慢，但是搞的定
然而笔记本和手机有更好的处理器
有专门做乘法的算术单元
你可能猜到了，乘法电路比加法复杂
- 没什么魔法，只是更多逻辑门
所以便宜的处理器没有.
好了，我们现在讲 ALU 的另一半：逻辑单元
逻辑单元执行逻辑操作
比如之前讨论过的 AND，OR 和 NOT 操作
它也能做简单的数值测试
比如一个数字是不是负数
例如，这是检查 ALU 输出是否为 0 的电路
它用一堆 OR 门检查其中一位是否为 1
哪怕只有一个 Bit (位) 是1，
我们就知道那个数字肯定不是 0，然后用一个 NOT 门取反
所以只有输入的数字是 0，输出才为 1
以上就是 ALU 的一个高层次概括
我们甚至从零做了几个主要组件，比如行波进位加法器
它们只是一大堆逻辑门巧妙的连在一起而已.
让我们回到视频开始时的 ALU，英特尔 74181
和我们刚刚做的 8 位 ALU 不同，74181 只能处理 4 位输入
也就是说
你刚做了一个比英特尔 74181 还好的 ALU ！
其实 差不多啦..
我们虽然没有全部造出来
但你理解了整体概念
74181 用了大概 70 个逻辑门，但不能执行乘除.
但它向小型化迈出了一大步
让计算机可以更强大更便宜
4 位 ALU 已经要很多逻辑门了
但我们的 8 位 ALU 会需要数百个逻辑门
工程师不想在用 ALU 时去想那些事情,
所以想了一个特殊符号来代表它，看起来像一个大 "V"
又一层抽象！
我们的 8 位  ALU 有两个输入，A和B，都是 8 位 (bits)
我们还需要告诉 ALU 执行什么操作
例如加法或减法
所以我们用 4 位的操作代码
我们之后的视频会再细说
简言之,"1000"可能代表加法命令 \N "1100"代表减法命令
操作代码告诉 ALU 执行什么操作
输出结果是 8 位的
ALU 还会输出一堆标志（Flag）
"标志"是1位的，代表特定状态.
比如相减两个数字，结果为 0
我们的零测试电路（前面做的）\N 会将零标志设为 True（1）
如果想知道两个数字是否相等，这个非常有用
如果想知道： A 是否小于 B
可以用 ALU 来算 A 减 B，看负标志是否为 true
如果是 true，我们就知道 A 小于 B
最后，还有一条线连到加法器的进位
如果有溢出，我们就知道
这叫溢出标志
高级 ALU 有更多标志
但这 3 个标志是 ALU 普遍用的
其实，我们之后的视频会用到它们
现在你知道了\N 计算机是怎样在没有齿轮或杠杆的情况下 进行运算
接下来两集  我们会用 ALU 做 CPU
但在此之前，计算机需要一些 "记忆" ！
我们下周会讲

上集，我们用逻辑门做了个简单 ALU
它能执行算术(Arithmetic)和逻辑(Logic)运算 \N ALU 里的 A 和 L 因此得名
当然，算出来之后如果扔掉就没什么意义了
得找个方法存起来
可能还要进行多个连续操作
这就用到计算机内存了
如果你在主机上打过一场长时间的对局
或玩困难模式的 "扫雷"
然后狗跑过来，被电源线绊倒，把插头拔了出来
你知道失去进度的痛苦
真同情你 :(
你损失数据的原因是 \N 电脑用的是"随机存取存储器"，简称"RAM"
它只能在有电的情况下存储东西，比如游戏状态
另一种存储 (memory) 叫持久存储，电源关闭时数据也不会丢失
它用来存其他东西.
我们之后会讨论存储 (memory) 的持久性问题
今天我们从简单开始
- 做只能存储 1 位的电路
之后再扩大，做出我们的内存模块
下次和 ALU 结合起来，做出 CPU！
我们至今说过的电路都是单向的
- 总是向前流动
比如上集的 8 位 "脉动进位加法器"
但也可以做回向电路，把输出连回输入
我们拿一个 OR 门试试，把输出连回输入
看看会发生什么
首先，两个输入都设为 0
"0 OR 0" 是 0，所以电路输出0
如果将 A 变成1
"1 OR 0" 为 1，所以输出 1
一转眼的功夫，输出回到 B
OR 门看到两个输入都是 1
"1 OR 1" 仍然为1，所以输出不变
如果将 A 变成 0，OR 门依然输出 1
现在我们有个电路能记录 "1"
然而有个小问题：这是永久的！
无论怎么试，都没法从 1 变回 0
我们换成 AND 门看看会怎样
开始时，A 和 B 都设 1
"1 AND 1" 永远输出 1
如果之后 A 设为 0，由于是 AND 门，输出会变成 0
这个电路能记录 0，和之前那个相反
就像之前，无论 A 设什么值，电路始终输出 0
现在有了能存 0 和 1 的电路
为了做出有用的存储 (memory) \N 我们把两个电路结合起来
这叫 "AND-OR 锁存器"
它有两个输入\N  "设置"输入, 把输出变成 1\N "复位"输入, 把输出变成 0
如果"设置"和"复位"都是 0，电路会输出最后放入的内容
也就是说，它存住了 1 位的信息！
存储！
这叫"锁存", 因为它"锁定"了一个值
放入数据的动作叫 "写入"  ，拿出数据的动作叫 "读取"
现在我们终于有办法存一个位了！
超棒！
麻烦的是, 用两条线 "设置"和"复位" 来输入, 有点难理解
为了更容易用，我们希望只有一条输入线
将它设为 0 或 1 来存储值
还需要一根线来"启用"内存
启用时允许写入，没启用时就 "锁定"
- 这条线叫 "允许写入线"
加一些额外逻辑门，可以做出这个电路
这叫"门锁"，因为门可以打开和关上
现在有点复杂了
我们不想关心单独的逻辑门
所以我们提升一层抽象
把 "门锁" 放到盒子里 - 这个盒子能存一个 bit
我们来测一下新组件！
一切从 0 开始
数据输入从0换到1, 从1换到0
什么也不会发生 - 输出依然是 0
因为 "允许写入线" 是关闭的，所以内容不会变化
所以要给 "允许写入线" 输入 1, "打开" 门
现在往 "数据线" 放 1，1 就能存起来了
注意输出现在是 1 了
成功！
现在可以关掉  "允许写入线" ，输出会保持 1
现在不管给 "数据线" 什么值
输出都不会变
值存起来了
现在又打开 "允许写入线"  \N  "数据线" 设为0
完成
"允许写入线" 关闭，输出 0
成功了！
当然，只能存 1 bit 没什么大用
- 肯定玩不了游戏
或做其它事情
但我们没限制只能用一个锁存器
如果我们并排放 8 个锁存器，\N 可以存 8 位信息，比如一个 8 bit 数字
一组这样的锁存器叫 "寄存器"
寄存器能存一个数字，这个数字有多少位，叫"位宽"
早期电脑用 8 位寄存器，然后是 16 位，32 位
如今许多计算机都有 64 位宽的寄存器
写入寄存器前，要先启用里面所有锁存器
我们可以用一根线连接所有 "允许输入线", 把它设为 1
然后用 8 条数据线发数据，然后将 "允许写入线" 设回 0
现在 8 位的值就存起来了
如果只有很少的位(bits)，把锁存器并排放置，也勉强够用了.
64 位寄存器要 64 根数据线，64 根连到输出端
幸运的是，我们只要 1 根线启用所有锁存器 \N 但加起来也有 129 条线了
如果存 256 位要 513 条线！
解决方法是矩阵！
在矩阵中，我们不并列排放锁存器
而是做成网格
存 256 位，我们用 16x16 网格的锁存器，有 16 行 16 列
要启用某个锁存器，就打开相应的 行线 和 列线
放大看看怎么做的
我们只想打开交叉处  锁存器的 "允许写入线"
所有其他锁存器，保持关闭
我们可以用 AND 门！
只有 行线和列线 均为 1 ，AND 门才输出 1
所以可以用选择单个锁存器
这种行/列排列法，用一根 "允许写入线" 连所有锁存器
为了让锁存器变成 "允许写入"
行线，列线和 "允许写入线" 都必须是 1
每次只有 1 个锁存器会这样
代表我们可以只用一根 "数据线"  \N 连所有锁存器来传数据
因为只有一个锁存器会启用，只有那个会存数据
其他锁存器会忽略数据线上的值，因为没有 "允许写入"
我们可以用类似的技巧, 做"允许读取线"来读数据
从一个指定的锁存器，读取数据
所以对于 256 位的存储
只要 35 条线 \N1条"数据线", 1条"允许写入线", 1条"允许读取线"
还有16行16列的线用于选择锁存器 \N （16+16=32, 32+3=35）
这省了好多线！
但我们需要某种方法来 唯一指定 交叉路口
我们可以想成城市
你可能想和别人  在第 12 大道和第 8 街的交界碰面
- 这是一个交叉点的地址
我们刚刚存了一位的地址是 "12行 8列"
由于最多 16 行, 用 4 位就够了
12 用二进制表示为 1100
列地址也可以这样： 8 用二进制表示为 1000
刚才说的"12行 8列"可以写成 11001000
为了将地址转成  行和列
我们需要 "多路复用器"
- 这个名字起码比 ALU 酷一点
多路复用器有不同大小
因为有 16 行，我们需要 1 到 16 多路复用器
工作方式是
输入一个 4 位数字，它会把那根线，连到相应的输出线
如果输入 0000，它会选择第一列
如果输入 0001，会选择下一列，依此类推
一个多路复用器处理行(row) \N 另一个多路复用器处理列(column)
好吧，开始有点复杂了
那么把 256 位内存当成一个整体好了
又提升了一层抽象！
它输入一个 8 位地址：4 位代表列，4 位代表行
我们还需要 "允许写入线" 和 "允许读取线"
最后，还需要一条数据线，用于读/写数据
不幸的是， 256 位的内存也没法做什么事
所以还要扩大规模
把它们并排放置
就像寄存器一样
一行8个，可以存一个 8 位数字 \N 8 位也叫一个字节（byte）
为了存一个 8 位数字，我们同时给 8 个 256 位内存一样的地址
每个地址存 1 位
意味着这里总共能存 256 个字节 （byte）
再次，为了简单，我们不管内部
不看作是一堆独立的存储模块和电路
而是看成一个整体的可寻址内存
我们有 256 个地址
每个地址能读或写一个 8 位值
我们下集做 CPU 时会用到这个内存
现代计算机的内存 \N 扩展到上兆字节（MB）和千兆字节（GB）的方式
和我们这里做的一样
不断把内存打包到更大规模
随着内存地址增多，内存地址也必须增长
8 位最多能代表 256 个内存地址 \N（1111 1111 是255，0~255 一共 256 个数字）
只有这么多
要给千兆或十亿字节的内存寻址，需要 32 位的地址
内存的一个重要特性是：可以随时访问任何位置
因此叫 "随机存取存储器" ，简称 RAM
当你听到有人说 RAM 有多大
他的意思是内存有多大
RAM 就像人类的短期记忆
记录当前在做什么事
比如吃了午饭没，或有没有交电话费
这是一条真的内存，上面焊了 8 个内存模块
如果打开其中一个，然后放大
会看到 32 个内存方块
放大其中一个方块，可以看到有 4 个小块
如果再放大，可以看到存一个"位"的矩阵
这个矩阵是 128 位 x 64 位
总共 8192 位
每个方格 4 个矩阵 \N 所以一个方格有 32768 个位 （8192 x 4 = 32768）
而一共 32 个方格
总而言之，1 个芯片大约存 100 万位
RAM 有 8 个芯片，所以总共 800 万位
也就是 1 兆字节（1 MB）
1 MB 如今不算大 - 这是 1980 年代的 RAM
如今你可以买到千兆字节（GB）的 RAM
那可是数十亿字节的内存
今天，我们用锁存器做了一块 SRAM（静态随机存取存储器）
还有其他类型的 RAM，如 DRAM，闪存和 NVRAM
它们在功能上与 SRAM 相似
但用不同的电路存单个位
- 比如用不同的逻辑门，电容器，电荷捕获或忆阻器
但根本上  这些技术都是矩阵层层嵌套，来存储大量信息
就像计算机中的很多事情，底层其实都很简单
让人难以理解的，是一层层精妙的抽象
像一个越来越小的俄罗斯套娃
下周见

今天我们讲 处理器
提示下 - 这集可能是最难的一集
所以一旦你理解了，就会变得超厉害der~
我们已经做了一个算术逻辑单元（ALU）
输入二进制，它会执行计算
我们还做了两种内存：
寄存器 - 很小的一块内存，能存一个值
之后我们增大做出了 RAM
RAM 是一大块内存，能在不同地址存大量数字
现在是时候把这些放在一起，组建计算机的 "心脏" 了
但这个 "心脏" 不会有任何包袱，比如人类情感.
计算机的心脏是"中央处理单元"，简称 "CPU"
CPU 负责执行程序
比如 Office，Safari 浏览器，你最爱的 《半条命2》
程序由一个个操作组成
这些操作叫"指令"(Instruction) \N 因为它们"指示"计算机要做什么
如果是数学指令，比如加/减
CPU 会让 ALU 进行数学运算
也可能是内存指令，CPU 会和内存通信，然后读/写值
CPU 里有很多组件.
所以我们一边说一边建
我们把重点放在功能，而不是一根根线具体怎么连
当我们用一条线连接两个组件时
这条线只是所有必须线路的一个抽象
这种高层次视角叫  "微体系架构"
好，我们首先要一些内存，把上集做的 RAM 拿来就行
为了保持简单，假设它只有 16 个位置，每个位置存 8 位
再来四个 8 位寄存器，叫 A，B，C，D
寄存器用来 临时存数据 和 操作数据
我们已经知道数据  是以二进制值存在内存里
程序也可以存在内存里
我们可以给 CPU 支持的所有指令，分配一个 ID
指令表
指令
描述
4位操作码
地址或寄存器
在这个假设的例子 \N 我们用前四位存 "操作代码" （operation code）
简称 "操作码" （opcode）
后四位代表数据来自哪里
- 可以是寄存器或内存地址
我们还需要两个寄存器，来完成 CPU.
1. 一个寄存器追踪程序运行到哪里了，我们叫它  "指令地址寄存器"
顾名思义，存当前指令的内存地址
2. 另一个寄存器存当前指令，叫  "指令寄存器"
当启动计算机时，所有寄存器从 0 开始
为了举例，我们在 RAM 里放了一个程序，我们今天会过一遍
CPU 的第一个阶段叫 "取指令阶段"
负责拿到指令
首先，将 "指令地址寄存器" 连到 RAM
寄存器的值为 0，因此 RAM 返回地址 0 的值
0010 1110 会复制到 "指令寄存器" 里
现在指令拿到了
要弄清是什么指令，才能执行（execute）
而不是杀死（kill）它
这是 "解码阶段"
前 4 位 0010 是 LOAD A 指令
意思是，把 RAM 的值放入寄存器 A
后 4 位 1110 是 RAM 的地址, 转成十进制是 14
接下来，指令由 "控制单元" 进行解码
就像之前的所有东西 \N  "控制单元" 也是逻辑门组成的
比如，为了识别 "LOAD A" 指令
需要一个电路，检查操作码是不是 0010
我们可以用很少的逻辑门来实现.
现在知道了是什么指令
就可以开始执行了，开始 "执行阶段"
用 "检查是否 LOAD_A 指令的电路"
可以打开 RAM 的 "允许读取线", 把地址 14 传过去
RAM 拿到值，0000 0011，十进制的 3
因为是 LOAD_A 指令 \N 我们想把这个值只放到寄存器 A，其他寄存器不受影响
所以需要一根线，把 RAM 连到 4 个寄存器
用 "检查是否 LOAD_A 指令的电路" \N 启用寄存器 A 的 "允许写入线"
这就成功了
- 把 RAM 地址 14 的值，放到了寄存器 A.
既然指令完成了，我们可以关掉所有线路
去拿下一条指令
我们把 "指令地址寄存器"+1，"执行阶段"就此结束.
LOAD_A 只是 CPU 可以执行的各种指令之一
不同指令由不同逻辑电路解码
这些逻辑电路会配置 CPU 内的组件来执行对应操作
具体分析这些解码电路太繁琐了
既然已经看了 1 个例子，
干脆把 "控制单元 "包成一个整体，简洁一些.
没错，一层新抽象
控制单元就像管弦乐队的指挥
"指挥" CPU 的所有组件
"取指令→解码→执行" 完成后
现在可以再来一次，从 "取指令" 开始
"指令地址寄存器" 现在的值是 1
所以 RAM 返回地址 1 里的值：0001 1111
到 "解码" 阶段！
0001 是 LOAD B 指令 \N 从 RAM 里把一个值复制到寄存器 B
这次内存地址是 1111，十进制的 15
现在到 "执行阶段"！
"控制单元" 叫 RAM 读地址 15，并配置寄存器 B 接收数据
成功，我们把值 0000 1110 \N 也就是十进制的 14 存到了寄存器 B
最后一件事是 "指令地址寄存器" +1
我们又完成了一个循环
下一条指令有点不同
来取它吧
1000 是 ADD 指令
这次后面的 4 位不是 RAM 地址，\N 而是 2 位 2 位分别代表 2 个寄存器
2 位可以表示 4 个值
所以足够表示 4 个寄存器
第一个地址是 01, 代表寄存器B
第二个地址是 00, 代表寄存器A
因此，1000 0100，代表把寄存器 B 的值，加到寄存器 A 里
为了执行这个指令，我们要整合第 5 集的 ALU
"控制单元" 负责选择正确的寄存器作为输入
并配置 ALU 执行正确的操作
对于 "ADD" 指令， "控制单元" 会
启用寄存器 B，作为 ALU 的第一个输入
还启用寄存器 A，作为 ALU 的第二个输入
之前说过，ALU 可以执行不同操作
所以控制单元必须传递 ADD 操作码告诉它要做什么
最后，结果应该存到寄存器 A
但不能直接写入寄存器 A
这样新值会进入 ALU ，不断和自己相加
因此，控制单元用一个自己的寄存器暂时保存结果
关闭 ALU，然后把值写入正确的寄存器
这里 3+14=17，二进制是 0001 0001
现在存到了寄存器 A
和之前一样，最后一件事是把指令地址 + 1
这个循环就完成了
好，来看最后一个指令：0100 1101
解码得知是 STORE A 指令（把寄存器 A 的值放入内存） \N RAM 地址 13
接下来，把地址传给 RAM
但这次不是 "允许读取" ，而是 "允许写入"
同时，打开寄存器 A 的 "允许读取"
这样就可以把寄存器 A 里的值，传给 RAM
恭喜，我们刚运行了第一个电脑程序！
它从内存中加载两个值，相加，然后把结果放回内存
刚刚是我一步步来讲的,
我们人工切换 CPU 的状态 "取指令→解码→执行"

其实是 "时钟" 来负责管理 CPU 的节奏
时钟以精确的间隔  触发电信号
控制单元会用这个信号，推进 CPU 的内部操作
确保一切按步骤进行
- 就像罗马帆船的船头，有一个人负责按节奏的击鼓,
让所有划船的人同步... 就像节拍器一样
节奏不能太快
因为就算是电也要一定时间来传输
CPU "取指令→解码→执行" 的速度叫 "时钟速度"
单位是赫兹 - 赫兹是用来表示频率的单位
1 赫兹代表一秒 1 个周期
因为我花了大概 6 分钟，给你讲了 4 条指令
读取→读取→相加→存储
所以我的时钟速度大概是 0.03 赫兹
我承认我算数不快
但哪怕有人算数很快，最多也就是一秒一次，或 1 赫兹
第一个单芯片 CPU 是 "英特尔 4004" \N 1971 年发布的 4 位CPU
它的微架构 很像我们之前说的 CPU
虽然是第一个单芯片的处理器
但它的时钟速度达到了 740 千赫兹 - 每秒 74 万次
你可能觉得很快
但和如今的处理器相比不值一提
一兆赫兹是 1 秒 1 百万个时钟周期
你现在看视频的电脑或手机，肯定有几千兆赫兹
- 1 秒 10 亿次时钟周期
你可能听过有人会把计算机超频
意思是修改时钟速度，加快 CPU 的速度
- 就像罗马帆船要撞另一艘船时，鼓手会加快敲鼓速度
芯片制造商经常给 CPU 留一点余地，可以接受一点超频
但超频太多会让 CPU 过热
或产生乱码，因为信号跟不上时钟
你可能很少听说降频
但降频其实很有用
有时没必要让处理器全速运行
可能用户走开了，或者在跑一个性能要求较低的程序
把 CPU 的速度降下来，可以省很多电
省电对用电池的设备很重要，比如笔记本和手机
为了尽可能省电
很多现代处理器可以按需求  加快或减慢时钟速度
这叫 "动态调整频率"
加上时钟后，CPU 才是完整的.
现在可以放到盒子里，变成一个独立组件
对
一层新的抽象！
RAM，上集说过，是在 CPU 外面的独立组件
CPU 和 RAM 之间 \N 用 "地址线"  "数据线" 和 "允许读/写线" 进行通信
虽然今天我们设计的 CPU 是简化版的,
但我们提到的很多机制，依然存在于现代处理器里
下一集，我们要加强 CPU，给它扩展更多指令.
同时开始讲软件.
下周见

上集我们把 ALU, 控制单元, RAM, 时钟 结合在一起
做了个基本，但可用的"中央处理单元", 简称 CPU
它是计算机的核心
我们已经用电路做了很多组件.
这次我们给 CPU 一些指令来运行!
CPU 之所以强大，是因为它是可编程的 -
如果写入不同指令，就会执行不同任务
CPU 是一块硬件，可以被软件控制!
我们重新看一下上集的简单程序
内存里有这些值
每个地址可以存 8 位数据
因为我们的 CPU 是假设的，这里前4位是"操作码"
后4位指定一个内存地址，或寄存器.
内存地址 0 是 0010 1110
前 4 位代表 LOAD_A 指令
意思是：把后 4 位指定的内存地址的值，放入寄存器 A
后 4 位是 1110，十进制的 14
我们来把 0010 1110 看成 "LOAD_A 14" 指令
这样更好理解！
也更方便说清楚
可以对内存里剩下的数也这样转换.
这里，我们的程序只有4个指令
还有数字 3 和 14
现在一步步看
"LOAD_A 14" 是从地址 14 中拿到数字3，放入寄存器A
"LOAD_B 15" 是从地址 15 中拿到数字14，放入寄存器B
好.
挺简单的！
下一个是 ADD 指令
"ADD B A" 告诉 ALU \N 把寄存器 B 和寄存器 A 里的数字加起来
（B和A的）顺序很重要，因为结果会存在第二个寄存器
也就是寄存器 A
最后一条指令是 "STORE_A 13" \N 把寄存器 A 的值存入内存地址 13
好棒！
我们把 2 个数加在了一起!
毕竟只有4个指令，也只能做这个了.
加多一些指令吧!
SUB 是减法，和 ADD 一样也要 2 个寄存器来操作.
还有 JUMP（跳转）
让程序跳转到新位置
如果想改变指令顺序，或跳过一些指令，这个很实用
举例, JUMP 0 可以跳回开头
JUMP 在底层的实现方式是 \N 把指令后 4 位代表的内存地址的值
覆盖掉 "指令地址寄存器" 里的值
还有一个特别版的 JUMP 叫 JUMP_NEGATIVE
它只在 ALU 的 "负数标志" 为真时，进行 JUMP
第5集讲过，算术结果为负，"负数标志"才是真
结果不是负数时, "负数标志"为假
如果是假，JUMP_NEGATIVE 就不会执行 \N 程序照常进行
我们之前的例子程序，其实应该是这样，才能正确工作.
否则跑完  STORE_A 13 之后，\N CPU 会不停运行下去，处理后面的 0
因为 0 不是操作码，所以电脑会崩掉!
我还想指出一点，指令和数据都是存在同一个内存里的.
它们在根本层面上毫无区别 - 都是二进制数
HALT 很重要，能区分指令和数据
好，现在用 JUMP 让程序更有趣一些.
我们还把内存中 3 和 14 两个数字，改成 1 和 1
现在来从 CPU 的视角走一遍程序
首先 LOAD_A 14，把 1 存入寄存器A \N（因为地址 14 里的值是 1）
然后 LOAD_B 15，把 1 存入寄存器B\N（因为地址 15 里的值也是 1）
然后 ADD B A 把寄存器 B 和 A 相加 \N 结果放到寄存器 A 里
现在寄存器 A 的值是 2 \N (当然是以二进制存的）
然后 STORE_A 13 指令，把寄存器 A 的值存入内存地址 13
现在遇到 JUMP 2 指令
CPU 会把"指令地址寄存器"的值，现在是 4，改成 2
因此下一步不再是 HALT
而是读内存地址 2 里的指令，也就是 ADD B A
我们跳转了!
寄存器 A 里是 2，寄存器 B 里是 1
1+2=3，寄存器 A 变成 3
存入内存
又碰到 JUMP 2，又回到 ADD B A.
现在寄存器 A 是 4
发现了吗？
每次循环都+1
不断增多
酷
但没法结束啊
永远不会碰到 HALT
总是会碰到 JUMP
这叫无限循环 - 这个程序会永远跑下去.. 下去.. 下去.. 下去
下去
为了停下来，我们需要有条件的 JUMP
只有特定条件满足了，才执行 JUMP.
比如 JUMP NEGATIVE 就是条件跳转的一个例子
还有其他类型的条件跳转，比如\N  JUMP IF EQUAL（如果相等）\N JUMP IF GREATER（如果更大）
现在把代码弄花哨一点，再过一遍代码
就像之前，程序先把内存值放入寄存器 A 和 B.
寄存器 A 是 11，寄存器 B 是 5
SUB B A，用 A 减 B，11-5=6
6 存入寄存器 A
JUMP NEGATIVE 出场
上一次 ALU 运算的结果是 6
是正数，所以 "负数标志" 是假
因此处理器不会执行 JUMP
继续下一条指令
JUMP 2 没有条件，直接执行！
又回到寄存器 A-B，6-5=1
A 变成 1
下一条指令
又是 JUMP NEGATIVE
因为 1 还是正数，因此 JUMP NEGATIVE 不会执行 \N 来到下一条指令，JUMP 2
又来减一次
这次就不一样了
这次ALU的 "负数标志" 是真
现在下一条指令
JUMP NEGATIVE 5, CPU 的执行跳到内存地址 5
跳出了无限循环！
现在的指令是 ADD B A，-4+5=1，1 存入寄存器 A
下一条指令  STORE_A 13，把 A 的值存入内存地址 13
最后碰到 HALT 指令，停下来.
虽然程序只有 7 个指令，但 CPU 执行了 13 个指令,
因为在内部循环了 2 次.
这些代码其实是算余数的，11除5余1
如果加多几行指令，我们还可以跟踪循环了多少次
11除5，循环2次
余1
当然，我们可以用任意2个数，7和81，18和54，什么都行
这就是软件的强大之处
软件还让我们做到硬件做不到的事
ALU 可没有除法功能
是程序给了我们这个功能.
别的程序也可以用我们的除法程序，来做其他事情
这意味着  一层新抽象！
我们这里假设的 CPU 很基础，所有指令都是 8 位,
操作码只占了前面 4 位
即便用尽 4 位，也只能代表 16 个指令
而且我们有几条指令，是用后 4 位来指定内存地址
因为 4 位最多只能表示 16 个值，
所以我们只能操作 16 个地址，这可不多.
我们甚至不能 JUMP 17
因为 4 位二进制无法表示数字 17
因此，真正的现代 CPU 用两种策略
最直接的方法是用更多位来代表指令，比如 32 位或 64 位
这叫 指令长度
毫不意外
第二个策略是 "可变指令长度"
举个例子，比如某个 CPU 用 8 位长度的操作码
如果看到 HALT 指令，HALT 不需要额外数据
那么会马上执行.
如果看到 JUMP，它得知道位置值
这个值在 JUMP 的后面
这叫 "立即值"
这样设计，指令可以是任意长度
但会让读取阶段复杂一点点
要说明的是，我们拿来举例的 CPU 和指令集都是假设的,
是为了展示核心原理
所以我们来看个真的 CPU 例子.
1971年，英特尔发布了 4004 处理器.
这是第一次把 CPU 做成一个芯片  \N 给后来的英特尔处理器打下了基础
它支持 46 个指令
足够做一台能用的电脑
它用了很多我们说过的指令，比如 JUMP ADD SUB LOAD
它也用 8 位的"立即值"来执行 JUMP, 以表示更多内存地址.
处理器从 1971 年到现在发展巨大.
现代 CPU, 比如英特尔酷睿 i7, 有上千个指令和指令变种
长度从1到15个字节.
举例，光 ADD 指令就有很多变种!
指令越来越多，是因为给 CPU 设计了越来越多功能
下集我们会讲
下周见

随着本系列进展，我们知道计算机进步巨大
从 1 秒 1 次运算，到现在有千赫甚至兆赫的CPU
你现在看视频的设备八成也有 GHz 速度
1 秒十亿条指令
这是很大的计算量！
早期计算机的提速方式是  减少晶体管的切换时间.
晶体管组成了逻辑门，ALU 以及前几集的其他组件
但这种提速方法最终会碰到瓶颈，所以处理器厂商
发明各种新技术来提升性能，不但让简单指令运行更快
也让它能进行更复杂的运算
上集我们写了个做除法的程序，给 CPU 执行
方法是做一连串减法，比如16除4 会变成
碰到 0 或负数才停下.
但这种方法要多个时钟周期，很低效
所以现代 CPU 直接在硬件层面设计了除法 \N 可以直接给 ALU 除法指令
这让 ALU 更大也更复杂一些
但也更厉害 - \N  复杂度 vs 速度 的平衡在计算机发展史上经常出现
举例，现代处理器有专门电路来处理 \N 图形操作, 解码压缩视频, 加密文档 等等
如果用标准操作来实现，要很多个时钟周期.
你可能听过某些处理器有 MMX, 3DNOW, SEE
它们有额外电路做更复杂的操作
用于游戏和加密等场景
指令不断增加，人们一旦习惯了它的便利就很难删掉
所以为了兼容旧指令集，指令数量越来越多
英特尔 4004，第一个集成CPU，有 46 条指令
足够做一台能用的计算机
但现代处理器有上千条指令，有各种巧妙复杂的电路
超高的时钟速度带来另一个问题
- 如何快速传递数据给 CPU
就像有强大的蒸汽机  但无法快速加煤
RAM 成了瓶颈
RAM 是 CPU 之外的独立组件
意味着数据要用线来传递，叫"总线"
总线可能只有几厘米
别忘了电信号的传输接近光速
但 CPU 每秒可以处理上亿条指令
很小的延迟也会造成问题
RAM 还需要时间找地址 \N 取数据，配置，输出数据
一条"从内存读数据"的指令可能要多个时钟周期
CPU 空等数据
解决延迟的方法之一是 \N 给 CPU 加一点 RAM - 叫"缓存"
因为处理器里空间不大，所以缓存一般只有 KB 或 MB
而 RAM 都是 GB 起步
缓存提高了速度
CPU 从 RAM 拿数据时 \N RAM 不用传一个，可以传一批
虽然花的时间久一点，但数据可以存在缓存
这很实用，因为数据常常是一个个按顺序处理
举个例子，算餐厅的当日收入
先取 RAM 地址 100 的交易额
RAM 与其只给1个值，直接给一批值
把地址100到200都复制到缓存
当处理器要下一个交易额时
地址 101，缓存会说："我已经有了，现在就给你"
不用去 RAM 取数据
因为缓存离 CPU 近, 一个时钟周期就能给数据 - CPU 不用空等！
比反复去 RAM 拿数据快得多
如果想要的数据已经在缓存，叫 缓存命中
如果想要的数据不在缓存，叫 缓存未命中
缓存也可以当临时空间，存一些中间值，适合长/复杂的运算
继续餐馆的例子，假设 CPU 算完了一天的销售额
想把结果存到地址 150
就像之前，数据不是直接存到 RAM
而是存在缓存，这样不但存起来快一些
如果还要接着算，取值也快一些
但这样带来了一个有趣的问题
缓存和 RAM 不一致了.
这种不一致必须记录下来，之后要同步
因此缓存里每块空间  有一个特殊标记
叫 "脏位"
- 这可能是计算机科学家取的最贴切的名字
同步一般发生在 当缓存满了而 CPU 又要缓存时
在清理缓存腾出空间之前，会先检查 "脏位"
如果是"脏"的, 在加载新内容之前, 会把数据写回 RAM
另一种提升性能的方法叫 "指令流水线"
想象下你要洗一整个酒店的床单
但只有 1 个洗衣机, 1 个干燥机
选择1：按顺序来，放洗衣机等 30 分钟洗完
然后拿出湿床单，放进干燥机等 30 分钟烘干
这样1小时洗一批
另外一说：如果你有 30 分钟就能烘干的干燥机
请留言告诉我是什么牌子，我的至少要 90 分钟.
即使有这样的神奇干燥机,  \N 我们可以用"并行处理"进一步提高效率
就像之前，先放一批床单到洗衣机
等 30 分钟洗完
然后把湿床单放进干燥机
但这次，与其干等 30 分钟烘干，\N 可以放另一批进洗衣机
让两台机器同时工作
30 分钟后，一批床单完成, 另一批完成一半
另一批准备开始
效率x2！
处理器也可以这样设计
第7集，我们演示了 CPU 按序处理
取指 → 解码 → 执行, 不断重复
这种设计，三个时钟周期执行 1 条指令
但因为每个阶段用的是 CPU 的不同部分
意味着可以并行处理！
"执行"一个指令时，同时"解码"下一个指令
"读取"下下个指令
不同任务重叠进行，同时用上 CPU 里所有部分.
这样的流水线  每个时钟周期执行1个指令
吞吐量 x 3
和缓存一样，这也会带来一些问题
第一个问题是 指令之间的依赖关系
举个例子，你在读某个数据 \N 而正在执行的指令会改这个数据
也就是说拿的是旧数据
因此流水线处理器  要先弄清数据依赖性
必要时停止流水线，避免出问题
高端 CPU，比如笔记本和手机里那种
会更进一步，动态排序 有依赖关系的指令
最小化流水线的停工时间
这叫 "乱序执行"
和你猜的一样，这种电路非常复杂
但因为非常高效，几乎所有现代处理器都有流水线
第二个问题是 "条件跳转"，比如上集的 JUMP NEGATIVE
这些指令会改变程序的执行流
简单的流水线处理器，看到 JUMP 指令会停一会儿 \N 等待条件值确定下来
一旦 JUMP 的结果出了，处理器就继续流水线
因为空等会造成延迟，所以高端处理器会用一些技巧
可以把 JUMP 想成是 "岔路口"
高端 CPU 会猜哪条路的可能性大一些
然后提前把指令放进流水线，这叫 "推测执行"
当 JUMP 的结果出了，如果 CPU 猜对了
流水线已经塞满正确指令，可以马上运行
如果 CPU 猜错了，就要清空流水线
就像走错路掉头
让 GPS 不要再！叫！了！
为了尽可能减少清空流水线的次数，CPU 厂商开发了复杂的方法
来猜测哪条分支更有可能，叫"分支预测"
现代 CPU 的正确率超过 90%
理想情况下，流水线一个时钟周期完成 1 个指令
然后"超标量处理器"出现了，一个时钟周期完成多个指令
即便有流水线设计，在指令执行阶段
处理器里有些区域还是可能会空闲
比如，执行一个 "从内存取值" 指令期间
ALU 会闲置
所以一次性处理多条指令（取指令+解码） 会更好.
如果多条指令要 ALU 的不同部分，就多条同时执行
我们可以再进一步，加多几个相同的电路 \N 执行出现频次很高的指令
举例，很多 CPU 有四个, 八个甚至更多 完全相同的ALU
可以同时执行多个数学运算
好了，目前说过的方法，都是优化 1 个指令流的吞吐量
另一个提升性能的方法是 同时运行多个指令流
用多核处理器
你应该听过双核或四核处理器
意思是一个 CPU 芯片里，有多个独立处理单元
很像是有多个独立 CPU
但因为它们整合紧密，可以共享一些资源
比如缓存，使得多核可以合作运算
但多核不够时，可以用多个 CPU
高端计算机，比如现在给你传视频的 Youtube 服务器
需要更多马力，让上百人能同时流畅观看
2个或4个CPU是最常见的
但有时人们有更高的性能要求
所以造了超级计算机！
如果要做怪兽级运算
比如模拟宇宙形成，你需要强大的计算能力
给普通台式机加几个 CPU 没什么用
你需要很多处理器！
不…不…还要更多
更多
截止至视频发布，世上最快的计算机在
中国无锡的国家超算中心
神威·太湖之光有 40960 个CPU，每个 CPU 有 256 个核心
总共超过1千万个核心，每个核心的频率是 1.45GHz
每秒可以进行 9.3 亿亿次浮点数运算
也叫 每秒浮点运算次数 (FLOPS)
相信我  这个速度很可怕
没人试过跑最高画质的《孤岛危机》但我估计没问题
长话短说，这些年处理器不但大大提高了速度
而且也变得更复杂，用各种技巧
榨干每个时钟周期 做尽可能多运算
我们的任务是利用这些运算能力，做又酷又实用的事
编程就是为了这个，我们下集说
下周见

前几集我们把重点放在计算机的原理
怎么从内存读写数据，执行操作
比如把两个数字加在一起
还简单讲了下指令的执行，也就是计算机程序
但我们还没讲的是：程序如何"进入"计算机
你应该记得在第 7, 8 集，我们一步步讲了例子程序
当时为了简单，我们假设程序已经魔法般在内存里了
但事实是，程序需要加载进内存
这不是魔法，是计算机科学！
给机器编程这个需求，早在计算机出现之前就有了
最著名的例子来自纺织业
如果你只想织一块红色大桌布
可以直接放红线进织布机
但如果想要图案怎么办? 比如条纹或者方格
工人要每隔一会儿 调整一次织布机
因为非常消耗劳动力，所以图案纺织品很贵
特定位置有没有穿孔，决定了线是高是低
横线是从上/从下穿过
为了让每行图案不同，纸卡连成长条
形成连续指令
听起来很熟？
很多人认为雅卡尔织布机是最早的编程
事实证明 穿孔纸卡便宜、可靠、也易懂
近一个世纪后
穿孔纸卡用于 1890 年美国人口普查
我们在第一集提过
一张卡存一个人的信息
比如种族
婚姻状况
子女数量
出生国家 等等
针对每个问题，人口普查工作者会在对应位置打孔
当卡片插入汇总机
孔会让对应总和值+1
可以插入整个国家人口的卡片
在结束后得到各个总值
值得注意的是，早期汇总机不算计算机
因为它们只做一件事 - 汇总数据
操作是固定的，不能编程
穿孔纸卡存的是数据，不是程序.
之后60年，这些机器被加强，可以做减、乘、除
甚至可以做一些小决定，决定何时执行某指令
为了正确执行不同计算，程序员需要某种控制面板
面板有很多小插孔，程序员可以插电线
让机器的不同部分  互相传数据和信号
因此也叫 "插线板"
不幸的是, 这意味着 运行不同程序要重新接线
所以到 1920 年代，控制面板变成了可拔插
让编程更方便
可以给机器插入不同程序
比如，一个插线板算销售税，另一个算工资单
但给插线板编程很复杂
图中乱成一团的线  负责算盈亏总额 \N 用于 IBM 402 核算机
在 1940 年代这样做很流行
用插线板编程  不只在机电计算机流行
世上第一台通用电子计算机，ENIAC，完成于 1946 年
用了一大堆插线板
程序在纸上设计好之后
给 ENIAC 连线，最多可能花三个星期
因为早期计算机非常昂贵 \N 停机几个星期只为换程序  完全无法接受
人们急需更快、更灵活的新方式来编程
幸运的是，到 1940 年代晚期 1950 年代初
内存变得可行
价格下降, 容量上升.  与其把程序存在插线板
存在内存变得可行
这样程序易于修改、方便 CPU 快速读取
这类机器叫 "存储程序计算机"
如果内存足够，不仅可以存要运行的程序
还可以存程序需要的数据
包括程序运行时产生的新数据
程序和数据都存在一个地方，叫 "冯诺依曼结构"
命名自 约翰·冯·诺依曼
杰出的数学家和物理学家 \N 参与了曼哈顿计划和早期电子计算机项目
他曾说：我在思考比炸弹重要得多的东西
计算机
冯诺依曼计算机的标志是，一个处理器(有算术逻辑单元)+
数据寄存器+指令寄存器+指令地址寄存器
+内存（负责存数据和指令)
希望这听起来很耳熟
因为第7集我们造了一个冯诺依曼计算机
第一台冯诺依曼架构的"储存程序计算机"
由曼彻斯特大学于 1948 年建造完成，绰号"宝宝"
甚至你现在看视频的计算机，也在用一样的架构
虽然有内存很棒
但程序和数据  依然需要某种方式输入计算机
所以用穿孔纸卡
让我们进入  思维泡泡
到1980年代，几乎所有的计算机都有穿孔纸卡读取器
可以吸入一张卡片，把卡片内容写进内存
如果放了一叠卡片，读取器会一个个写进内存
一旦程序和数据写入完毕，电脑会开始执行
即便简单程序也有几百条指令，要用一叠纸卡来存
如果不小心摔倒弄撒了
要花上几小时、几天、甚至几周来整理
有个小技巧是  在卡片侧面画对角线
如果弄散了，整理起来会方便很多
用纸卡的最大型程序 \N 是美国空军的 SAGE 防空系统，于 1955 年完成
据称顶峰时期 雇佣了世上 20% 程序员
主控制程序用了 62500 张穿孔纸卡
等同于大约 5MB 的数据
以如今的标准，不值一提
穿孔纸卡不仅可以往计算机放数据
还可以取出数据
程序运行到最后，结果可以输到纸卡上，方式嘛，当然是打孔
然后人可以分析结果，或者再次放进计算机，做进一步计算
谢了 思维泡泡
穿孔纸卡 的亲戚是纸带
基本是一回事，只不过更连续，不是一张张卡.
当然我们还没提硬盘, 只读光盘, DVD, U盘等等
以后我们会讲这些更先进的存储方法
最后，除了插线板和穿孔纸卡
在 1980 年代前，还有一种常见编程方式
面板编程
与其插一堆线到插线板
可以用一大堆开关和按钮，做到一样的效果
面板上有指示灯，代表各种函数的状态和内存中的值
50和60年代的计算机，一般都有这样巨大的控制台
很少有人只用开关来输入一整个程序，但技术上是可行的
早期针对计算机爱好者的家用计算机，大量使用了开关
因为大多数家庭用户负担不起昂贵的外围设备 \N 比如穿孔纸卡读取器
第一款取得商业成功的家用计算机是 Altair 8800
有两种版本可以买: \N 1. 预先装好的整机  \N 2. 需要组装的组件
计算机爱好者 喜欢买组件版
售价极低，在 1975 年卖 400 美元左右
相当于 2017 年的 2000 美元
为了给 8800 编程，你要拨动面板上的开关
输入二进制操作码
然后按 "存储键" 把值存入内存
然后会到下一个内存位置 \N 你可以再次拨开关，写下一个指令
重复这样做
把整个程序都写入内存之后
可以推动开关，回到内存地址0
然后按运行按钮，灯会闪烁
这就是 1975 年的家用计算机, 哇.
不管是插线板、开关或穿孔纸卡
早期编程都是专家活
不管是全职还是技术控，都要非常了解底层硬件
比如 操作码, 寄存器等, 才能写程序
所以编程很难，很烦
哪怕工程师和科学家都无法 完全发挥计算机的能力
我们需要一种更简单方式  告诉计算机要做什么
一种更简单的编程方式
这带领我们到下一个话题 - 编程语言, 我们下集会讲
下周见
本集由 CuriosityStream 赞助播出

之前我们把重点放在硬件 - 组成计算机的物理组件
比如电，电路，寄存器，RAM，ALU，CPU
但在硬件层面编程非常麻烦
所以程序员想要一种更通用的方法编程
- 一种"更软的"媒介
没错，我们要讲软件！
第 8 集我们一步步讲了一个简单程序
第一条指令在内存地址 0：0010 1110
之前说过，前 4 位是操作码
简称 OPCODE
对于这个假设 CPU，0010 代表 LOAD_A 指令
- 把值从内存复制到寄存器 A
后 4 位是内存地址，1110 是十进制的 14
所以这 8 位表达的意思是 \N  "读内存地址 14，放入寄存器 A"
只是用了两种不同语言
可以想成是英语和摩尔斯码的区别
"你好" 和 ".... . .-.. .-.. ---" 是一个意思：你好
只是编码方式不同
英语和摩尔斯码的复杂度也不同
英文有 26 个字母以及各种发音
摩尔斯码只有"点"和"线"
但它们可以传达相同的信息，计算机语言也类似.
计算机能处理二进制，二进制是处理器的"母语"
事实上，它们*只能*理解二进制
这叫"机器语言"或"机器码"
在计算机早期阶段，必须用机器码写程序
具体来讲，会先在纸上用英语写一个"高层次版"
举例："从内存取下一个销售额，
然后加到天、周、年的总和
然后算税"
等等...
这种对程序的高层次描述，叫 "伪代码"
在纸上写好后
用"操作码表"把伪代码转成二进制机器码
翻译完成后，程序可以喂入计算机并运行
你可能猜到了，很快人们就厌烦了
所以在 1940~1950 年代
程序员开发出一种新语言， 更可读 更高层次
每个操作码分配一个简单名字，叫"助记符"
"助记符"后面紧跟数据，形成完整指令
与其用 1 和 0 写代码，程序员可以写"LOAD_A 14"
我们在第 8 集用过这个助记符，因为容易理解得多！
当然，CPU 不知道 LOAD_A 14 是什么
它不能理解文字，只能理解二进制
所以程序员想了一个技巧，写二进制程序来帮忙
它可以读懂文字指令，自动转成二进制指令
这种程序叫
你可能猜到了
汇编器
汇编器读取用"汇编语言"写的程序，然后转成"机器码"
"LOAD_A 14" 是一个汇编指令的例子
随着时间推移，汇编器有越来越多功能，让编程更容易
其中一个功能是自动分析 JUMP 地址
这里有一个第8集用过的例子：
注意, JUMP NEGATIVE 指令跳到地址 5
JUMP 指令跳到地址 2
问题是，如果在程序开头多加一些代码
所有地址都会变
更新程序会很痛苦！
所以汇编器不用固定跳转地址
而是让你插入可跳转的标签
当程序被传入汇编器，汇编器会自己搞定跳转地址
程序员可以专心编程，不用管底层细节
隐藏不必要细节来做更复杂的工作
我们又提升了一层抽象
然而，即使汇编器有这些厉害功能，比如自动跳转
汇编只是修饰了一下机器码
一般来说，一条汇编指令对应一条机器指令
所以汇编码和底层硬件的连接很紧密
汇编器仍然强迫程序员思考  用什么寄存器和内存地址
如果你突然要一个额外的数，可能要改很多代码
让我们进入思考泡泡
葛丽丝·霍普博士 也遇到了这个问题
作为美国海军军官，她是哈佛1号计算机的首批程序员之一
这台机器我们在第 2 集提过
这台巨大机电野兽在 1944 年战时建造完成，帮助盟军作战
程序写在打孔纸带上，放进计算机执行
顺便一说，如果程序里有漏洞
真的就 直接用胶带来补"漏洞"
Mark 1 的指令集非常原始，甚至没有 JUMP 指令
如果代码要跑不止一次
得把带子的两端连起来  做成循环
换句话说，给 Mark 1 编程简直是噩梦！
战后，霍普继续在计算机前沿工作
为了释放电脑的潜力
她设计了一个高级编程语言，叫"算术语言版本 0"
简称"A-0"
汇编与机器指令是一一对应的
但一行高级编程语言  可能会转成几十条二进制指令
为了做到这种复杂转换 \N Hopper 在 1952 年创造了第一个编译器
编译器专门把高级语言 转成低级语言
比如汇编或机器码（CPU 可以直接执行机器码）
谢了 思想泡泡
尽管"使编程更简单"很诱人
但很多人对霍普的点子持怀疑态度
她曾说"我有能用的编译器，但没人愿意用
他们告诉我计算机只能做算术,不能运行程序"
但这个点子是好的
不久，很多人尝试创造新编程语言
- 如今有上百种语言！
可惜的是，没有任何 A-0 的代码遗留下来
所以我们用 Python 举例（一门现代编程语言）
假设我们想相加两个数字，保存结果
记住，如果用汇编代码
我们得从内存取值，和寄存器打交道，以及其他底层细节
但同样的程序可以用 Python 这样写：
不用管寄存器或内存位置
- 编译器会搞定这些细节，不用管底层细节
程序员只需要创建 代表内存地址的抽象，叫"变量"
给变量取名字
现在可以把两个数 存在变量里
这里取名 A 和 B, 实际编程时你可以随便取名
然后相加两个数，把结果存在变量 C
底层操作时，编译器可能把变量 A 存在寄存器 A
但我不需要知道这些！
眼不见心不烦
这是个重要历史里程碑
但 A-0 和之后的版本没有广泛使用
FORTRAN，名字来自 "公式翻译"
这门语言数年后由 IBM 在 1957 年发布
主宰了早期计算机编程
FORTRAN 项目总监 John Backus 说过
"我做的大部分工作都是因为懒
我不喜欢写程序
所以我写这门语言，让编程更容易"
你懂的，典型的"懒人"
（白眼）创造自己的编程语言
平均来说，FORTRAN 写的程序
比等同的手写汇编代码短 20 倍
然后 FORTRAN 编译器会把代码转成机器码
人们怀疑性能是否比得上手写代码
但因为能让程序员写程序更快，所以成了一个更经济的选择
运行速度慢一点点，编程速度大大加快
当时 IBM 在卖计算机
因此最初 FORTRAN 代码只能跑在 IBM 计算机上
1950 年代大多数编程语言和编译器
只能运行在一种计算机上
如果升级电脑
可能要重写所有代码！
因此工业界，学术界，政府的计算机专家 \N 在 1959 年组建了一个联盟
- 数据系统语言委员会，Grace Hopper 担任顾问
开发一种通用编程语言，可以在不同机器上通用
最后诞生了一门高级，易于使用，
"普通面向商业语言"，简称 COBOL
为了兼容不同底层硬件
每个计算架构需要一个 COBOL 编译器
最重​​要的是，这些编译器都可以接收相同 COBOL 代码
不管是什么电脑
这叫"一次编写，到处运行"
如今大多数编程语言都是这样
不必接触 CPU 特有的汇编码和机器码
减小了使用门槛
在高级编程语言出现之前
编程只是计算机专家和爱好者才会做的事
而且通常是主职
但现在，科学家，工程师，医生，经济学家，教师
等等，都可以把计算机用于工作
感谢这些语言
计算机科学从深奥学科 变成了大众化工具
同时，编程的抽象也让计算机专家
现在叫"专业程序员"
制作更复杂的程序
如果用汇编写可能要上百万行
当然，计算机的历史没有在 1959 年结束
编程语言设计的黄金时代才刚刚开始
和硬件一起飞速发展
在 1960 年代，有 ALGOL, LISP 和 BASIC 等语言
70年代有：Pascal，C 和 Smalltalk
80年代有：C++，Objective-C 和 Perl
90年代有：Python，Ruby 和 Java
新千年 Swift, C#, Go 在崛起
不要把 Go 和\N 《冰雪奇缘》的 Let it Go 和游戏 Pokemon Go 弄混
有些语言你可能听起来耳熟 - 很多现在还存在
你现在用的浏览器很可能是 C++ 或 Objective-C 写的
我刚才说的编程语言名字 只是冰山一角
新的编程语言在不断诞生
新语言想用更聪明的抽象
让某些方面更容易或更强大
或利用新技术和新平台带来的优势
让更多人能快速做出美妙的事情
许多人认为编程的"圣杯"是直接用英文
直接对计算机说话，然后它会理解并执行
这种智能系统目前只存在于科幻小说
"2001：太空漫游" 的粉丝可能没什么意见
现在你理解了编程语言,
接下来几集 我们会深入了解
编程语言和用语言写的软件
是怎么做到那些酷事
下周见
（给 Curiosity Stream 打广告）

上集讲到用机器码写程序,
还要处理那么多底层细节  对写大型程序是个巨大障碍
为了脱离底层细节，开发了编程语言
让程序员专心解决问题，不用管硬件细节
今天我们讨论  大多数编程语言都有的基本元素
就像口语一样，编程语言有"语句"
语句表达单个完整思想，比如"我想要茶"或者"在下雨"
用不同词汇可以代表不同含义 \N 比如"我想要茶"变成"我想要独角兽"
但没法把"我想要茶"改成"我想要雨"- 语法毫无意义
规定句子结构的一系列规则 叫语法
英语有语法，所有编程语言也都有语法
a=5 是一个编程语言语句
意思是创建一个叫 a 的变量，把数字 5 放里面.
这叫"赋值语句"，把一个值赋给一个变量
为了表达更复杂的含义，需要更多语句
比如 \Na=5 \N b=10 \Nc=a+b
意思是，变量 a 设为5，变量 b 设为10
把 a 和 b 加起来，把结果 15 放进变量 c
注意，变量名可以随意取
除了 a b c，也可以叫苹果、梨、水果
计算机不在乎你取什么名，只要不重名就行
当然取名最好还是有点意义，方便别人读懂
程序由一个个指令组成，有点像菜谱：
烧水、加面，等10分钟，捞出来就可以吃了
程序也是这样，从第一条语句开始
一句一句运行到结尾
刚才我们只是把两个数字加在一起
无聊
我们来做一款游戏吧
当然，现在这个学习阶段 \N来编写一整个游戏还太早了
所以我们只写一小段一小段的代码
来讲解一些基础知识
假设我们在写一款老派街机游戏：Grace Hopper 拍虫子
阻止虫子飞进计算机造成故障
关卡越高，虫子越多
Grace 要在虫子损坏继电器之前  抓住虫子
好消息是  她有几个备用继电器
开始编写时，我们需要一些值 来保存游戏数据
比如当前关卡数、分数、剩余虫子数、
Grace 还剩几个备用继电器
所以我们要"初始化"变量 \N "初始化"的意思是设置最开始的值.
关卡=1  分数=0  虫子数=5 \N 备用继电器=4   玩家名=Andre
为了做成交互式游戏，程序的执行顺序要更灵活
不只是从上到下执行
因此用 "控制流语句"
控制流语句有好几种，最常见的是 if 语句
可以想成是 "如果 X 为真，那么执行 Y"
用英语举例就是 "如果累了, 就去喝茶"
如果 "累了" 为真，就去喝茶
如果 "累了" 为假，就不喝茶
if 语句就像岔路口
走哪条路  取决于 "表达式" 的真假，
因此这些表达式又叫 "条件语句"
在大多数编程语言中，if 语句看起来像这样：
if [条件], then [一些代码]，结束 if 语句.
比如，if [第一关]，then [分数设为0] \N 因为玩家才刚开始游戏
同时把虫子数设为 1，让游戏简单些
注意, 依赖于 if 条件的代码，要放在 IF 和 END IF 之间
当然，条件表达式 可以改成别的，比如：
"分数 >10" 或者 "虫子数 <1"
if 还可以和 else 结合使用 \N 条件为假会执行 else 里的代码
如果不是第1关，else 里的指令就会被执行
Grace 要抓的虫子数，是当前关卡数 * 3
所以第 2 关有 6 个虫子，第 3 关有 9 个虫子，以此类推
else 中没有改分数，所以 Grace 的分数不会变
这里列了一些热门编程语言  if-then-else 的具体语法
具体语法略有不同，但主体结构一样
if 语句 根据条件执行一次
如果希望根据条件执行多次，需要"条件循环"
比如 while 语句，也叫 "while 循环"
当 while 条件为真，代码会重复执行
不管是哪种编程语言，结构都是这样
假设到达一定分数会冒出一个同事，给 Grace 补充继电器
棒极了！
把继电器补满到最大数 4 个 \N 我们可以用 while 语句来做
来过一遍代码
假设同事入场时， Grace 只剩一个继电器
当执行 while 循环，第一件事是检查条件
继电器数量<4?
继电器数量现在是1，所以是真
进入循环！
碰到这一行：继电器数量=继电器数量+1
看起来有点怪，变量的赋值用到了自己
我们讲下这个
总是从等号右边开始，
"继电器数量+1" 是多少？
当前值是1，所以 1+1=2
结果存到"继电器数量"，覆盖旧的值
所以现在继电器数量是 2
现在到了结尾，跳回开始点
和之前一样，先判断条件，看要不要进入循环
继电器数量<4？
是，继电器数量是2，所以再次进入循环!
3 存入"继电器数量"
回到开头
是!
进入循环
4 存入"继电器数量"
不！
现在条件为假，退出循环，执行后面的代码
while 循环就是这样运作的!
另一种常见的叫 "for 循环"
不判断条件，判断次数，会循环特定次数
看起来像上图
现在放些真正的值进去
上图例子会循环10次，因为设了变量 i
从 1 开始，一直到 10
for 的特点是，每次结束， i 会 +1
当 i 等于10，就知道循环了10次，然后退出.
我们可以用任何数字，10, 42, 10 亿
假设每关结束后  给玩家一些奖励分
奖励分多少取决于 继电器剩余数量
随着难度增加，剩下继电器会越来越难
因此奖励分会根据当前关卡数，指数级增长
我们要写一小段代码来算指数
指数是一个数乘自己，乘特定次数
用循环来实现简直完美!
首先，创建一个叫"奖励分"的新变量，设为 1 （看上图）
然后 for 循环，从 1 到 [当前关卡数]
[奖励分] x [继电器剩余数]，结果存入 [奖励分]
比如继电器数是2，关卡数是3
for 会循环3次，奖励分会乘
继电器数量 x 继电器数量 x 继电器数量
也就是1×2×2×2，奖励分是8，2的3次方
这个指数代码很实用，其他地方可能会用到
如果每次想用就复制粘贴，会很麻烦，每次都要改变量名
如果代码发现问题，要补漏洞时 \N 要把每一个复制黏贴过的地方都找出来改
而且会让代码更难懂
少即是多！
我们想要某种方法，把代码"打包" \N 可以直接使用，得出结果，
不用管内部复杂度.
这又提升了一层抽象！
为了隐藏复杂度
可以把代码打包成 "函数"
也叫 "方法" 或 "子程序"\N（有些编程语言这么叫）
其他地方想用这个函数，直接写函数名就可以了
现在我们把指数代码变成函数.  第一步，取名.
叫什么都行，比如"快乐独角兽"
但因为是算指数,  直接叫"指数"合适一些
还有，与其用特定变量名，比如 "继电器" 和 "关卡数"
用更通用的名字，比如 底数(Base) 和 指数(Exp)
Base 和 Exp 的初始值需要外部传入
剩余代码和之前一样
现在完成了，有函数名和新变量名.
最后, 我们还需要把结果 交给使用这个函数的代码
所以用 RETURN 语句，指明返回什么.
完整版代码是这样
现在可以随意用这个函数
只需要写出名字 然后传入2个数字  就可以了
如果要算 2 的 44 次方，写 exponent(2,44)
结果是 18 万亿左右
幕后原理是，2 和 44 存进 Base 和 Exp
跑循环，然后返回结果
我们来用这个新函数 算奖励分
首先，奖励分初始化为 0
然后用 if 语句，看剩不剩继电器（看上图的 > 0）
如果还剩，用指数函数，传入 [继电器数] 和 [关卡数]
它会算 [继电器数]的[关卡数]次方,  存入奖励分
这段算奖励分的代码，之后可能还会用，也打包成一个函数
没错，这个函数 (CalcBonus) \N 会调用另一个函数 (Exponent)
还有！这个 CalcBonus 函数，可以用在其他更复杂的函数
我们来写一个函数, 每一关结束后都会调用
叫 LevelFinished (关卡结束)
需要传入 [剩余继电器数]  [关卡数] [当前分]
这些数据必须传入.
里面用 CalcBonus 算奖励分，并加进总分
还有，如果当前分 > 游戏最高分
把新高分和玩家名 存起来
现在代码变得蛮"花哨"了
函数调函数调函数
我们写这样一行代码时，复杂度都隐藏起来了
不需要知道内部的循环和变量
只知道结果会像魔术一样返回，总分 53
但是这不是魔术，是抽象的力量
如果你理解了这个例子，就明白了函数的强大之处
和现代编程的核心
比如浏览器这样的复杂程序，用一长串语句来写是不可能的
会有几百万行代码，没人能理解
所以现代软件由上千个函数组成
每个负责不同的事
如今超过100行代码的函数很少见
如果多于 100 行，应该有东西可以拆出来做成一个函数
模块化编程  不仅可以让单个程序员独立制作 App
也让团队协作可以写更大型的程序
不同程序员写不同函数
只需要确保自己的代码工作正常
把所有人的拼起来，整个程序也应该能正常运作！
现实中，程序员不会浪费时间写指数函数这种东西
现代编程语言 有很多预先写好的函数集合，叫 "库"
由专业人员编写，不仅效率高，而且经过了仔细检查
几乎做所有事情都有库，网络、图像、声音
我们之后会讲这些主题.
但在此之前，我们先讲算法
好奇吗？
你应该才是！
下周见

前两集，我们"初尝"了高级编程语言\N （比如 Python 和 Java）
我们讨论了几种语句 - 赋值语句，if 语句，循环语句
以及把代码打包成 "函数"
比如算指数
重要的是，之前写的指数函数 \N 只是无数解决方案的一种
还有其它方案
- 用不同顺序写不同语句 也能得到一样结果
不同的是 "算法"，意思是：解决问题的具体步骤
即使结果一致，有些算法会更好
一般来说，所需步骤越少越好
不过有时我们也会关心其他因素，比如占多少内存
"算法" 一词来自 波斯博识者 阿尔·花拉子密
1000 多年前的代数之父之一
如何想出高效算法 - 是早在计算机出现前就有的问题
诞生了专门研究计算的领域，然后发展成一门现代学科
你猜对了！
计算机科学！
记载最多的算法之一是"排序"
比如给名字、数字排序
排序到处都是
找最便宜的机票
按最新时间排邮件
按姓氏排联系人
-这些都要排序
你可能想"排序看起来不怎么难… 能有几种算法呢?"
答案是超多
计算机科学家花了数十年发明各种排序算法
还起了酷酷的名字，"冒泡排序""意面排序"
我们来试试排序！
试想有一堆机票价格，都飞往  印第安纳波利斯 (美国地名)
数据具体怎么在内存中表示  下周再说
上图的这样一组数据  叫"数组"（Array）
来看看怎么排序
先从一种简单算法开始
先找到最小数，从最上面的 307 开始
因为现在只看了这一个，所以它是最小数
下一个是 239，比 307 小
所以新的最小数变成 239
下一个是 214 ，新的最小数
250 不是，384, 299, 223, 312 都不是
现在扫完了所有数字
214 是最小的
为了升序排列（从小到大排序）
把 214 和最上面的数字，交换位置
好棒! 刚排序了一个数字！
现在重复同样的过程
这次不从最上面开始，从第 2 个数开始
先看到 239，我们当作是 "最小数"
扫描剩下的部分，发现 223 最小
所以把它和第 2 位交换
重复这个过程，从第 3 位数字开始
让 239 和 307 互换位置
重复直到最后一个数字
瞧，数字排好了，可以买机票了！
刚刚这种方法，或者说算法，
叫 选择排序 - 非常基础的一种算法
以下是"伪代码"
这个函数可以排序8个, 80个或8千万个数字
函数写好了就可以重复使用
这里用循环 遍历数组
每个数组位置都跑一遍循环，找最小数然后互换位置
可以在代码中看到这一点 \N （一个 for 循环套另一个 for 循环）
这意味着，大致来说，如果要排 N 个东西，要循环 N 次，
每次循环中再循环 N 次，共 N*N,  或 N
算法的 输入大小 和 运行步骤 之间的关系
叫算法的 复杂度
表示运行速度的量级
计算机科学家们把算法复杂度叫 - 没开玩笑
大 O 表示法
算法复杂度 O(N  ) 效率不高
前面的例子有 8 个元素（n=8）, 8  = 64
如果 8 个变 80 个
运行时间变成 80  = 6400
虽然大小只增长了 10 倍（8 到 80）
但运行时间增加了 100 倍！（64 到 6400 ）
随着数组增大，对效率的影响会越来越大
这对大公司来说是个问题，比如 谷歌
要对几十亿条信息排序
作为未来的计算机科学家你可能会问：有没有更高效的排序算法？
回到未排序的数组
试另一个算法 "归并排序"
第一件事是检查数组大小是否 > 1
如果是，就把数组分成两半
因为数组大小是 8，所以分成两个数组，大小是 4
但依然大于 1，所以再分成大小是 2 的数组
最后变成 8 个数组，每个大小为 1
现在可以"归并"了，"归并排序"因此得名
从前两个数组开始，读第一个（也是唯一一个）值
307 和 239
239 更小，所以放前面
剩下的唯一数字是 307 ，所以放第二位
成功合并了两个数组
重复这个过程，按序排列
然后再归并一次
同样，取前两个数组，比较第一个数
239 和 214
214 更小，放前面
再看两个数组里的第一个数：239 和 250
239 更小，所以放下一位
看剩下两个数：307 和 250
250 更小，所以放下一位
最后剩下 307 ，所以放最后
每次都以 2 个数组开始
然后合并成更大的有序数组
我们把刚隐藏起来的，下面的数组也这样做
现在有两个大小是 4 的有序数组
就像之前，比较两个数组的第一个数，取最小数
重复这个过程，直到完成
就排好了！
但坏消息是：无论排多少次
你还是得付 214 美元到 印第安纳波利斯
总之，"归并排序"的算法复杂度是 O(n * log n)
n 是需要 比较+合并 的次数
和数组大小成正比
log N 是合并步骤的次数
例子中把大小是 8 的数组，分成四个数组
然后分成 2 个，最后分成 1 个
分了 3 次
重复切成两半，和数量成对数关系
相信我！
如果数组大小变成 16 - 之前的两倍
也只要多分割 1 次
因为 Log   16=4
即使扩大一千倍
从8到8000，分割次数也不会增大多少
13 比 3 只是4倍多一点
然而排序的元素多得多
因此"归并排序"比"选择排序"更有效率
这下我收藏的陶瓷猫  可以更快排序了！
有好几十种排序算法，但没时间讲
所以我们来谈一个经典算法问题：
图搜索
"图" 是用线连起来的一堆 "节点"
可以想成地图，每个节点是一个城市，线是公路
一个城市到另一个城市，花的时间不同
可以用 成本(cost) 或 权重(weight) 来代称
代表要几个星期
假设想找"高庭"到"凛冬城"的最快路线
最简单的方法是尝试每一条路
计算总成本
这是蛮力方法
假设用蛮力方法 来排序数组
尝试每一种组合，看是否排好序
这样的时间复杂度是 O(n!)
n 是节点数，n! 是 n 乘 n-1 乘 n-2... 一直到 1
比 O(n  ) 还糟糕
我们可以更聪明些！
图搜索问题的经典算法  发明者是
理论计算机科学的伟人 Edsger Dijkstra
所以叫 "Dijkstra 算法"
从"高庭"开始，此时成本为0，把0标在节点里
其他城市标成问号，因为不知道成本多少
Dijkstra 算法总是从成本最低的节点开始
目前只知道一个节点 "高庭", 所以从这里开始
跑到所有相邻节点，记录成本
完成了一轮算法
但还没到"凛冬城"
所以再跑一次 Dijkstra 算法
"高庭" 已经知道了
下一个成本最低的节点，是 "君临城"
就像之前，记录所有相邻节点的成本
到"三叉戟河"的成本是 5
然而我们想记录的是，从"高庭"到这里的成本
所以"三叉戟河"的总成本是 8+5=13周
现在走另一条路到"奔流城"
成本高达 25 ，总成本 33
但 "奔流城" 中最低成本是 10
所以无视新数字，保留之前的成本 10
现在看了"君临城"的每一条路，还没到"凛冬城" 所以继续.
下一个成本最低的节点，是"奔流城"，要 10 周
先看 "三叉戟河" 成本： 10+2=12
比之前的 13 好一点
所以更新 "三叉戟河" 为 12
"奔流城"到"派克城"成本是 3
10+3=13，之前是14
所以更新 "派克城" 为 13
"奔流城"出发的所有路径都走遍了， \N 你猜对了，再跑一次 Dijkstra 算法
下一个成本最低的节点，是"三叉戟河"
从"三叉戟河"出发，唯一没看过的路，通往"凛冬城"！
成本是 10
加"三叉戟河"的成本 12
总成本 22
再看最后一条路，"派克城"到"凛冬城"，成本 31
现在知道了最低成本路线，让军队最快到达,
还绕过了"君临城"！
Dijkstra 算法的原始版本，构思于 1956 年
算法复杂度是 O(n  )
前面说过这个效率不够好
意味着输入不能很大
比如美国的完整路线图
幸运的是，Dijkstra 算法几年后得到改进
变成 O(n log n + l)
n 是节点数，l 是多少条线
虽然看起来更复杂
但实际更快一些
用之前的例子，可以证明更快 \N （6 个节点 9 条线）
从 36 减少到 14 左右
就像排序，图搜索算法也有很多，有不同优缺点
每次用谷歌地图时
类似 Dijkstra 的算法就在服务器上运行，找最佳路线
算法无处不在
现代世界离不开它们
这集只触及了算法的冰山一角
但成为计算机科学家的核心
是根据情况合理决定 用现有算法 还是自己写新算法
希望这集的小例子能让你体会到这点
下周见

上集讲了一些经典算法
比如给数组排序，找图的最短路径
而上集没讲的是
算法处理的数据  存在内存里的格式是什么
你肯定不想数据像 John Green 的大学宿舍一样乱 \N 到处都是食物，衣服和纸
我们希望数据是结构化的，方便读取
因此计算机科学家发明了 "数据结构"！
上集已经介绍了一种基本数据结构：
数组（Array）\N 也叫列表（list）或向量（Vector）（在其它编程语言里）
数组的值一个个连续存在内存里
所以不像之前，一个变量里只存一个值（比如 j = 5）
我们可以把多个值存在数组变量里
为了拿出数组中某个值，我们要指定一个下标（index）
大多数编程语言里，数组下标都从 0 开始
用方括号 [ ] 代表访问数组
如果想相加数组 J 的第一个和第三个元素
把结果存在变量 a，可以写上图这样一行代码
数组存在内存里的方式  十分易懂
为了简单，假设编译器从内存地址 1000 开始存数组
数组有7个数字，像上图一样按顺序存.
写 j[0]，会去内存地址 1000
加 0 个偏移，得到地址 1000，拿值：5
如果写 j[5]，会去内存地址 1000
加 5 个偏移，得到地址 1005，拿值： 4
很容易混淆 "数组中第 5 个数" 和 "数组下标为 5 的数"
它们不是一回事
记住，下标 5 其实是数组中第 6 个数
因为下标是从 0 开始算的
数组的用途广泛
所以几乎所有编程语言  都自带了很多函数来处理数组
举例，数组排序函数很常见
只需要传入数组，就会返回排序后的数组
不需要写排序算法
数组的亲戚是 字符串 (string)
其实就是字母,数字,标点符号等  组成的数组
第 4 集讨论过计算机怎么存储字符
写代码时 用引号括起来就行了  \N j = "STAN ROCKS"
虽然长的不像数组，但的确是数组
幕后看起来像这样
注意，字符串在内存里以 0 结尾
不是"字符0"，是"二进制值0" \N 这叫字符"null"，表示字符串结尾
这个字符非常重要，如果调用 print 函数
print 在屏幕上输出字符串
会从开始位置，逐个显示到屏幕
但得知道什么时候停下来！
否则会把内存里所有东西 都显示出来
0 告诉函数何时停下
因为计算机经常处理字符串，所以有很多函数专门处理字符串
比如连接字符串的 strcat
strcat 接收两个字符串，把第二个放到第一个结尾.
我们可以用数组做一维列表
但有时想操作二维数据
比如电子表格，或屏幕上的像素
那么需要 矩阵（Matrix）
可以把矩阵看成  数组的数组！
一个 3x3 矩阵就是一个长度为3的数组 \N 数组里每个元素都是一个长度为3的数组
可以这样初始化.
内存里是这样排列的
为了拿一个值，需要两个下标，比如 j[2][1]
告诉计算机在找数组 2 里，位置是 1 的元素
得到数字 12
矩阵酷的地方是，不止能做 3x3 的矩阵
任何维度都行
可以做一个5维矩阵，然后这样访问 \N a = j[2][0][18][18][3]
现在你知道了  怎么读一个 5 维矩阵
快去告诉你的朋友！
目前我们只存过单个数字/字符，存进数组或矩阵
但有时, 把几个有关系的变量存在一起, 会很有用
比如银行账户号和余额
多个变量打包在一起叫  结构体 (Struct)
现在多个不同类型数据，可以放在一起
甚至可以做一个数组，里面放很多结构体
这些数据在内存里  会自动打包在一起
如果写 j[0]，能拿到  j[0] 里的结构体
然后拿银行账户和余额
存结构体的数组，和其它数组一样
创建时就有固定大小，不能动态增加大小
还有，数组在内存中 按顺序存储
在中间插入一个值很困难
但结构体可以创造更复杂的数据结构，消除这些限制
我们来看一个结构体，叫 节点(node)
它存一个变量 \N 一个指针（pointer）
"指针" 是一种特殊变量，指向一个内存地址，因此得名.
用 节点 可以做 链表（linked list）
链表是一种灵活数据结构，能存很多个 节点 (node)
灵活性是通过每个节点 指向 下一个节点实现的
假设有三个节点，在内存地址 1000，1002, 1008
隔开的原因 可能是创建时间不同
它们之间有其他数据
可以看到第一个节点，值是 7，指向地址 1008
代表下一个节点，位于内存地址 1008
现在来到下一个节点
值是 112，指向地址 1002
如果跟着它，会看到一个值为 14 的节点
这个节点  指回地址 1000，也就是第一个节点
这叫 循环链表
但链表也可以是非循环的，最后一个指针是 0
"null"，代表链表尽头
当程序员用链表时
很少看指针具体指向哪里
而是用链表的抽象模型，就像上图
更容易看懂
数组大小需要预先定好
链表大小可以动态增减
可以创建一个新节点，通过改变指针值，把新节点插入链表
链表也很容易重新排序，两端缩减，分割，倒序等
超方便！
链表也适合上集的排序算法
因为灵活，很多复杂数据结构 都用链表
最出名的是 队列（queue）和 栈（stack）
"队列" 就像邮局排队，谁先来就排前面
虽然你可能只想买邮票，而前面的人要寄 23 个包裹
这叫 先进先出（FIFO）
我指队列，不是指那 23 个包裹
想象有个指针叫"邮局队列"，指向链表第一个节点
第一个节点是 Hank，服务完 Hank 之后 \N 读取 Hank 的指针
把"邮局队列"指向下一个人
这样就把 Hank "出队"（dequeue）了
如果我们想把某人"入队"（enqueue） \N 意思是加到队列里
要遍历整个链表到结尾
然后把结尾的指针，指向新人（Nick）
只要稍作修改，就能用链表做 栈，\N 栈是后进先出(LIFO)
可以把"栈"想成一堆松饼
做好一个新松饼，就堆在之前上面
吃的时候，是从最上面开始
美味！
栈就不叫"入队""出队"了
叫"入栈"（push） "出栈"（pop）
对，这些是正确术语！
如果节点改一下，改成 2 个指针
就能做 树（tree）
很多算法用了 "树" 这种数据结构
同样，程序员很少看指针的具体值
而是把"树"抽象成这样：最高的节点叫"根节点"（root）
"根节点"下的所有节点   都叫"子节点"（children）
任何子节点的直属上层节点，叫"母节点"（parent node）
这个例子能说明 托马斯·杰斐逊 是 阿龙·伯尔 的父亲吗？
我让你们的同人文来决定
没有任何"子节点"的节点
也就是"树"结束的地方，叫"叶节点"（leaf）
在这里的例子中，节点最多只可以有 2 个子节点
因此叫 二叉树（binary tree）
但你可以随便改，弄成 3个，4个，或更多
甚至节点 可以用链表存所有子节点
"树"的一个重要性质是（不管现实中还是数据结构中）
"根"到"叶"是 单向 的
如果根连到叶，叶连到根  就很奇怪
如果数据随意连接，包括循环
可以用"图"表示
还记得上集用路连接城市的"图"吗？
这种结构  可以用有多个指针的节点表示
因此没有 根 叶 子节点 父节点 这些概念
可以随意指向！
以上概述了计算机科学中，最主要的一些数据结构
这些基本结构之上，程序员做了各种新变体，有不同性质.
比如"红黑树"和"堆"，我们没时间讲
不同数据结构适用于不同场景
选择正确数据结构会让工作更简单
所以花时间考虑用什么数据结构是值得的
幸运的是，大多数编程语言自带了预先做好的数据结构
比如，C++有"标准模板库"，Java有"Java 类库"
程序员不用浪费时间从零写
时间可以花在更有趣的事情
又提升了一层抽象！
下周见！

前几集我们聊了基础，比如函数，算法和数据结构
今天，我们来看一位对计算机理论 贡献巨大的人
计算机科学之父
长得不怎么像 本尼 的 阿兰·图灵
阿兰·马蒂森·图灵 于 1921 年出生在伦敦，\N 从小就表现出惊人数学和科学能力
他对计算机科学的建树始于 1935 年
当时他是剑桥国王学院的硕士生
他开始解决德国数学家 大卫·希尔伯特 提出的问题
叫 Entscheidungsproblem （德语）
即"可判定性问题":
是否存在一种算法，输入正式逻辑语句 \N 输出准确的"是"或"否"答案？
如果这样的算法存在， \N 可以回答比如 "是否有一个数大于所有数"
不, 没有.  我们知道答案
但有很多其他数学问题，我们想知道答案
所以如果这种算法存在,  我们想知道
美国数学家 阿隆佐·丘奇  \N 于 1935年 首先提出解决方法
开发了一个叫"Lambda 算子"的数学表达系统
证明了这样的算法不存在
虽然"Lambda 算子"能表示任何计算
但它使用的数学技巧 难以理解和使用
同时在大西洋另一边
阿兰·图灵 想出了自己的办法来解决"可判定性问题"
提出了一种假想的计算机，现在叫"图灵机"
图灵机提供了简单又强大的数学计算模型
虽然用的数学不一样
但图灵机的计算能力和 Lambda 算子一样
同时因为图灵机更简单，所以在新兴的计算机领域更受欢迎
因为它如此简单，我现在就给你解释
图灵机是一台理论计算设备
还有一个状态变量，保存当前状态
还有一组规则，描述机器做什么
规则是根据 当前状态+读写头看到的符号，决定机器做什么
结果可能是在纸带写入一个符号
或改变状态，或把读写头移动一格
或执行这些动作的组合
为了更好理解，讲个简单例子：
让图灵机读一个以零结尾的字符串
并计算 1 的出现次数  是不是偶数
如果是, 在纸带上写一个 1
如果不是，在纸带上写一个 0
首先要定义"图灵机"的规则
如果当前状态是"偶数",  当前符号是1
那么把状态更新为"奇数"，把读写头向右移动
如果当前状态为偶数，当前符号是 0
意味着到了字符串结尾
那么在纸带上写一个 1，并且把状态改成 停机(halt)
状态改为"停机" 是因为图灵机已完成计算
但我们还需要 2 条规则，来处理状态为奇数的情况
一条处理 奇数 + 纸带是 0 的情况 \N 一条处理 奇数 + 纸带是 1 的情况
最后，要决定机器的初始状态，这里定成"偶数"
定义好了 起始状态+规则
就像写好了程序，现在可以输入了
假设把"1 1 0"放在纸带上，有两个 1，是偶数
如果"偶数"对你是新知识 \N 也许我们该开一门【十分钟速成课：数学】
注意，规则只让 读写头 向右移动
其他部分无关紧要，为了简单所以留空
"图灵机"准备好了，开始吧
机器起始状态为"偶数"，看到的第一个数是 1
符合最上面那条规则，所以执行对应的步骤
把状态更新到"奇数"， 读写头向右移动一格
然后又看到 1, 但机器状态是"奇数"，所以执行第三条规则
使机器状态变回"偶数"，读写头向右移动一格
现在看到 0，并且机器状态是 偶数，所以执行第二条规则
在纸带上写 1，表示"真" 的确有偶数个 1
然后机器停机
这就是图灵机的原理，很简单对吧？
你可能想知道 有什么大不了的
图灵证明了这个简单假想机器
如果有足够时间和内存，可以执行任何计算
它是一台通用计算机
刚才的程序就是个简单例子
只要有足够的规则，状态和纸带  可以创造任何东西
浏览器, 魔兽世界 任何东西！
当然 这样做效率很低，但理论上可行.
所以图灵机是很强大的计算模型
事实上，就可计算和不可计算而言
没有计算机比图灵机更强大
和图灵机一样强大的，叫 "图灵完备"
每个现代计算系统 比如笔记本电脑，智能手机
甚至微波炉和恒温器内部的小电脑
都是"图灵完备"的
为了回答可判定性问题
他把图灵机用于一个有趣计算问题：
"停机问题"
简单说就是
"给定图灵机描述和输入纸带，是否有算法可以确定
机器会永远算下去还是到某一点会停机？
我们知道输入 1 1 0，图灵机会停机
因为刚做过这个例子，它最后停机了
但如果是更复杂的问题呢？
有没有办法在不执行的情况，弄清会不会停机？
一些程序可能要运行好几年
所以在运行前知道 会不会出结果很有用
否则就要一直等啊等，忧虑到底会不会出结果
当几十年后变老了，再按强制结束
好悲伤！
图灵通过一个巧妙逻辑矛盾 \N 证明了停机问题是无法解决的
我们来看看他的推理
想象有一个假想图灵机，\N 输入：问题的描述 + 纸带的数据
输出 Yes 代表会"停机"，输出 No 代表不会
我要给这台机器一个有趣的名字叫 H， \N 来自"停机"的第一个字母
不用担心它具体怎么工作
假设这样的机器存在就好  毕竟重点是推论
图灵推理说： 如果有个程序， H 无法判断是否会"停机"
意味着"停机问题"无法解决
为了找到这样的程序，图灵用 H 设计了另一个图灵机
如果 H 说程序会"停机"，那么新机器会永远运行（即不会停机）
如果 H 的结果为 No，代表不会停机
那么让新机器输出 No，然后"停机"
实质上是一台和 H 输出相反的机器
如果程序不停机，就停机
如果程序停机，就永远运行下去
我们还需要在机器前面加一个分离器
让机器只接收一个输入，\N 这个输入既是程序，也是输入
我们把这台新机器叫 异魔
目前为止，这个机器不难理解
但接下来马上会变复杂，会有点难懂
如果把 异魔 的描述，作为本身的输入会怎样
意味着在问 H ，当异魔的输入是自己时会怎样
但如果 H 说异魔会停机
那么异魔会进入无限循环，因此不会停机
如果 H 说异魔不会停机，那么异魔会输出 No 然后停机
所以 H 不能正确判定 停机问题
因为没有答案
这是一个悖论
意味着"停机问题"不能用图灵机解决
还记得刚刚说： 图灵证明了图灵机可以实现任何计算
"停机问题"证明了，不是所有问题都能用计算解决
哇，好难理解
我都可能要再看一遍
长话短说，丘奇和图灵证明了计算机的能力有极限
无论有多少时间或内存，有些问题是计算机无法解决的
丘奇和图灵证明了计算是有极限的，
起步了可计算性理论，现在叫"丘奇-图灵论题"
当时是1936年，图灵只有24岁
他的职业生涯才刚刚开始
从1936年到1938年 \N 在丘奇指导下，他在普林斯顿拿到博士学位
毕业后回到剑桥
1939年后不久，英国卷入第二次世界大战
图灵的才能很快被投入战争
事实上，在战争开始前一年
他已经在英国政府的 密码破译学校兼职
位于"布莱切利园"的一个密码破译组织
他的工作内容之一是破解德国的通信加密
特别是"英格玛机"加密的信息
简单说，英格玛机会加密明文
如果输入字母 H-E-L-L-O
机器输出 X-W-D-B-J
这个过程叫"加密"
文字不是随便打乱的
加密由"英格玛机"顶部的齿轮组合决定
每个齿轮有26个可能位置
机器前面还有插板，可以将两个字母互换
总共有上十亿种可能
如果你有"英格玛机"，并且知道正确的齿轮和插头设置
输入X-W-D-B-J，机器会输出 hello
解密了这条消息
当然，德军不会把机器设置发到微博上
盟军必须自己破译密码
有数十亿种组合，根本没法手工尝试所有组合
幸运的是，英格玛机和操作员不是完美的
一个大缺陷是：字母加密后绝不会是自己
H 加密后绝对不是 H
图灵接着之前波兰破译专家的成果继续工作
设计了一个机电计算机，叫 Bombe
利用了这个缺陷，它对加密消息尝试多种组合
如果发现字母解密后和原先一样
我们知道英格玛机决不会这么做
这个组合会被跳过，接着试另一个组合
Bombe 大幅减少了搜索量
让破译人员把精力花在更有可能的组合
比如在解码文本中找常见的德语单词
德国人时不时会怀疑有人在破解，然后升级英格玛机
比如加一个齿轮，创造更多可能组合
他们甚至还做了全新的加密机
整个战争期间，图灵和同事在布莱切利园努力破解加密
解密得到的德国情报，为盟军赢得了很多优势
有些史学家认为他们把战争减短了好几年
战后，图灵回到学术界 \N 为许多早期计算机工作做出贡献
比如曼彻斯特 1 号，一个早期有影响力的存储程序计算机
但他最有名的战后贡献是"人工智能"
这个领域很新，直到1956年才有名字
这个话题很大，以后再谈（第34集）
1950 年，图灵设想了未来的计算机
拥有和人类一样的智力，或至少难以区分
图灵提出 \N 如果计算机能欺骗人类相信它是人类，才算是智能
这成了智能测试的基础，如今叫"图灵测试"
想像你在和两个人沟通 \N 不用嘴或面对面，而是来回发消息
可以问任何问题，然后会收到回答
但其中一个是计算机
如果你分不出哪个是人类，哪个是计算机
那么计算机就通过了图灵测试
这个测试的现代版叫
"公开全自动图灵测试，用于区分计算机和人类"
简称"验证码"
防止机器人发垃圾信息等
我承认 有时我都认不出那些扭曲的东西是什么字
这难道意味着我是计算机？
通常这个系列我们不会深入历史人物的个人生活
但图灵与悲剧密不可分
所以他的故事值得一提
图灵那个时代，同性恋是违法的，英国和大部分国家都是
1952 年调查他家的入室盗窃案时，向当局暴露了他的性取向
被起诉 "行为严重不检点"
图灵被定罪，有2个选择： \N 1. 入狱  2. 接受激素来压制性欲
他选了后者，部分原因是为了继续学术工作
但药物改变了他的情绪和性格
虽然确切情况永远无法得知
图灵于1954年服毒自尽，年仅41岁
由于图灵对计算机科学贡献巨大，许多东西以他命名
其中最出名的是"图灵奖"
计算机领域的最高奖项
相当于物理, 化学等其它领域的诺贝尔奖
虽然英年早逝，但图灵激励了第一代计算机科学家
而且为如今便利的数字时代 做出了重要基石性工作
我们下周见

之前花了很多时间讲排序
也写了些 10 行左右的排序代码
对1个程序员来说很容易写
而且代码很短，不必用专门工具
- 记事本就够了
真的！
但排序算法很少会是独立程序 \N 更可能是大项目的一小部分
举个例子，微软的 Office 大约有 4000 万代码
4000 万！
太多了，一个人不可能做到
为了写大型程序，程序员用各种工具和方法
所有这些形成了"软件工程"学科
- 这个词由工程师 Margaret Hamilton 创造
她帮助 NASA 在阿波罗计划中避免了严重问题
她曾说过：
"有点像牙根管治疗：你总是拖到最后才做 \N 但有些事可以预先做好
有点像预防性体检, 只不过是预防软件出错"
第 12 集提过
把大项目分解成小函数  可以让多人同时工作
不用关心整个项目，关心自己的函数就好了
如果你的任务是写排序算法
你只需要确保高效和正确就可以了
然而把代码打包成函数 依然不够
如果只是这样，微软 Office 会有几十万个函数
虽然比 4000 万行代码要好一些，但还是太多了
解决办法是：把函数打包成层级. \N 把相关代码都放在一起，打包成对象（objects）
例如，汽车软件中 可能有几个和定速巡航有关的函数
比如 设定速度，逐渐加速减速，停止定速巡航
因为这些函数都相关，可以包装成一个"定速巡航对象"
但不止如此，我们还可以做更多
"定速巡航"只是引擎软件的一部分
可能还有 "火花塞点火" "燃油泵" 和 "散热器"
我们可以做一个"引擎对象" 来包括所有"子"对象
除了子对象，"引擎对象"可能有自己的函数
比如 开关引擎
它也会有自己的变量，比如汽车行驶了多少英里
总的来说，对象可以包其它对象，函数和变量
当然，"引擎对象"只是"汽车对象"的一部分
还有传动装置，车轮，门，窗等
作为程序员，如果想设"定速巡航"
要一层层向下
从最外面的对象往里找
最后找到想执行的函数：
编程语言经常用类似这样的语法
把函数打包成对象的思想叫 "面向对象编程"
这种思想和之前类似
通过封装组件，隐藏复杂度
之前把晶体管  打包成了逻辑门
现在软件也这样做
又提升了一层抽象！
把大型软件（如汽车软件）\N 拆成一个个更小单元，适合团队合作
一个团队负责定速巡航系统
团队里的一位程序员负责其中一些函数
类似建摩天大楼
有电工装电线
管道工配管
焊接工焊接
油漆工涂油漆
还有成百上千人做其他事情
在不同岗位同时工作，各尽其能
直到整栋楼完成
回到定速巡航的例子
定速巡航 要用到引擎的其它函数，来保持车速
定速巡航 团队不负责这些代码，另一个团队负责
因为是其他团队的代码，
定速巡航 团队需要文档 帮助理解代码都做什么
以及定义好的 "程序编程接口" -简称 API
API 帮助不同程序员合作 \N 不用知道具体细节，只要知道怎么使用就行了
例如"点火控制"对象中，可能有"设置发动机转数"函数
"检查火花塞电压"函数
"点燃单个火花塞"函数
"设置发动机转速"非常有用
"定速巡航"团队要用到这个函数
但他们对点火系统不怎么了解
让他们调用"点燃单个火花塞"函数，不是好主意
引擎可能会炸！
可能啦
API 控制哪些函数和数据让外部访问 \N 哪些仅供内部
"面向对象"的编程语言 \N 可以指定函数是 public 或 private，来设置权限
如果函数标记成 private
意味着 只有同一个对象内的其他函数能调用它
在这个例子里，只有内部函数比如 setRPM
才能调用 fireSparkplug 函数
而 setRPM 函数是 public  \N 所以其它对象可以调用它，比如 定速巡航
"面向对象编程"的核心是 \N 隐藏复杂度，选择性的公布功能
"面向对象"的核心是 \N 隐藏复杂度，选择性的公布功能
因为做大型项目很有效，所以广受欢迎
计算机上几乎所有软件，游戏机里几乎所有游戏
都是 "面向对象" 编程语言写的
比如 C++, C#, Objective-C 等
其他流行 OO 语言，你可能听过 Python 和 Java
有一点很重要：代码在编译前就只是文字而已
前面提过，你可以用记事本或任何文字处理器
有人确实这样做
但一般来说，现代软件开发者  会用专门的工具来写代码
工具里集成了很多有用功能\N 帮助写代码，整理，编译和测代码
因为集成了所有东西
因此叫 集成开发环境，简称 IDE
所有 IDE 都有写代码的界面
还带一些有用功能，比如代码高亮，来提高可读性
许多 IDE 提供实时检查，比如拼写
大型项目有很多源代码文件
IDE 帮助开发者整理和看代码
很多 IDE 还可以直接编译和运行代码
如果程序崩了，因为你还没写完呢
IDE 可以定位到出错代码
还会提供信息 帮你解决问题
这叫 调试（debug）
调试很重要
大多数程序员会花 70％~80％ 时间调试，而不是在写代码
好工具能极大帮助程序员防止和解决错误
很多开发者只用一款 IDE
但承认吧，VIM 才是最棒的编辑器
如果你知道怎么退出的话
除了写代码和调试
程序员工作的另一个重要部分是  给代码写文档
文档一般放在一个叫 README 的文件里
告诉其他程序员，看代码前先看这个文件
文档也可以直接写成"注释"，放在源代码里
注释是标记过的一段文字
编译代码时  注释会被忽略
注释存在的唯一作用 \N 就是帮助开发者理解代码
好文档能帮助开发者 \N 几个月后理解自己的代码，对其他人也很重要
我想花一秒 再强调一下注释很重要
最糟糕的就是拿到一堆代码，没有任何注释和文档
结果得逐行读代码，理解到底干嘛的
我是认真的
别做那种人
文档还可以提高复用性
与其让程序员一遍遍写同样的东西
可以直接用别人写好的来解决问题
读文档看怎么用就行，不用读代码
"读文档啊"
除了 IDE，还有一个重要软件帮助团队协作
源代码管理
也叫"版本控制"
苹果或微软这样的大型软件公司
会把代码放到一个中心服务器上
叫"代码仓库"
程序员想改一段代码时
可以 check out
有点像从图书馆借书
一般这种操作，可以直接在 IDE 内完成
然后开发者在自己的电脑上编辑代码
加新功能，测试
如果代码没问题了，所有测试通过了
可以把代码放回去
这叫  提交 (commit)
当代码被 check out，而且可能被改过了
其他开发者不会动这段代码
防止代码冲突和重复劳动
这样多名程序员可以同时写代码，建立庞大的系统
重要的是，你不希望提交的代码里有问题 \N 因为其他人可能用到了这些代码
导致他们的代码崩溃，造成困惑而且浪费时间
代码的主版本 (master)
应该总是编译正常，尽可能少 bug
但有时 bug 还是会出现
幸运的是，源代码管理可以跟踪所有变化
如果发现 bug
全部或部分代码，可以"回滚"到之前的稳定版
"源代码管理" 也记录了谁改了什么代码
所以同事可以给你发 讨厌的
我是说"有帮助的" 邮件给写代码的人
写代码和测代码密不可分
测试一般由个人或小团队完成
测试可以统称 "质量保证测试"，简称 QA
严格测试软件的方方面面
模拟各种可能情况，看软件会不会出错
基本上就是找 bug
解决大大小小的错误需要很多工作
但对确保软件质量至关重要
让软件在各种情况下按预期运行
你可能听过 "beta 版" 软件
意思是软件接近完成
但不是 100％ 完全测试过
公司有时会向公众发布 beta 版，以帮助发现问题
用户就像免费的 QA 团队
你听过比较少的是 \N beta 版之前的版本：alpha 版本
alpha 版一般很粗糙，错误很多，\N 经常只在公司内部测试
以上只是软件工程师用的工具和技巧的冰山一角
它们帮助软件工程师制作令人喜爱的软件
如 YouTube，GTA5 和 PPT 等等
如你所料
这些代码要强大的处理能力 才能高速速度运行
所以下集讨论，计算机怎么发展到如今这么快
到时见
本集由 Curiosity Stream 赞助播出

过去 6 集我们聊了软件 \N 从早期编程方式到现代软件工程
在大概50年里  软件从纸带打孔  \N 变成面向对象编程语言  在集成开发环境中写程序
但如果没有硬件的大幅度进步 \N 软件是不可能做到这些的
为了体会硬件性能的爆炸性增长 \N 我们要回到电子计算机的诞生年代
大约 1940年代~1960年代中期这段时间里 \N 计算机都由独立部件组成
叫"分立元件" \N 然后不同组件再用线连在一起
举例, ENIAC 有1万7千多个真空管, 7万个电阻
1万个电容器, 7千个二极管, 5百万个手工焊点
如果想提升性能，就要加更多部件 \N 这导致更多电线，更复杂
这个问题叫 "数字暴政''
1950 年代中期，晶体管开始商业化（市场上买得到） \N 开始用在计算机里
晶体管比电子管 更小更快更可靠
但晶体管依然是分立元件
1959年，IBM 把 709 计算机从原本的电子管 \N 全部换成晶体管
诞生的新机器 IBM 7090  \N 速度快 6 倍，价格只有一半
晶体管标志着"计算 2.0 时代"的到来
虽然更快更小 \N 但晶体管的出现 还是没有解决"数字暴政"的问题
有几十万个独立元件的计算机不但难设计 \N 而且难生产
1960 年代，这个问题的严重性达到顶点 \N 电脑内部常常一大堆电线缠绕在一起
看看这个 1965 年 PDP-8 计算机的内部
解决办法是引入一层新抽象，封装复杂性
突破性进展在 1958 年 \N 当时 Jack Killby 在德州仪器工作
演示了一个电子部件：\N "电路的所有组件都集成在一起"
简单说就是：\N 与其把多个独立部件用电线连起来，拼装出计算机
我们把多个组件包在一起，变成一个新的独立组件
这就是 集成电路（IC）
几个月后，在1959年 Robert Noyce 的仙童半导体 \N 让集成电路变为现实
Kilby 用锗来做集成电路，锗很稀少而且不稳定
仙童半导体公司用硅 \N 硅的蕴藏量丰富，占地壳四分之一
也更稳定可靠
所以 Noyce 被公认为现代集成电路之父
开创了电子时代，创造了硅谷（仙童公司所在地）
之后有很多半导体企业都出现在硅谷
起初，一个 IC 只有几个晶体管 \N 例如这块早期样品，由西屋公司制造
即使只有几个晶体管 \N 也可以把简单电路，第 3 集的逻辑门，能封装成单独组件
IC 就像电脑工程师的乐高积木 \N 可以组合出无数种设计
但最终还是需要连起来， \N 创造更大更复杂的电路，比如整个计算机
所以工程师们再度创新：印刷电路板，简称 PCB
PCB 可以大规模生产，无需焊接或用一大堆线. \N 它通过蚀刻金属线的方式，把零件连接到一起
把 PCB 和 IC 结合使用 \N 可以大幅减少独立组件和电线，但做到相同的功能
而且更小，更便宜，更可靠.  三赢！
许多早期 IC 都是把很小的分立元件 \N 封装成一个独立单元，例如这块 1964 年的IBM样品
不过，即使组件很小 \N 塞5个以上的晶体管还是很困难
为了实现更复杂的设计，需要全新的制作工艺 \N "光刻"登场！
简单说就是 \N用光把复杂图案印到材料上，比如半导体
它只有几个基础操作，但可以制作出复杂电路
下面用一个简单例子，来做一片这个！
我们从一片硅开始，叫"晶圆" \N 长得像薄饼干一样
美味！
我们在第 2 集讨论过 \N 硅很特别，它是半导体
它有时导电，有时不导电 \N 我们可以控制导电时机
所以硅是做晶体管的绝佳材料
我们可以用晶圆做基础 \N 把复杂金属电路放上面，集成所有东西
非常适合做.. 集成电路!
下一步是在硅片顶部  \N 加一层薄薄的氧化层, 作为保护层
然后加一层特殊化学品, 叫 "光刻胶" \N 光刻胶被光照射后 会变得可溶
可以用一种特殊化学药剂洗掉
单单光刻胶本身，并不是很有用 \N 但和"光掩膜"配合使用会很强大
光掩膜就像胶片一样，只不过不是 \N 吃墨西哥卷饼的可爱仓鼠，而是要转移到晶圆上的图案
把光掩膜盖到晶圆上，用强光照射 \N 挡住光的地方，光刻胶不会变化
光照到的地方，光刻胶会发生化学变化 \N 洗掉它之后，暴露出氧化层
用另一种化学物质 - 通常是一种酸 \N 可以洗掉"氧化层"露出的部分, 蚀刻到硅层
注意，氧化层被光刻胶保护住了.
为了清理光刻胶，我们用另一种化学药品洗掉它
是的，光刻法用很多化学品，每种都有特定用途
现在硅又露出来了 \N 我们想修改硅露出来的区域  让它导电性更好
所以用一种化学过程来改变它，叫"掺杂"
不是开玩笑！我们继续
"掺杂" 通常用高温气体来做，比如磷 \N 渗透进暴露出的硅，改变电学性质
半导体的具体物理和化学性质我们不会深究,
如果你感兴趣，描述里有个视频链接 \N 视频制作者是 Derek Muller 他的频道叫 Veritasium
但我们还需要几轮光刻法 来做晶体管
过程基本一样，先盖氧化层，再盖光刻胶
然后用新的光掩膜，这次图案不同 \N 在掺杂区域上方开一个缺口
洗掉光刻胶
然后用另一种气体掺杂 \N 把一部分硅转成另一种形式
为了控制深度，时机很重要 \N 我们不想超过之前的区域
现在 所有需要的组件都有了
最后一步，在氧化层上做通道 \N 这样可以用细小金属导线，连接不同晶体管
再次用光刻胶和光掩膜  蚀刻出小通道
现在用新的处理方法 叫"金属化" \N 放一层薄薄的金属，比如铝或铜
但我们不想用金属盖住所有东西 \N 我们想蚀刻出具体的电路
所以又是类似的步骤 \N 用光刻胶+光掩膜，然后溶掉暴露的光刻胶，暴露的金属
咻~
晶体管终于做好了！ \N 它有三根线，连接着硅的三个不同区域
每个区域的掺杂方式不同，这叫双极型晶体管
这个 1962 年的真实专利，永远改变了世界
用类似步骤，光刻可以制作其他电子元件 \N 比如电阻和电容，都在一片硅上
而且互相连接的电路也做好了
再见了，分立元件！
之前的例子 只做了一个晶体管，但现实中 \N 光刻法一次会做上百万个细节
芯片放大是这样的，导线上下交错，连接各个元件
尽管可以把光掩膜投影到一整片晶圆上 \N 但光可以投射成任意大小
就像投影仪可以投满荧幕一样
我们可以把光掩膜 \N 聚焦到极小的区域，制作出非常精细的细节
一片晶圆可以做很多 IC \N 整块都做完后，可以切割然后包进微型芯片
微型芯片就是在电子设备中那些小长方体
记住，芯片的核心都是一小片 IC
随着光刻技术发展，晶体管变小  密度变高
1960 年代初，IC 很少超过 5 个晶体管，因为塞不下
但 1960 年代中期 \N 市场上开始出现超过 100 个晶体管的 IC
1965年，戈登·摩尔看到了趋势：每两年左右，
得益于材料和制造技术的发展 \N 同样大小的空间，能塞进两倍数量的晶体管！
这叫 摩尔定律
然而这个名字不太对 \N 因为它不是定律，只是一种趋势
但它是对的
芯片的价格也急剧下降 \N 1962年平均50美元，下降到1968年2美元左右
如今 几美分就能买到 IC
晶体管更小密度更高 还有其他好处
晶体管越小，要移动的电荷量就越少 \N 能更快切换状态  耗电更少
电路更紧凑 还意味着信号延迟更低 \N 导致时钟速度更快
1968年，罗伯特·诺伊斯 和 戈登·摩尔  \N 联手成立了一家新公司
结合 Intergrated(集成) 和 Electronics(电子) 两个词
取名 Intel， 如今最大的芯片制造商
Intel 4004 CPU, 在第 7, 8 集介绍过 \N 是个重要里程碑
发布于1971年 \N 是第一个用 IC 做的处理器，也叫微型处理器
因为真的非常小！
它有2300个晶体管
人们惊叹于它的整合水平 \N 整个 CPU 在一个芯片里
而仅仅 20 年前，用分立元件会占满整个屋子
集成电路的出现 \N 尤其是用来做微处理器，开启了计算 3.0
而 Intel 4004 只是个开始，CPU 晶体管数量爆发增长
1980年，3 万晶体管 \N  1990年，100 万晶体管
2000年，3000 万个晶体管
2010年，10亿个晶体管！\N 在一个芯片里！我的天啊！
为了达到这种密度，光刻的分辨率 \N 从大约一万纳米，大概是人类头发直径的 1/10
发展到如今的 14 纳米 \N 比血红细胞小 400 倍！
当然，CPU 不是唯一受益的元件
大多数电子器件都在指数式发展：\N 内存，显卡，固态硬盘，摄像头感光元件，等等
如今的处理器，比如 iPhone 7 的 A10 CPU \N 有33亿个晶体管
面积仅有 1cm x 1cm，比一张邮票还小
现代工程师设计电路时，当然不是手工一个个设计晶体管 \N 这不是人力能做到的
1970年代开始，超大规模集成(VLSI)软件 \N 用来自动生成芯片设计
用比如 "逻辑综合" 这种技术 \N 可以放一整个高级组件，比如内存缓存
软件会自动生成电路，做到尽可能高效
许多人认为这是计算 4.0 的开始
坏消息是，专家们几十年来 \N 一直在预言摩尔定律的终结
现在可能终于接近了
进一步做小，会面临 2 个大问题
1. 用光掩膜把图案弄到晶圆上 \N 因为光的波长，精度已达极限
所以科学家在研制波长更短的光源，投射更小的形状
2. 当晶体管非常小，电极之间可能只距离几个原子 \N 电子会跳过间隙，这叫：量子隧道贯穿
2. 当晶体管非常小，电极之间可能只距离几个原子 \N 电子会跳过间隙，这叫：量子隧穿效应
如果晶体管漏电，就不是好开关
科学家和工程师在努力找解决方法
实验室中已造出小至1纳米的晶体管
能不能商业量产依然未知，未来也许能解决
我非常期待！下周见！
本集由 Hover 赞助播出

1940,1950 年代的电脑，每次只能运行一个程序
程序员在打孔纸卡上写程序
然后拿到一个计算机房间,  交给操作员
等计算机空下来了，操作员会把程序放入
然后运行，输出结果，停机
以前计算机慢，这种手动做法可以接受
运行一个程序通常要几小时，几天甚至几周
但上集说过，计算机越来越快，越来越快
指数级增长！
很快，放程序的时间 比程序运行时间还长
我们需要一种方式 让计算机自动运作
于是"操作系统"诞生了
操作系统，简称 OS，其实也是程序
但它有操作硬件的特殊权限  \N 可以运行和管理其它程序
操作系统一般是开机第一个启动的程序
其他所有程序 都由操作系统启动
操作系统开始于 1950 年代 \N 那时计算机开始变得更强大更流行
第一个操作系统 加强了程序加载方式
之前只能一次给一个程序，现在可以一次多个
当计算机运行完一个程序，会自动运行下一个程序
这样就不会浪费时间，找下一个程序的纸卡
这叫 批处理
电脑变得更快更便宜，开始在出现在世界各地
特别是大学和政府办公室
很快，人们开始分享软件，但有一个问题
在哈佛1号和 ENIAC 那个时代，计算都是一次性的
程序员只需要给那"一台"机器写代码
处理器，读卡器，打印机都是已知的
但随着电脑越来越普遍，计算机配置并不总是相同的
比如计算机可能有相同 CPU，但不同的打印机
这对程序员很痛苦
不仅要担心写程序，还要担心程序怎么和不同型号打印机交互
以及计算机连着的其他设备，这些统称"外部设备"
和早期的外部设备交互，是非常底层的
程序员要了解设备的硬件细节
加重问题的是，程序员很少能拿到所有型号的设备来测代码
所以一般是阅读手册来写代码，祈祷能正常运行
现在是"即插即用"，以前是"祈祷能用"
这很糟糕，所以为了程序员写软件更容易
操作系统充当软件和硬件之间的媒介
更具体地说，操作系统提供 API 来抽象硬件，叫"设备驱动程序"
程序员可以用标准化机制  和输入输出硬件（I/O）交互
比如，程序员只需调用 print(highscore)
操作系统会处理  输到纸上的具体细节
到 1950 年代尾声，电脑已经非常快了
处理器经常闲着，等待慢的机械设备（比如打印机和读卡器）
程序阻塞在 I/O 上
而昂贵的处理器则在度假，就是放松啥也不做
50年代后期，英国曼彻斯特大学 \N 开始研发世界上第一台超级计算机，Atlas
他们知道机器会超级快，所以需要一种方式来最大限度的利用它
他们的解决方案是一个程序叫 Atlas Supervisor  \N 于1962年完成
这个操作系统 \N不仅像更早期的批处理系统那样，能自动加载程序
还能在单个 CPU 上同时运行几个程序
它通过调度来做到这一点
假设 Atlas 上有一个游戏在运行
并且我们调用一个函数 print(highscore)
它让 Atlas 打印一个叫 highscore 的变量值
让朋友知道 我是最高分冠军
print 函数运行需要一点时间，大概上千个时钟周期
但因为打印机比 CPU 慢，与其等着它完成操作
Atlas 会把程序休眠，运行另一个程序
最终, 打印机会告诉 Atlas, 打印已完成
Atlas 会把程序标记成可继续运行
之后在某时刻会安排给 CPU 运行
并继续 print 语句之后的下一行代码
这样, Atlas 可以在 CPU 上运行一个程序
同时另一个程序在打印数据
同时另一个程序读数据
Atlas 的工程师做的还要多，配了4台纸带读取器，4台纸带打孔机
多达8个磁带驱动器
使多个程序可以同时运行，在单个 CPU 上共享时间
操作系统的这种能力叫"多任务处理"
同时运行多个程序有个问题
每个程序都会占一些内存 \N 当切换到另一个程序时，我们不能丢失数据
解决办法是 给每个程序分配专属内存块
举个例子，假设计算机一共有 10000 个内存位置
程序 A 分配到内存地址 0 到 999
而程序 B 分配到内存地址 1000 到 1999，以此类推
如果一个程序请求更多内存，操作系统会决定是否同意
如果同意，分配哪些内存块
这种灵活性很好，但带来一个奇怪的后果
程序 A 可能会分配到非连续的内存块
比如内存地址 0 到 999，以及 2000 到 2999
这只是个简单例子
真正的程序可能会分配到内存中数十个地方
你可能想到了，这对程序员来说很难跟踪
也许内存里有一长串销售额，每天下班后要算销售总额
但列表 存在一堆不连续的内存块里
为了隐藏这种复杂性，操作系统会把内存地址进行 "虚拟化"
这叫 "虚拟内存"，程序可以假定内存总是从地址0开始
简单又一致
而实际物理位置  被操作系统隐藏和抽象了
一层新的抽象
用程序 B 来举例 \N 它被分配了内存地址 1000 到 1999
对程序 B 而言，它看到的地址是 0 到 999
操作系统会自动处理 \N 虚拟内存和物理内存之间的映射
如果程序 B 要地址 42，实际上是物理地址 1042
这种内存地址的虚拟化  对程序 A 甚至更有用
在例子中，A 被分配了两块隔开的内存
程序 A 不知道这点.
以 A 的视角，它有 2000 个连续地址
当程序 A 读内存地址 999 时 \N 会刚好映射到物理内存地址 999
但如果程序 A 读下一个地址 1000
会映射到物理地址 2000
这种机制使程序的内存大小可以灵活增减 \N 叫"动态内存分配"
对程序来说，内存看起来是连续的.
它简化了一切，为操作系统同时运行多个程序 \N 提供了极大的灵活性
给程序分配专用的内存范围，\N 另一个好处是 这样隔离起来会更好
如果一个程序出错，开始写乱七八糟的数据
它只能捣乱自己的内存，不会影响到其它程序.
这叫 "内存保护"
防止恶意软件（如病毒）也很有用
例如，我们不希望其他程序有能力 \N 读或改邮件程序的内存
如果有这种权限 \N 恶意软件可能以你的名义发邮件，甚至窃取个人信息
一点都不好！
Atlas 既有"虚拟内存"也有"内存保护"
是第一台支持这些功能的计算机和操作系统！
到 1970 年代，计算机足够快且便宜
大学会买电脑让学生用
计算机不仅能同时运行多个程序，还能让多用户能同时访问
多个用户用"终端"来访问计算机
"终端"只是键盘+屏幕，连到主计算机 \N 终端本身没有处理能力
冰箱大小的计算机可能有50个终端，能让50个用户使用
这时操作系统不但要处理多个程序，还要处理多个用户
为了确保其中一个人  不会占满计算机资源
开发了 分时操作系统
意思是 每个用户只能用一小部分处理器，内存等
因为电脑很快 \N 即使拿到 1/50 的资源也足以完成许多任务
早期分时操作系统中，最有影响力的是 \N Multics（多任务信息与计算系统）
于 1969 年发布
Multics 是第一个，从设计时就考虑到安全的操作系统
开发人员不希望恶意用户 访问不该访问的数据
比如学生假装成教授，访问期末考试的文件
这导致 Multics 的复杂度超过当时的平均水准
操作系统会占大约 1 Mb 内存，这在当时很多！
可能是内存的一半，只拿来运行操作系统！
Multics 的研究人员之一 Dennis Ritchie 曾说过
"阻碍 Multics 获得商业成功的一个明显问题是
从某种方面来说，它被过度设计了，功能太多了"
所以 Dennis 和另一个 Multics 研究员 \N Ken Thompson 联手打造新的操作系统
叫 Unix
他们想把操作系统分成两部分：
首先是操作系统的核心功能
如内存管理，多任务和输入/输出处理 \N 这叫"内核"
第二部分是一堆有用的工具
但它们不是内核的一部分（比如程序和运行库）
紧凑的内核 意味着功能没有那么全面
Multics 的另一个开发者 Tom Van Vleck 回忆说：
"我对 Dennis 说，我在 Multics 写的一半代码都是错误恢复代码"
他说:"Unix 不会有这些东西
如果有错误发生，我们就让内核"恐慌"（panic）
当调用它时，机器会崩溃
你得在走廊里大喊，"嘿，重启电脑"
你可能听过 "内核恐慌"（kernel panic）
这就是这个词的来源
内核如果崩溃，没有办法恢复
所以调用一个叫"恐慌"（panic）的函数
起初只是打印"恐慌"一词，然后无限循环
这种简单性意味着  \N Unix 可以在更便宜更多的硬件上运行
使 Unix 在 Dennis 和 Ken 工作的 \N 贝尔实验室大受欢迎
越来越多开发人员用 Unix 写程序和运行程序
工具数量日益增长
1971 年发布后不久
就有人写了不同编程语言的编译器 \N 甚至文字处理器
使得 Unix 迅速成为 \N 1970~80年代最流行的操作系统之一
到 1980 年代早期
计算机的价格 降到普通人买得起  \N 这些叫"个人电脑"或"家庭电脑"
这些电脑比大型主机简单得多 \N 主机一般在大学，公司和政府
因此操作系统也得简单
举例，微软的磁盘操作系统（MS-DOS）只有 160 kB \N 一张磁盘就可以容纳
于 1981 年发布，成为早期家用电脑最受欢迎的操作系统
虽然缺少"多任务"和"保护内存"这样功能
意味着程序经常使系统崩溃
虽然很讨厌但还可以接受，因为用户可以重启
哪怕是微软 1985 年发布的早期 Windows \N 虽然在 90 年代很流行
但却缺乏"内存保护"
当程序行为不当时，就会"蓝屏"
代表程序崩溃的非常严重，把系统也带崩溃了
幸运的是，新版Windows有更好的保护，不会经常崩溃
如今的计算机 有现代操作系统
比如 Mac OS X，Windows 10 \NLinux，iOS和Android
虽然大部分设备只有一个人使用
你！
操作系统依然有"多任务, "虚拟内存", "内存保护"
因此可以同时运行多个程序：
一边在浏览器看 YouTube，一边在 Photoshop 修图
用 Spotify 放音乐，同步 Dropbox
如果没有操作系统这几十年的发展，这些都不可能,
当然，我们也需要地方放程序
下周会讨论

系列中 我们多次谈到内存（Memory）
甚至在第 6 集设计了一个简单内存
一般来说，电脑内存是 "非永久性"
如果 Xbox 电源线不小心拔掉了，内存里所有数据都会丢失
所以内存叫"易失性"存储器
我们还没谈过的话题  是存储器（Storage）
存储器（Storage）和内存（Memory）有点不同
任何写入"存储器"的数据，比如你的硬盘 \N 数据会一直存着，直到被覆盖或删除，断电也不会丢失
存储器是"非易失性"的
以前是"易失性"的速度快，"非易失性"的速度慢
但随着技术发展，两者的差异越来越小
如今我们认为稀松平常的技术，比如这个 U 盘
能低成本+可靠+长时间  存储上 GB 的数据
但以前可不是这样的
最早的存储介质是 打孔纸卡 \N 以及纸卡的亲戚    打孔纸带
到1940年代，纸卡标准是 80列x12行
一张卡能存 960 位数据 (80x12=960)
据我们所知的  最大纸卡程序
是美国军方的"半自动地面防空系统" 简称 SAGE
一个在 1958 年投入使用的防空系统
主程序存储在 62,500 个纸卡上
大小 5MB 左右, 相当如今手机拍张照
纸卡用了十几年，因为不用电而且便宜耐用
然而坏处是读取慢，只能写入一次
打的孔无法轻易补上
对于存临时值，纸卡不好用
我们需要更快更大更灵活的存储方式
J. Presper Eckert 在 1944 年建造 ENIAC 时发明了一种方法
叫"延迟线存储器"（Delay Line Memory）原理如下
拿一个管子装满液体，如水银
管子一端放扬声器，另一端放麦克风
扬声器发出脉冲时  会产生压力波
压力波需要时间  传播到另一端的麦克风
麦克风将压力波 转换回电信号.
我们可以用压力波的传播延迟  来存储数据！
假设有压力波代表 1，没有代表 0
扬声器可以输出 1​​010 0111
压力波沿管子传播，过了一会儿，撞上麦克风，
将信号转换回 1 和 0
如果加一个电路，连接麦克风和扬声器
再加一个放大器（Amplifier）来弥补信号衰弱
就能做一个存储数据的循环
信号沿电线传播几乎是瞬时的,
所以任何时间点只显示  1 bit 数据
但管子中可以存储多个位(bit)
忙完 ENIAC 后，Eckert 和同事 John Mauchly
着手做一个更大更好的计算机叫 EDVAC，使用了延迟线存储器
总共有 128 条延迟线，每条能存 352 位（bits）
总共能存 45,000 位(bit)
对 1949 年来说还不错！
这使得 EDVAC 成为最早的 "存储程序计算机" 之一
我们在第 10 集讨论过
但"延迟线存储器"的一大缺点是
每一个时刻只能读一位 (bit) 数据
如果想访问一个特定的 bit，比如第 112 位(bit) \N 你得等待它从循环中出现
所以又叫 "顺序存储器"或"循环存储器"
而我们想要的是 "随机存取存储器" \N 可以随时访问任何位置
增加内存密度也是一个挑战
把压力波变得更紧密  意味着更容易混在一起
所以出现了其他类型的 "延迟线存储器"
如 "磁致伸缩延迟存储器"
用金属线的振动来代表数据
通过把线卷成线圈，1英尺×1英尺的面积能存储大概 1000位(bit)
然而，延迟线存储器在 1950 年代中期就基本过时了
因为出现了新技术，性能,可靠性和成本都更好
"磁芯存储器"，用了像甜甜圈的小型磁圈
如果给磁芯绕上电线，并施加电流，可以将磁化在一个方向
如果关掉电流，磁芯保持磁化
如果沿相反方向施加电流
磁化的方向（极性）会翻转
这样就可以存 1 和 0！
如果只存 1 位不够有用，所以把小甜甜圈排列成网格
有电线负责选行和列 \N 也有电线贯穿每个磁芯, 用于读写一位(bit)
我手上有一块磁芯存储器
每个黄色方格  有32行x32列的磁芯 \N 每个磁芯存 1 位数据
所以能存 1024 位(bit)  (32x32=1024)
总共 9 个黄色方格
所以这块板子最多能存 9216 位(bit) (1024x9=9216)
换算过来大约是 9 千字节 \N (9216 bit ~= 9 kb)
磁芯内存的第一次大规模运用\N 是 1953 年麻省理工学院的 Whirlwind 1 计算机
磁芯排列是 32×32
用了 16 块板子，能存储大约 16000 位(bit)
更重要的是，不像"延迟线存储器" \N 磁芯存储器能随时访问任何一位(bit)
这在当时非常了不起
"磁芯存储器" 从 1950 年代中期开始成为主流 \N 流行了 20 多年
而且一般还是手工编织的！
刚开始时  存储成本大约 1 美元 1 位(bit) \N 到1970年代，下降到 1 美分左右
不幸的是，即使每位 1 美分也不够便宜
之前提过，现代手机随便拍张照片都有 5 MB
5MB 约等于 4000 万 bit
你愿意花 40 万美元在"磁芯存储器"上存照片吗？
如果你有这么多钱
你知道 Crash Course 在 Patreon 有赞助页吗？
对吧？你懂的
总之，当时对存储技术进行了大量的研究
到 1951 年，Eckert 和 Mauchly 创立了自己的公司
设计了一台叫 UNIVAC 的新电脑
最早进行商业销售的电脑之一
它推出了一种新存储：磁带
磁带是纤薄柔软的一长条磁性带子  卷在轴上
磁带可以在"磁带驱动器"内前后移动
里面有一个"写头"绕了电线，电流通过产生磁场
导致磁带的一小部分被磁化
电流方向决定了极性，代表 1 和 0
还有一个"读头"，可以非破坏性地检测极性
UNIVAC 用了半英寸宽，8条并行的磁带
磁带每英寸可存 128 位数据
每卷有 1200 英尺长
意味着一共可以存 1500 万位左右
- 接近2兆字节！（2 MB）
虽然磁带驱动器很贵，但磁带又便宜又小
因此磁带至今仍用于存档
磁带的主要缺点是访问速度
磁带是连续的，必须倒带或快进到达特定位置
可能要几百英尺才能得到某个字节(byte)，这很慢
1950,60年代，有个类似技术是 "磁鼓存储器"
有金属圆筒，盖满了磁性材料以记录数据
滚筒会持续旋转，周围有数十个读写头
等滚筒转到正确的位置\N 读写头会读或写 1 位(bit) 数据
为了尽可能缩短延迟, 鼓轮每分钟上千转！
到 1953 年，磁鼓技术飞速发展 \N 可以买到存 80,000 位的"磁鼓存储器"
- 也就是 10 KB
但到 1970 年代 "磁鼓存储器" 不再生产
然而，磁鼓导致了硬盘的发展 \N 硬盘和磁鼓很相似
不过硬盘用的是盘，不像磁鼓用圆柱体，因此得名
原理是一样的，磁盘表面有磁性
写入头和读取头  可以处理上面的 1 和 0
硬盘的好处是薄，可以叠在一起
提供更多表面积来存数据
IBM 对世上第一台磁盘计算机就是这样做的
顺便一说名字不错
它有 50 张 24 英寸直径的磁盘，总共能存 5 MB 左右
太棒啦! 终于能存一张现代手机的照片了！这年是 1956 年
要访问某个特定 bit
一个读/写磁头会向上或向下移动，找到正确的磁盘
然后磁头会滑进去
就像磁鼓存储器一样，磁盘也会高速旋转
所以读写头要等到正确的部分转过来
RAMAC 305 访问任意数据，平均只要六分之一秒左右
也叫寻道时间
虽然六分之一秒对存储器来说算不错 \N 但对内存来说还不够快
所以 RAMAC 305 还有"磁鼓存储器"和"磁芯存储器"
这是"内存层次结构"的一个例子
一小部分高速+昂贵的内存
一部分稍慢+相对便宜些的内存
还有更慢+更便宜的内存
这种混合  在成本和速度间取得平衡
1970 年代，硬盘大幅度改进并变得普遍
如今的硬盘可以轻易容纳 1TB 的数据
能存 20 万张 5MB 的照片！
网上最低 40 美元就可以买到
每 bit 成本 0.0000000005 美分
比磁芯内存 1 美分 1 bit 好多了！
另外，现代硬盘的平均寻道时间低于 1/100 秒
我简单地提一下硬盘的亲戚，软盘
除了磁盘是软的，其他基本一样
你可能见过某些程序的保存图标是一个软盘
软盘曾经是真实存在的东西！
软盘是为了便携，在 1970~1990 非常流行
如今当杯垫挺不错的
密度更高的软盘，如 Zip Disks，在90年代中期流行起来
但十年内就消失了
光学存储器于 1972 年出现，12 英寸的"激光盘"
你可能对后来的产品更熟：光盘（简称 CD）
以及 90 年代流行的 DVD
功能和硬盘软盘一样，都是存数据.
但用的不是磁性
光盘表面有很多小坑，造成光的不同反射
光学传感器会捕获到，并解码为 1 和 0
如今，存储技术在朝固态前进，没有机械活动部件
比如这个硬盘，以及 U 盘
里面是集成电路，我们在第 15 集讨论过
第一个 RAM 集成电路出现于 1972 年 \N 成本每比特 1 美分
使"磁芯存储器"迅速过时
如今成本下降了更多 \N 机械硬盘 被 固态硬盘 逐渐替代，简称 SSD
由于 SSD 没有移动部件
磁头不用等磁盘转
所以 SSD 访问时间低于 1/1000 秒
这很快！
但还是比 RAM 慢很多倍
所以现代计算机 仍然用存储层次结构
我们从 1940 年代到现在进步巨大
就像在第 14 集讨论过的  晶体管数量和摩尔定律
内存和存储技术也有类似的趋势
从早期每 MB 成本上百万美元，下滑到
2000 年只要几分钱，如今远远低于 1 分钱
完全没有打孔纸卡
你能想象 SEGA 的纸卡房间风一吹会怎样吗？
62,500 张卡
我想都不敢想
我们下周见

上集我们讲了数据存储，磁带和硬盘这样的技术
可以在断电状态长时间存上万亿个位
非常合适存一整块有关系的数据，或者说"文件"
你肯定见过很多种文件 \N 比如文本文件，音乐文件，照片和视频
今天，我们要讨论文件到底是什么 \N 以及计算机怎么管理文件
随意排列文件数据完全没问题，但按格式排会更好
这叫 "文件格式"
你可以发明自己的文件格式，程序员偶尔会这样做
但最好用现成标准，比如 JPEG 和 MP3
来看一些简单文件格式，最简单的是文本文件
也叫 TXT 文件, 里面包含的是... 文字 （惊喜吧）
就像所有其它文件，文本文件只是一长串二进制数
原始值看起来会像这样：
可以转成十进制看，但帮助不大
解码数据的关键是 ASCII 编码
一种字符编码标准，第 4 集讨论过.
第一个值 72 \N 在 ASCII 中是大写字母 H
以此类推 解码其他数字
来看一个更复杂的例子：波形(Wave)文件，也叫 WAV \N 它存音频数据
在正确读取数据前，需要知道一些信息
比如码率(bit rate)，以及是单声道还是立体声
关于数据的数据，叫"元数据"(meta data)
元数据存在文件开头，在实际数据前面 \N 因此也叫 文件头(Header)
WAV 文件的前 44 个字节长这样
有的部分总是一样的，比如写着 WAVE 的部分
其他部分的内容，会根据数据变化
音频数据紧跟在元数据后面，是一长串数字
数字代表每秒捕获多次的声音幅度
如果想学声音的基础知识 \N 可以看物理速成课第18集
举个例子，看一下"你好"的波形
现在捕获到了一些声音，我们放大看一下
电脑和手机麦克风，每秒可以对声音进行上千次采样
每次采样可以用一个数字表示
声压越高数字越大，也叫"振幅"
WAVE 文件里存的就是这些数据！
每秒上千次的振幅！
播放声音文件时，扬声器会产生相同的波形
"你好！"
现在来谈谈 位图(Bitmap)，后缀 .bmp, 它存图片
计算机上，图片由很多个叫"像素"的方块组成
每个像素由三种颜色组成：红，绿，蓝
叫"加色三原色"，混在一起可以创造其它颜色
就像 WAV 文件一样，BMP 文件开头也是元数据 \N 有图片宽度，图片高度，颜色深度
举例，假设元数据说图是 4像素宽 x 4像素高
颜色深度 24 位\N  8 位红色，8 位绿色，8 位蓝色
提醒一下，8位 (bit) 和 1字节(byte)是一回事
一个字节能表示的最小数是 0，最大 255
图像数据看起来会类似这样：\N 来看看第一个像素的颜色
红色是255，绿色是255，蓝色也是255
这等同于全强度红色，全强度绿色和全强度蓝色
混合在一起变成白色
所以第一个像素是白色！
下一个像素的红绿蓝值，或 RGB 值 \N  255,255,0 是黄色！
下一个像素是 0,0,0 ，黑色
下一个是黄色
因为元数据说图片是 4x4 \N 我们知道现在到了第一行结尾
所以换一行
下一个 RGB 值是 255,255,0，又是黄色
好，我们读完剩下的像素
一个低分辨率的吃豆人
刚才显然只是一个简单例子，但这张图片也可以用 BMP 存
我想再次强调，不管是文本文件，WAV，BMP
或是我们没时间讨论的其他格式
文件在底层全是一样的： 一长串二进制
为了知道文件是什么，文件格式至关重要
现在你对文件更了解了 \N 我们接下来讨论计算机怎么存文件
虽然硬件可能是磁带，磁鼓，磁盘或集成电路
通过软硬件抽象后，可以看成一排能存数据的桶
在很早期时，计算机只做一件事，比如算火炮射程表 \N 整个储存器就像一整个文件
数据从头存到尾，直到占满
但随着计算能力和存储容量的提高 \N 存多个文件变得非常有用
最简单的方法  是把文件连续存储
这样能用, \N 但怎么知道文件开头和结尾在哪里？
储存器没有文件的概念，只是存储大量位
所以为了存多个文件 \N 需要一个特殊文件，记录其他文件的位置
这个特殊文件有很多名字，这里泛称 "目录文件"
这个文件经常存在最开头，方便找
位置 0！
目录文件里，存所有其他文件的名字
格式是文件名 + 一个句号 + 扩展名，比如 BMP 或 WAV
扩展名帮助得知文件类型
目录文件还存文件的元数据，比如创建时间
最后修改时间，文件所有者是谁\N是否能读/写  或读写都行
最重要的是，目录文件有文件起始位置和长度
如果要添加文件，删除文件，更改文件名等
必须更新目录文件
就像书的目录，如果缩短或移动了一个章节 \N 要更新目录，不然页码对不上
目录文件，以及对目录文件的管理 \N 是一个非常简单的文件系统例子
文件系统专门负责管理文件
刚刚的例子叫"平面文件系统" \N因为文件都在同一个层次
平的！
当然，把文件前后排在一起  有个问题
如果给 todo.txt 加一点数据 \N 会覆盖掉后面 carrie.bmp 的一部分
所以现代文件系统会做两件事
1. 把空间划分成一块块 \N 导致有一些 "预留空间" 可以方便改动
同时也方便管理
用这样的方案，目录文件要记录文件在哪些块里
2. 拆分文件，存在多个块里
假设打开 todo.txt 加了些内容\N 文件太大存不进一块里
我们不想覆盖掉隔壁的块，所以文件系统会分配 \N 一个没使用的块，容纳额外的数据
目录文件会记录不止一个块，而是多个块
只要分配块，文件可以轻松增大缩小
如果你看了第18集 操作系统 \N 这听起来很像"虚拟内存"
概念上讲的确很像！
假设想删掉 carrie.bmp \N 只需要在目录文件删掉那条记录
让一块空间变成了可用
注意这里没有擦除数据，只是把记录删了
之后某个时候，那些块会被新数据覆盖 \N 但在此之前，数据还在原处
所以计算机取证团队可以"恢复"数据
虽然别人以为数据已经"删了", 狡猾！
假设往 todo.txt 加了更多数据 \N 所以操作系统分配了一个新块，用了刚刚 carrie.bmp 的块
现在 todo.txt 在 3 个块里，隔开了，顺序也是乱的
这叫碎片
碎片是增/删/改文件导致的，不可避免
对很多存储技术来说，碎片是坏事
如果 todo.txt 存在磁带上，读取文件要
先读块1, 然后快进到块5，然后往回转到块2
来回转个半天
现实世界中，大文件可能存在数百个块里
你可不想等五分钟才打开文件
答案是碎片整理！
这个词听起来好像很复杂，但实际过程很简单
以前看计算机做碎片整理 真的很有趣！
计算机会把数据来回移动，排列成正确的顺序
整理后 todo.txt 在 1 2 3，方便读取.
目前只说了平面文件系统，文件都在同一个目录里.
如果存储空间不多，这可能就够用了 \N 因为只有十几个文件
但上集说过，容量爆炸式增长，文件数量也飞速增长
很快，所有文件都存在同一层变得不切实际
就像现实世界\N 相关文件放在同一个文件夹会方便很多
然后文件夹套文件夹.
这叫"分层文件系统"，你的计算机现在就在用这个.
实现方法有很多种，我们用之前的例子来讲重点好了
最大的变化是 目录文件不仅要指向文件, 还要指向目录
我们需要额外元数据  来区分开文件和目录，
这个目录文件在最顶层，因此叫根目录
所有其他文件和文件夹，都在根目录下
图中可以看到根目录文件有3个文件 \N 2个子文件夹："音乐"和"照片"
如果想知道"音乐"文件夹里有什么 \N 必须去那边读取目录文件（格式和根目录文件一样）
有很多好歌啊！
除了能做无限深度的文件夹 \N 这个方法也让我们可以轻松移动文件
如果想把 theme.wav 从根目录移到音乐目录
不用移动任何数据块
只需要改两个目录文件 \N 一个文件里删一条记录，另一个文件里加一条记录
theme.wav 依然在块5
文件系统的几个重要概念  现在介绍完了.
它提供了一层新抽象！
文件系统使我们不必关心 \N 文件在磁带或磁盘的具体位置
整理和访问文件更加方便
我们像普通用户一样直观操纵数据，比如打开和整理文件
接下来几集也会从用户角度看问题
下周见
本集由 Curiosity Stream 赞助播出

上集我们讨论了文件格式，如何编码文字，声音，图片
还举了具体例子 .txt .wav .bmp
这些格式虽然管用，而且现在还在用 \N 但它们的简单性意味着效率不高
我们希望文件能小一点，这样能存大量文件，传输也会快一些
等邮件附件下载烦死人了
解决方法是 压缩，把数据占用的空间压得更小
用更少的位(bit)来表示数据
听起来像魔法，但其实是计算机科学！
我们继续用上集的 吃豆人例子，图像是 4像素x4像素
之前说过，图像一般存成一长串像素值
为了知道一行在哪里结束 \N 图像要有元数据，写明尺寸等属性
但为了简单起见，今天忽略这些细节
如果红绿蓝都是 255 会得到白色
如果混合 255红色和255绿色，会得到黄色
这个图像有16个像素(4x4),  每个像素3个字节
总共占48个字节（16x3=48）
但我们可以压缩到少于 48 个字节
一种方法是 减少重复信息
最简单的方法叫 游程编码(Run-Length Encoding)
适合经常出现相同值的文件
比如吃豆人 有7个连续黄色像素
与其全存下来：黄色，黄色，黄色...
可以插入一个额外字节，代表有7个连续黄色像素
然后删掉后面的重复数据.
为了让计算机能分辨哪些字节是"长度" 哪些字节是"颜色" \N 格式要一致
所以我们要给所有像素前面标上长度
有时候数据反而会变多，但就这个例子而言
我们大大减少了字节数，之前是48 现在是24
小了50％！省了很多空间！
还有，我们没有损失任何数据 \N 我们可以轻易恢复到原来的数据
这叫"无损压缩"，没有丢失任何数据
解压缩后，数据和压缩前完全一样
我们来看另一种无损压缩，它用更紧凑的方式表示数据块
有点像 "别忘了变厉害" 简写成 DFTBA
为此，我们需要一个字典，存储"代码"和"数据"间的对应关系
我们看个例子
我们可以把图像看成一块块，而不是一个个像素
为了简单，我们把2个像素当成1块（占6个字节）
但你也可以定成其他大小
我们只有四对： 白黄 黑黄 黄黄 白白
我们会为这四对  生成紧凑代码(compact codes)
有趣的是，这些块的出现频率不同
1950年代 大卫·霍夫曼 发明了一种高效编码方式叫 \N "霍夫曼树"（Huffman Tree） 当时他是麻省理工学院的学生
算法是这样的
首先，列出所有块和出现频率，每轮选两个最低的频率
这里 黑黄 和 白白 的频率最低，它们都是 1
可以把它们组成一个树，总频率 2
现在完成了一轮算法
现在我们重复这样做
这次有3个可选
就像上次一样，选频率最低的两个，放在一起，并记录总频率
好，我们快完成了
这次很简单，因为只有2个选择
把它们组合成一棵树就完成了！
现在看起来像这样，它有一个很酷的属性：按频率排列
频率低的在下面
现在有了一棵树，你可能在想  "怎么把树变成字典？"
我们可以把每个分支用 0 和 1 标注，就像这样
现在可以生成字典
黄黄 编码成 0  \N 白黄 编码成 10 \N 黑黄 编码成 110 \N 白白 编码成 111
酷的地方是  它们绝对不会冲突
因为树的每条路径是唯一的
意味着代码是"无前缀"的，没有代码是以另一个代码开头的
现在我们来压缩！
注意是位(bit)！ 不是字节(byte)！ \N 14位(bit) 还不到2个字节(byte)！
但，先别急着开香槟！
字典也要保存下来，否则 14 bit 毫无意义
所以我们把字典 加到 14 bit 前面，就像这样
现在加上字典，图像是 30 个字节(bytes)  \N 比 48 字节好很多
"消除冗余"和"用更紧凑的表示方法"，这两种方法通常会组合使用
几乎所有无损压缩格式都用了它们 \N 比如 GIF, PNG, PDF, ZIP
游程编码 和 字典编码 都是无损压缩
压缩时不会丢失信息，解压后，数据和之前完全一样
无损对很多文件很重要
比如我给你发了个压缩的 word 文档\N 你解压之后发现内容变了，这就很糟糕了
但其他一些文件，丢掉一些数据没什么关系
丢掉那些人类看不出区别的数据
大多数有损压缩技术，都用到了这点
实际细节比较复杂，所以我们讲概念就好
以声音为例，你的听力不是完美的
有些频率我们很擅长，其他一些我们根本听不见，比如超声波
除非你是蝙蝠
举个例子，如果录音乐，超声波数据都可以扔掉 \N 因为人类听不到超声波
另一方面，人类对人声很敏感，所以应该尽可能保持原样
低音介于两者之间，人类听得到，但不怎么敏感
一般是感觉到震动
有损音频压缩利用这一点，用不同精度编码不同频段
听不出什么区别，不会明显影响体验
音乐发烧友估计要吐槽了！
日常生活中你会经常碰到这类音频压缩
所以你在电话里的声音 和现实中不一样
压缩音频是为了让更多人能同时打电话
如果网速变慢了，压缩算法会删更多数据
进一步降低声音质量，所以 Skype 通话有时听起来像机器人
和没压缩的音频格式相比，比如 WAV 或 FLAC \N ( 这下音乐发烧友满意了）
压缩音频文件如 MP3，能小10倍甚至更多.
省了超多空间！
所以我的旧 iPod 上有一堆超棒的歌
别批判我
这种删掉人类无法感知的数据的方法，叫"感知编码"
它依赖于人类的感知模型，模型来自"心理物理学"领域
这是各种"有损压缩图像格式"的基础，最著名的是 JPEG
就像听力一样，人的视觉系统也不是完美的.
我们善于看到尖锐对比，比如物体的边缘
但我们看不出颜色的细微变化
JPEG 利用了这一点，把图像分解成 8x8 像素块
然后删掉大量高频率空间数据
举个例子，这是导演的狗，面面
超可爱！
我们来看其中一个 8x8 像素
几乎每个像素都和相邻像素不同，用无损技术很难压缩 \N 因为太多不同点了
很多小细节
但人眼看不出这些细节
因此可以删掉很多，用这样一个简单的块来代替
这看起来一样，但可能只占10％的原始数据
我们可以对所有 8x8 块做一样的操作
图片依然可以认出是一只狗，只是更粗糙一些
以上例子比较极端，进行了高度压缩，只有原始大小的八分之一
通常你可以取得平衡，图片看起来差不多，但文件小不少
你看得出两张图的区别吗？
估计看不出，但我想提一下，视频压缩也造成了影响
毕竟你现在在看视频啊
视频只是一长串连续图片 \N 所以图片的很多方面也适用于视频
但视频可以做一些小技巧 \N 因为帧和帧之间很多像素一样
比如我后面的背景！
这叫 时间冗余
视频里不用每一帧都存这些像素 \N 可以只存变了的部分
当帧和帧之间有小小的差异时，比如后面这个频率发生器
很多视频编码格式，只存变化的部分
这比存所有像素更有效率 \N 利用了帧和帧之间的相似性
更高级的视频压缩格式 会更进一步
找出帧和帧之间相似的补丁 \N 然后用简单效果实现，比如移动和旋转
变亮和变暗
如果我这样摆手，视频压缩器会识别到相似性
用一个或多个补丁代表我的手，然后帧之间直接移动这些补丁
所以你看到的是我过去的手（不是实时的）\N 有点可怕 但数据量少得多
MPEG-4 是常见标准，可以比原文件小20倍到200倍
但用补丁的移动和旋转 来更新画面
当压缩太严重时会出错 \N 没有足够空间更新补丁内的像素
即使补丁是错的，视频播放器也会照样播放
导致一些怪异又搞笑的结果，你肯定见过这些.
总的来说，压缩对大部分文件类型都有用
从这个角度来讲，人类不完美的视觉和听觉 也算有用
学习压缩非常重要 \N 因为可以高效存储图片，音乐，视频
如果没有压缩 \N 在 YouTube 看"明星拼车唱歌"几乎不可能
因为你的带宽可能不够（会很卡） \N 而且供应商不愿意免费传输那么多数据
现在你知道为什么打 Skype 电话 \N 有时像在和恶魔通话
下周见

我们之前讨论过 输入输出 \N 但都是计算机组件互相输入输出
比如 RAM 输出数据，或输指令进 CPU
我们还没讲 来自人类的输入
也没讲怎么从电脑中拿出信息，除了用打孔纸卡
当然，有很多种 "输入输出设备"  \N 让我们和计算机交互
它们在人类和机器间提供了界面
如今有整个学科专门研究这个，叫 "人机交互"
界面对用户体验非常重要 \N 所以是我们接下来几集的重点
在系列开头的几集，我们提过
早期机械计算设备 \N 用齿轮，旋钮和开关等机械结构来输入输出
这些就是交互界面
甚至早期电子计算机  比如 Colossus 和 ENIAC
也是用一大堆机械面板和线 来操作
输入一个程序可能要几星期，还没提运行时间.
运行完毕后想拿出数据，一般是打印到纸上
打印机超有用
甚至 查尔斯·巴贝奇 都给差分机专门设计了一个
那可是 1820 年代!
然而，到 1950 年代，机械输入完全消失
因为出现了打孔纸卡和磁带
但输出仍然是打印到纸上
还有大量指示灯，在运行中提供实时反馈
那个时代的特点是 尽可能迁就机器 \N 对人类好不好用是其次
打孔纸带就是个好例子
就是为了方便计算机读取
纸带是连续的，方便机器处理
纸孔可以方便地 用机械或光学手段识别
纸孔可以编码程序和数据
当然, 人类不是以纸孔方式思考的.
所以负担放到了程序员身上
他们要花额外时间和精力 \N 转成计算机能理解的格式
一般需要额外人员和设备帮忙
要注意的是，基本上 1950 年前的早期计算机 \N "输入"的概念很原始
是的，的确是人类负责输入程序和数据 \N 但计算机不会交互式回应
程序开始运行后会一直运行  直到结束
因为机器太贵了 \N 不能等人类慢慢敲命令和给数据
要同时放入程序和数据
这在 1950 年代晚期开始发生变化
一方面，小型计算机变得足够便宜
让人类来回和计算机交互  变得可以接受
交互式就是人和计算机之间来回沟通
而另一方面
大型计算机变得更快，能同时支持多个程序和多个用户
这叫"多任务"和"分时系统"
但交互式操作时 \N 计算机需要某种方法来获得用户输入
所以借用了当时已经存在的数据录入机制：键盘
当时，打字机已经存在几个世纪了
但现代打字机是 \N克里斯托弗·莱瑟姆·肖尔斯 在 1868 年发明的
虽然到 1874 年才完成设计和制造
但之后取得了商业成功
肖尔斯 的打字机用了不寻常的布局，QWERTY
名字来自键盘左上角按键
为什么这么设计 有很多猜测
最流行的理论是  这样设计是为了 \N 把常见字母放得远一些，避免按键卡住
这个解释虽然省事，但可能是错的，或至少不够全面
事实上，QWERTY 把很多常见字母放在了一起 \N 比如 TH 和 ER
我们知道 肖尔斯和他的团队设计了很多版 \N 才进化到这个布局
总之，肖尔斯 的打字机取得了成功 \N 所以其它公司很快开始抄他的设计
过去一个世纪有不少新的键盘布局被发明，宣称各种好处
但人们已经熟悉了 QWERTY 布局 \N 根本不想学新布局
这是经济学家所说的 转换成本
所以现在都快1个半世纪了 \N 我们还在用 QWERTY 键盘布局
我应该提一下，QWERTY 不是通用的
有很多变体，比如法国 AZERTY 布局
以及中欧常见的 QWERTZ 布局
有趣的是，肖尔斯 根本没想到打字会比手写快
手写速度大约是每分钟 20 个
打字机主要为了易读性和标准化，而不是速度
然而随着打字机成为办公室标配 \N 对快速打字的渴望越来越大
有两个重大进步  解放了打字的潜力
1880年左右，辛辛那提速记学院 \N 一名叫 伊丽莎白·朗利 的老师
开始推广 十指打字
比一个手指打字要移动的距离短得多，所以速度更快
几年后，弗兰克·爱德华·麦克格林 \N 盐湖城的一位联邦法庭书记
学会了盲打，打字时不用看键盘
1888年，麦格高林 赢了备受关注的打字速度比赛
之后"十指盲打"开始流行
专业打字员  每分钟 100 字以上
比手写快多了！而且清晰又整洁！
虽然人类擅长用打字机
但我们没法把打字机塞到计算机面前，让它打字
计算机又没有手指
所以早期计算机用了一种特殊打字机，是专门用来发电报的,
叫 电传打字机
这些打字机是强化过的，可以用电报线发送和接收文本
按一个字母，信号会通过电报线，发到另一端
另一端的电传打字机会打出来
使得两人可以长距离沟通
基本是个蒸汽朋克版聊天室
因为电传打字机有电子接口，稍作修改就能用于计算机
电传交互界面在 1960~1970 很常见
用起来很简单
输入一个命令，按回车，然后计算机会输回来
用户和计算机来回"对话"
这叫"命令行界面"
它是最主要的人机交互方式，一直到 1980 年代
用电传打字机的命令行交互  类似这样：
用户可以输入各种命令
我们来看几个命令，先看当前目录有什么文件
输入命令 ls，名字来自 list 的缩写
然后计算机会列出 当前目录里的所有文件
如果想看 secretStarTrekDiscoveryCast.txt 有什么
要用另一个命令 显示文件内容
unix 用 cat 命令显示文件内容 \N cat 是连接(concatenate)的缩写
然后指定文件名，指定的方法是写在 cat 命令后面 \N 传给命令的值叫 参数
如果同一个网络里有其他人
你可以用 finger 命令找朋友 \N 就像是个很原始的"找朋友" App
电传打字机 直到1970年代左右都是主流交互方式
尽管屏幕最早出现在 1950 年代 \N 但对日常使用太贵 而且分辨率低
然而因为针对普通消费者的电视机开始量产 \N 同时处理器与内存也在发展
到1970年代，屏幕代替电传打字机 变得可行
但与其为屏幕  专门做全新的标准
工程师直接用现有的 电传打字机协议
屏幕就像无限长度的纸 \N 除了输入和输出字，没有其它东西
协议是一样的，所以计算机分不出是纸还是屏幕
这些"虚拟电传打字机"或"玻璃电传打字机"\N 叫 终端
到1971年，美国大约有 7 万台电传打字机 \N 以及 7 万个终端
屏幕又好又快又灵活
如果删一个错别字 会立刻消失
所以到 1970 年代末  屏幕成了标配
你也许会想，命令行界面太原始了 \N 做不了什么有意思的事
即便只有文字 \N 程序员也找到了一些方法，让它变得有趣一些
早期的著名交互式文字游戏  Zork
出现于 1977 年
早期游戏玩家需要丰富的想象力
想像自己身在虚构世界，比如"四周漆黑一片
附近可能有怪物会吃掉你"
我们用命令行玩玩看
就像之前，我们可以用 ls 命令，看当前目录有什么
然后用 cd 命令，进入游戏文件夹 \N cd 的意思是 "改变文件夹"
再用 ls 看有哪些游戏
超棒！我们有"冒险旅程"！(adventure)
想运行这个程序，只需要输入它的名字
在程序自行停止或我们主动退出前 \N 它会接管命令行
你现在看到的，是"巨大洞穴冒险"这款游戏的真实输出
由 Will Crowther 在 1976 年开发
游戏中，玩家可以输入1个词或2个词的命令 \N 来移动人物，和其他东西交互，捡物品等
然后游戏会像旁白一样，输出你的当前位置， \N 告诉你能做什么动作，以及你的动作造成的结果
有些动作会导致死亡！
原始版本只有 66 个地方可供探索
但它被广泛认为是最早的互动式小说
游戏后来从纯文字进化成多人游戏 \N 简称 MUD，或多人地牢游戏
是如今 MMORPG 的前辈 \N （大型多人在线角色扮演游戏）
如果你想了解游戏史，我们有游戏速成课  \N 主持人 Andre Meadows
命令行界面虽然简单  但十分强大
编程大部分依然是打字活 \N 所以用命令行比较自然
因此，即使是现在  \N 大多数程序员工作中依然用命令行界面
而且用命令行访问远程计算机 是最常见的方式 \N 比如服务器在另一个国家
如果你用 Windows, macOS, Linux
你的计算机有命令行界面，但你可能从来没用过
你可以在 Windows 搜索栏中输入 cmd
或在 Mac 上搜 Terminal
然后你可以装 Zork 玩！
现在你知道了 \N 早期计算机的发展是如何影响到现在的.
想想要是手机没有 QWERTY 键盘 \N 在 Instagram 给图片配标题可就麻烦了
但我们还有一个重要话题没讲
美妙的图形界面！
这是下周的主题
下周见

这台 1960 年的 PDP-1 \N 是一个早期图形计算机的好例子
你可以看到 左边是柜子大小的电脑
中间是电传打字机
右边是一个圆形的屏幕
注意它们是分开的
因为当时文本任务和图形任务是分开的.
事实上，早期的屏幕无法显示清晰的文字
而打印到纸上  有更高的对比度和分辨率
早期屏幕的典型用途 是跟踪程序的运行情况
比如寄存器的值
如果用打印机 \N 一遍又一遍打印出来没有意义
不仅费纸而且慢
另一方面，屏幕更新很快，对临时值简直完美
但屏幕很少用于输出计算结果，结果一般都打印到纸上
或其它更永久的东西上
但屏幕超有用 \N 到1960年代，人们开始用屏幕做很多酷炫的事情
几十年间出现了很多显示技术
但最早最有影响力的是 阴极射线管（CRT）
原理是把电子发射到 有磷光体涂层的屏幕上
当电子撞击涂层时 会发光几分之一秒
由于电子是带电粒子，路径可以用磁场控制
屏幕内用板子或线圈  把电子引导到想要的位置
上下左右都行
既然可以这样控制，有 2 种方法绘制图形 \N 1. 引导电子束描绘出形状
这叫"矢量扫描"
因为发光只持续一小会儿 \N 如果重复得足够快 可以得到清晰的图像
2. 按固定路径，一行行来 \N 从上向下，从左到右，不断重复
只在特定的点打开电子束，以此绘制图形
这叫 "光栅扫描"
用这种方法，可以用很多小线段绘制形状  甚至文字
最后，因为显示技术的发展
我们终于可以在屏幕上显示清晰的点，叫"像素"
液晶显示器，简称 LCD
和以前的技术相当不同
但 LCD 也用光栅扫描 \N 每秒更新多次 像素里红绿蓝的颜色
有趣的是，很多早期计算机不用像素
- 不是技术做不到, 而是因为像素占太多内存
200像素×200像素的图像，有 40,000 个像素
哪怕每个像素只用一个 bit 表示 \N 代表黑色或白色，连灰度都没有！
- 会占 40,000 bit 内存 \N 比 PDP-1 全部内存的一半还多
所以计算机科学家和工程师，得想一些技巧来渲染图形 \N 等内存发展到足够用
所以早期计算机不存大量像素值 \N 而是存符号，80x25个符号最典型
总共 2000 个字符
如果每个字符用 8 位表示，比如用 ASCII
总共才 16000 位，这种大小更合理
为此，计算机需要额外硬件
来从内存读取字符，转换成光栅图形 \N 这样才能显示到屏幕上
这个硬件叫 "字符生成器"，基本算是第一代显卡
它内部有一小块只读存储器，简称 ROM
存着每个字符的图形，叫"点阵图案"
如果图形卡看到一个 8 位二进制，发现是字母 K
那么会把字母 K 的点阵图案 \N光栅扫描显示到屏幕的适当位置
为了显示，"字符生成器" 会访问内存中一块特殊区域 \N 这块区域专为图形保留，叫 屏幕缓冲区
程序想显示文字时，修改这块区域里的值就行
这个方案用的内存少得多 \N 但也意味着 只能画字符到屏幕上
即使有这样限制 \N 人们用 ASCII 艺术发挥了很多创意！
也有人用字符模仿图形界面
用下划线和加号来画盒子，线，和其他简单形状
但字符集实在太小，做不了什么复杂的事
因此对 ASCII 进行了各种扩展，加新字符
比如上图的 IBM CP437 字符集，用于 DOS.
某些系统上 \N 可以用额外的 bit 定义字体颜色和背景颜色
做出这样的 DOS 界面 \N 这界面只用了刚刚提到的字符集
字符生成器 是一种省内存的技巧 \N 但没办法绘制任意形状
绘制任意形状很重要 \N 因为电路设计，建筑平面图，地图，好多东西都不是文字！
为了绘制任意形状，同时不吃掉所有内存
计算机科学家用 CRT 上的"矢量模式"
概念非常简单：所有东西都由线组成
没有文字这回事
如果要显示文字，就用线条画出来
只有线条，没有别的
明白了吗？好，我们举个实例吧
假设这个视频是一个 笛卡尔平面 \N 200个单位宽，100个单位高
原点 (0,0) 在左上角
我们可以画形状，用如下矢量命令
这些命令来自 Vectrex，一个早期矢量显示系统
首先，reset ，这个命令会清空屏幕
把电子枪的绘图点移动到坐标 (0,0)
并把线的亮度设为 0
MOVE_TO 50 50 \N 把绘图点移动到坐标 (50,50)
INTENSITY 100 \N 把强度设为 100
现在亮度提高了\N 移动到 (100,50)  然后 (60,75)  然后 (50,50)
最后把强度设回 0
酷，我们画了一个三角形！
这些命令占 160 bit  \N 比存一个庞大的像素矩阵更好
就像之前的"字符生成器" \N把内存里的字符转成图形一样
这些矢量指令也存在内存中 \N 通过矢量图形卡画到屏幕上
数百个命令可以按序存在屏幕缓冲区
画出复杂图形，全是线段组成的！
由于这些矢量都在内存中 \N 程序可以更新这些值
让图形随时间变化 - 动画！
最早的电子游戏之一, Spacewar!
是 1962 年在 PDP-1 上用矢量图形制作的.
它启发了许多后来的游戏，比如 爆破彗星(Asteroids)
甚至第一个商业街机游戏：太空大战
1962 年是一个大里程碑 \N  Sketchpad 诞生
一个交互式图形界面，用途是计算机辅助设计 (CAD)
它被广泛认为是第一个完整的图形程序
发明人 伊万·萨瑟兰 后来因此获得图灵奖
为了与图形界面交互 \N Sketchpad 用了当时发明不久的输入设备 光笔
就是一个有线连着电脑的触控笔
笔尖用光线传感器，可以检测到显示器刷新
通过判断刷新时间，电脑可以知道笔的位置
有了光笔和各种按钮 \N 用户可以画线和其他简单形状
Sketchpad 可以让线条完美平行，长度相同 \N 完美垂直90度，甚至动态缩放
这些在纸上很费力，在计算机上非常简单！
用户还可以保存设计结果，方便以后再次使用 \N 甚至和其他人分享
你可以有一整个库 \N 里面有电子元件和家具之类的
可以直接拖进来用
从如今的角度来看 好像很普通
但在1962年 \N 计算机还是吃纸带的大怪兽，有柜子般大小
Sketchpad 和光笔让人大开眼界
它们代表了人机交互方式的关键转折点
电脑不再是关在门后 负责算数的机器了
可以当助手 帮人类做事
最早用真正像素的计算机和显示器\N 出现于 1960 年代末
内存中的位(Bit) 对应屏幕上的像素
这叫 位图显示
现在我们可以绘制任意图形了
你可以把图形想成一个巨大像素值矩阵
就像之前
计算机把像素数据存在内存中一个特殊区域 \N 叫"帧缓冲区"
早期时，这些数据存在内存里\N 后来存在高速视频内存里，简称 VRAM
VRAM 在显卡上，这样访问更快 \N 如今就是这样做的.
在 8 位灰度屏幕上，我们可用的颜色范围是 0 强度（黑色）
到 255 强度(白色)
其实更像绿色或橙色 \N 因为许多早期显示器不能显示白色
我们假设 这个视频在低分辨率的位图屏幕上
分辨率 60x35像素
如果我们想把 (10,10) 的像素设为白色 \N 可以用这样的代码
如果想画一条线  假设从(30,0)到(30,35) \N 可以用这样一个循环
把整列像素变成白色
如果想画更复杂的图形，比如矩形，那么需要四个值
1. 起始点X坐标  \N2. 起始点Y坐标 \N 3. 宽度 \N 4. 高度
目前只试了白色，这次画矩形试下灰色
灰色介于0到255中间 \N 所以我们用 127 (255/2=127.5)
然后用两个循环，一个套另一个
这样外部每跑一次，内部会循环多次 \N 可以画一个矩形
计算机绘图时会用指定的颜色 127
我们来包装成 "画矩形函数"，就像这样：
假设要在屏幕的另一边 画第二个矩形 \N 这次可能是黑色矩形
可以直接调用 "画矩形函数", 超棒！
就像之前说的其他方案
程序可以操纵"帧缓冲区"中的像素数据，实现交互式图形
乒乓球时间！
当然，程序员不会浪费时间从零写绘图函数 \N 而是用预先写好的函数来做，画直线，曲线，图形，文字等
一层新抽象！
位图的灵活性，为交互式开启了全新可能 \N 但它的高昂成本持续了十几年
上集提到，1971 年 \N 整个美国也只有大约 7 万个电传打字机和 7 万个终端
令人惊讶的是 \N 只有大约 1000 台电脑有交互式图形屏幕
这可不多！
Sketchpad 和 太空大战 这样的先驱  \N 推动了图形界面发展
帮助普及了计算机显示器 \N 由此，图形界面的曙光初现
接下来讲图形界面
下周见

之前介绍了计算机历史 \N 从人类文明的曙光开始 (第1集）
一直到 1940 年代中期  电子计算机诞生
过去 23 集里讲的很多东西
比如编程语言和编译器，算法和集成电路
软盘和操作系统，电报机和屏幕
全都是1940~1970年代，大概这30年间里出现的
那时苹果和微软还不存在，也没有推特，谷歌或者 Uber.
还没到个人电脑时代
而万维网，无人驾驶汽车，虚拟现实等主题，\N 这个系列的后半部分会讲
今天, 我们不管电路和算法 \N 来聊聊这个影响力巨大的时代
我们会把重点放在 \N 冷战，太空竞赛，全球化，消费主义的兴起.
1945年二战结束后不久
两个超级大国的关系越发紧张，美国和苏联开始了冷战
因此政府往科学和工程学 投入大量资金
计算机在战时已经证明了自身的价值 \N 比如曼哈顿计划 和 破解纳粹通讯加密
所以政府大量投入资源 \N 各种雄心勃勃的项目得以进行
比如之前提过的 ENIAC, EDVAC, Atlas, Whirlwind
这种高速发展，如果仅靠商业运作是根本无法做到的
要依靠销售收回开发成本.
1950年代，事情开始发生变化,
特别是 Univac 1，它是第一台取得商业成功的电脑
不像 ENIAC 或 Atlas \N Univanc 1 不是一台机器，而是一个型号
一共造了40多台
大部分 Univac 去了政府或大公司
成为美国日益增长的军事工业综合体的一部分
因为政府有钱承担这些尖端科技.
一个著名的例子是，\N 一台给 美国原子能委员会 生产的 Univac 1
被 CBS 用来预测 1952 年美国总统大选的结果
仅用1％的选票，Univac 1 正确预测了结果. \N 艾森豪威尔 获得压倒性胜利，而专家预测 史蒂文森 会赢
这次事件把计算机推到了公众面前
计算机和以前的机器不一样
以前的机器 增强人类的物理能力
比如卡车能带更多东西，自动织布机更快
机床更精确 等等. 这些东西代表了工业革命.
而计算机增强的是人类智力
范内瓦·布什 看到了这种潜力 \N 他在1945年发表了一篇文章
描述了一种假想计算设备叫 Memex
可以用这个设备 \N 存自己所有的书, 其他资料 以及和别人沟通
而且数据是按照格式存储, \N 所以可以快速查询，有很大灵活性.
可以辅助我们的记忆
他还预测会出现 新的百科全书形式
信息之间相互链接
听起来是不是很熟悉？（维基百科）
Memex 启发了  之后几个重要里程碑
比如上集 伊万·萨瑟兰 的 Sketchpad(画板)
以及后面很快会讲到 \N Dough Engelbart 的 oN-LINE 系统（第26集）
范内瓦·布什 \N 做过"美国科学研究与开发办公室"的头头
这个部门负责在二战期间 \N 资助和安排科学研究
冷战时 范内瓦·布什 到处游说，\N 想建立一个职责类似，但是在和平时期运作的部门
因此 国家科学基金会 于1950年成立
至今，国家科学基金会 \N 依然负责给科学研究 提供政府资金
美国的科技领先全球，主要原因之一就是这个机构.
1950年代，消费者开始买晶体管设备
其中值得注意的是 收音机
它又小又耐用，用电池就够了，而且便携
不像 1940 年代之前的收音机，用的是真空管.
收音机非常成功，卖的像"菲比精灵"和 iPhone 一样畅销.
日本政府也在寻求工业机会，想振兴战后经济，
他们很快动手从贝尔实验室 取得晶体管的授权
帮助振兴日本的半导体和电子行业
1955年，索尼的第一款产品面世
TR-55 晶体管收音机. 他们把重心放在质量和价格.
因此日本公司在短短5年内，就占有了美国便携式收音机市场的一半.
这为日本成为美国的强大工业对手，埋下伏笔
1953年，整个地球大概有100台计算机
苏联这时的计算机科技  只比西方落后几年
苏联在1950年 \N完成了第一个可编程电子计算机
但苏联在太空竞赛远远领先
我们进入思想泡泡
苏联在1957年 \N 把第一个卫星送上轨道，史波尼克1号
不久，在1961年
苏联宇航员 尤里·加加林 第一个进入太空
美国民众对此不满
使得肯尼迪总统 \N 在加加林太空任务一个月后
提出要登陆月球. 登月很贵的!
NASA 的预算增长了几乎十倍,
在 1966 年达到顶峰，占了政府预算的4.5%
如今, NASA 的预算只占 0.5%
NASA 用这笔钱资助各种科学研究
阿波罗计划花的钱最多，雇了40万人左右
而且有2万多家大学和公司参与.
其中一个挑战是 怎样在太空中导航
NASA 需要电脑计算复杂的轨道来引导太空船
因此，他们造了 "阿波罗导航计算机"
有3个重要要求
1. 计算机要快, 这在意料之中.
2. 计算机要又小又轻.
太空船里的空间不多
而且要飞去月球，能轻一点是一点
3. 要超级可靠
这对太空船非常重要，因为太空中有很多震动，辐射，极端温度变化
如果东西坏掉了，可没办法去"百思买"买新的
那时的主流科技 \N 真空管和晶体管 无法胜任这些要求
那个时代的主流科技，真空管和离散晶体管，无法胜任这些要求.
所以 NASA 用全新科技：集成电路
我们几集前聊过
阿波罗导航计算机 首先使用了集成电路
NASA 是唯一负担得起集成电路的组织
最初，一个芯片差不多50美金
导航计算机需要上千个芯片
但美国也因此成功登月，打败苏联
谢了 思想泡泡
虽然人们经常把集成电路的发展 \N 归功于阿波罗导航计算机
但它们的产量很低，一共只有 17 次阿波罗任务
实际上是军事 大大推进了集成电路发展
特别是洲际导弹和核弹，使集成电路大规模生产
美国建造强大计算机时，也进一步推进了集成电路
一般叫"超级计算机"，\N 因为它们经常比全球最快电脑还快10倍以上
但 CDC，Cray，IBM 制造的计算机非常昂贵
几乎只有政府负担得起
这些计算机用于政府机构，比如美国国家安全局
以及实验室比如  \N 劳伦斯·利弗莫尔 实验室 \N  洛斯·阿拉莫斯 国家实验室
最初，美国的半导体行业 \N 靠高利润政府合同起步
因此忽略了消费者市场，因为利润小
因此日本半导体行业在1950和1960年代 \N 靠低利润率占领了消费者市场
日本人投入大量资金，大量制造以达到规模经济
同时研究技术，提高质量和产量 \N 以及用自动化来降低成本
1970年代，太空竞赛和冷战逐渐消退 \N 高利润的政府合同变少
美国的半导体和电子设备公司发现更难竞争了
虽然很多计算机组件商品化了，但并没有什么帮助
DRAM 就是 DRAM
能从日立买便宜的，干嘛要从英特尔买贵的？
1970年代 美国公司开始缩小，合并，或直接倒闭
1974年 英特尔不得不裁员三分之一
知名的仙童半导体也在 1979 年濒临倒闭 \N 被其他公司收购了
为了生存，很多公司把生产外包出去，降低成本
英特尔不再把精力放在 内存集成电路 \N 而是把精力放在处理器
这个决定最后挽救了公司
美国公司的无力 \N 导致 夏普 和 卡西欧 这样的日本公司
占领了1970年代的主流产品
手持计算器
因为集成电路，计算机又小又便宜
取代了办公室里昂贵的桌面计算器
对大多数人 \N 这是他们第一次不必用纸笔和计算尺来做计算
手持计算机因此大卖
进一步降低了集成电路的成本
使得微处理器被广泛使用
比如之前讨论过的 Intel 4004
Intel 在1971年 \N 应日本计算器公司 Busicom 的要求做了这个芯片
很快，日本电子产品到处都是
从电视到手表到随身听
而廉价的微处理器，也催生了全新的产品，比如街机游戏
1972年诞生了Pong，1976年诞生了打砖块
因为成本不断下降
很快，普通人也买得起计算机了
这段期间，第一批家用电脑开始出现，比如1975年的 Altair 8800
以及第一款家用游戏机，比如1977年的Atari 2600
家用！我再说一遍 家用！
如今没什么大不了的.
但那时是计算机的全新时代
在短短三十年内，计算机从大到人类可以在 CPU 里走来走去
当然，你要有政府许可你这样做.
发展到小到小孩都能拿住的手持玩具，而且微处理器还快得多.
这种巨大变化是由两种力量推动的：政府和消费者
政府资金，比如冷战期间美国投入的钱
推动了计算机的早期发展
并且让计算机行业活得足够久，使得技术成熟到可以商用
然后是公司，最后是消费者，把计算机变成了主流
冷战虽然结束了，但这种关系今天仍在继续
政府依然在资助科学研究
情报机构依然在超级计算机
人类仍然被发射到太空里
而你依然在买电视，Xbox，Playstation，笔记本电脑和手机
因此，计算机会继续飞速发展
我们下周见

上周说过"个人计算机"的概念 \N 在计算机发展的头 30 年难以想象
如果只让一个人用，成本实在太高
但到 70 年代初，各种组件的成本都下降了 \N 可以做出低成本  同时性能足够强大的计算机
不是玩具级计算机，是真正能用的计算机
这个转变中 \N 最有影响力的是 单芯片 CPU 的出现
强大 + 体积小 + 便宜
集成电路的进步，也提供了低成本固态存储器
可以用于计算机的 RAM 和 ROM
忽然间 \N 把整台计算机做到一张电路板上成为可能
大大地降低了制造成本
而且，那时有便宜可靠的储存介质 \N 比如磁带和软盘
最后是 低成本的显示器 \N 通常是电视机稍作改装而成
如果在 1970 年代 \N 将这四种原料混在一起
就得到了"微型计算机"
因为和那个时代的"普通"计算机相比 \N 这些计算机很小
"普通"计算机就是公司或大学里的那种
但比大小更重要的是成本
这是有史以来第一次，计算机的价格足够低
"一个人专用"的想法变得可行
不用划分时间和别人公用计算机
没有多用户登录，计算机只属于一个人，只有一个用户
个人计算机时代到来
计算机成本下降+性能提升, 让个人计算机成为可能
但这个时间点很难准确定义, 并没有一个具体时间点
因此"第一台个人计算机"这个名号，有很多竞争者
比如 Kenback-1 和 MCM/70
不过第一台取得商业成功的个人计算机 \N 争议较小：Altair 8800
首次亮相在 1975 年《Popular Electronics》封面
售价 $439 美元，需要自己组装
计算通货膨胀后，相当如今的 2000 美元左右
不算小钱，但比起 1975 年的其它计算机，算是非常便宜了
各种需要自己组装的组件包  \N卖给了计算机爱好者
因为买的人多，很快相关产品出现了
比如内存，纸带读取器，甚至电传接口
让你可以从纸带上读取更长更复杂的程序
然后用电传终端交互
但程序还是要用 机器码 写
写起来很麻烦，即使计算机爱好者也讨厌写
这没有吓跑年轻的比尔·盖茨和保罗·艾伦
他们当时是19岁和22岁
他们联系了制造 Altair 8800 的 MITS 公司
建议说，如果能运行 BASIC 程序 \N 会对爱好者更有吸引力
BASIC 是一门更受欢迎更简单的编程语言
为此，他们需要一个程序 \N 把 BASIC 代码转成可执行机器码
这叫 解释器 (interpreter)
"解释器"和"编译器"类似
区别是"解释器"运行时转换\N而"编译器"提前转换
让我们进入思想泡泡！
MITS 表示感兴趣
同意与 Bill 和 Paul 见个面，让他们演示一下
问题是，他们还没写好解释器
所以他们花了几个星期赶工 \N 而且还不是在 Altair 8800 上写的
最后在飞机上完成了代码
他们在墨西哥 阿尔伯克基（城市） \N 的 MITS 总部做演示时，才知道代码可以成功运行
幸运的是进展顺利 \N MITS 同意在计算机上搭载他们的软件
Altair BASIC 成了微软的第一个产品
虽然1975年之前就有计算机爱好者
但 Altair 8800 大量催生了更多计算机爱好者
爱好者们组成各种小组 \N 分享知识，软件，以及对计算机的热爱
最具传奇色彩的小组是"家酿计算机俱乐部"
第一次小组聚会在1975年3月
看一台第一批运来加州的 Altair 8800
第一次聚会上，24岁的 Steve Wozniak  \N 被 Altair 8800 大大激励
开始想设计自己的计算机
1976年5月，他向小组展示了原型机
并且把电路图分享给感兴趣的其他会员
他的设计不同寻常 \N 要连到电视显示，并提供文本界面
在低成本计算机上还是第一次见
同是俱乐部成员和大学朋友的 史蒂夫·乔布斯
建议说与其免费分享设计，不如直接出售装好的主板
但用户依然需要自己加键盘，电源和机箱
1976年7月开始发售，价格$666.66美元
它叫 Apple-I ，苹果计算机公司的第一个产品
谢了 思想泡泡
就像 Altair 8800 一样，Apple-I 也是作为套件出售
Apple-I 吸引了业余爱好者 \N 不介意机器买回来自己组装
但个人消费者和公司对 Apple-I 不感兴趣
这在 1977 年发生变化 \N 市场上有了三款开箱即用的计算机
第一款是 Apple-II
苹果公司第一个提供全套设备的产品
设计和制造工艺都是专业的
它还提供了简单彩色图形和声音输出
这些功能对低成本机器非常了不起
Apple-II 卖了上百万套
把苹果公司推到了个人计算机行业的前沿
第二款是"TRS-80 1型"
由 Tandy 公司生产
由 Radioshack 销售，所以叫 TRS
虽然不如 Apple-II 先进 \N 但因为价格只有一半，所以卖得很火爆
最后一款是 Commodore PET 2001
有一体化设计
集成了计算机，显示器，键盘和磁带驱动器
目标是吸引普通消费者
计算机和家用电器之间的界限开始变得模糊
这3台计算机被称为1977年的"三位一体"
它们都自带了 BASIC 解释器
让不那么精通计算机的人也能用 BASIC 写程序
针对消费者的软件行业 开始腾飞
市场上出现了各种 \N 针对个人计算机的游戏和生产力工具
比如计算器和文字处理器
最火的是 1979 年的 VisiCalc
第一个电子表格程序
比纸好无数倍
是微软 Excel 和 Google Sheets 的老祖先
但这些计算机带来的最大影响 \N 也许是他们的营销策略
它们针对普通消费者 \N 而不是企业和爱好者
这是第一次大规模地
计算机出现在家庭，小公司，以及学校中
这引起了全球最大计算机公司 IBM 的注意
其市场份额从1970年的60％ \N 在1980年降到了30％左右
因为IBM忽略了增长的"微型计算机"市场
这个市场每年增长约40％
随着微型计算机演变成个人计算机 \N IBM 知道他们需要采取行动
但要做到这一点 \N 公司要从根本上重新思考战略和设计
1980年 IBM 最便宜的计算机 \N "5120"的价格大概是一万美元
永远也没法和 Apple-II 这样的计算机竞争
意味着要从头开始
一个由十二名工程师组成的精干团队（后来叫"肮脏十二人"）
被派往佛罗里达州的 \N 博卡拉顿（Boca Raton）办公室
让他们独立工作
不受 IBM 内部的政治斗争干扰 \N 他们想怎么设计怎么设计
没用 IBM 的 CPU，选了 Intel 的芯片
也没用 IBM 的首选操作系统 CP/M
而是用了微软的 DOS
依此类推，从屏幕到打印机都这样自由选择
IBM 第一次不得不与外部公司竞争
来给新计算机做硬件和软件
这和 IBM 的传统做法不同：自己做硬件来节省成本
然后和其它公司合作
经过短短一年
IBM 个人计算机发布了，简称 IBM PC
产品立马取得了成功
长期信任 IBM 品牌的企业买了很多
但最有影响力的是 \N 它使用 "开放式架构"
有良好的文档和扩展槽
使得第三方可以做硬件/外设
包括显卡，声卡，外置硬盘，游戏控制杆 \N 以及无数其它组件
这刺激了创新，激发了竞争，产生了巨大的生态系统
这个开放架构叫 IBM Compatible"（IBM 兼容）
意味着如果买了"IBM兼容"的计算机
你可以用庞大生态系统中的其它软硬件
开放架构也意味着 竞争对手公司可以遵循这个标准
做出自己的"IBM 兼容"计算机
很快，康柏和戴尔也开始卖 PC
微软很乐意把 MS-DOS 授权给他们
使 DOS 迅速成为最受欢迎的 PC 操作系统
仅在前三年 \N IBM就卖出了200万台 PC ，超过了苹果
有了庞大用户群，软件和硬件开发人员 \N 把精力放在"IBM 兼容"平台，因为潜在用户更多
同时，想买计算机的人 \N 也会看哪种计算机的软硬件选择更多
就像雪球效应一样
而那些生产非"IBM兼容"计算机的公司 （一般性能更好）
都失败了
只有苹果公司在没有"IBM兼容"的情况下 \N 保持了足够市场份额
苹果公司最终选了相反的方式："封闭架构"
即自己设计一切，用户一般无法加新硬件到计算机中
意味着苹果公司要做自己的计算机，自己的操作系统
还有自己的外围设备，如显示器，键盘和打印机
通过控制整个范围，从硬件到软件
苹果能控制用户体验并提高可靠性
不同的商业策略是"Mac vs PC 谁更好"这种争论的起源
这些争论如今还存在 \N 不过"Mac vs PC"用词不对，因为它们都是个人计算机！
但是随便啦
为了在低成本个人计算机的竞争冲击下生存下来
苹果需要提高自身水平 \N 提供比 PC 和 DOS 更好的用户体验
他们的答案是 Macintosh，于 1984 年发布
一台突破性 价格适中的一体式计算机 \N 用的不是命令行界面，而是图形界面
我们下周讨论图形界面. 到时见

我们上集最后 \N 谈了苹果在1984年发布的 Macintosh
这是普通人可以买到的 \N 第一台带图形用户界面的计算机
还带一个鼠标
那时的计算机全是命令行 \N 图形界面是个革命性进展
不必记住或猜正确的命令
我们不必记住或猜测正确的命令
图形界面直接显示了，你可以做什么
只要在屏幕上找选项就行了
这是一个"选择并点击"的界面
突然间计算机更直观了
不只是爱好者或科学家能用计算机 \N 任何人都可以用计算机解决问题
人们认为是 Macintosh \N 把图形用户界面（GUI）变成主流
但实际上图形界面是数十年研究的成果
前几集，我们讨论了早期的交互式图形程序
比如 Sketchpad 和太空战争 \N 都是1962年制作的
但都是一次性项目，不是整合良好的体验
现代图形界面的先驱 \N 可以说是 道格拉斯·恩格尔巴特
让我们进入思想泡泡！
二战期间 \N 恩格尔巴特 驻扎在菲律宾做雷达操作员
他读了 万尼瓦尔·布什 的 Memex 文章
这些文章启发了他
当他海军服役结束时
他回到学校  \N 1955年在 UCB 取得博士学位
他沉溺于新兴的计算机领域
他在1962年一份开创性报告中 \N 汇集了各种想法
报告名为："增强人类智力"
恩格尔巴特认为，人类面临的问题 \N 比解决问题的能力增长得更快
因此，找到增强智力的方法 \N 似乎是必要且值得一做的目标
他构想计算机不仅做自动化工作
也可以成为未来知识型员工 \N 应对复杂问题的工具
伊凡·苏泽兰 的"几何画板" \N 进一步启发了 恩格尔巴特
他决定动手把愿景变为现实 \N 开始招募团队来做 oN-Line System
他意识到如果只有键盘 \N 对他想搭建的程序来说是不够的
用他的话说：
"我们设想人们用计算机辅助工作站来增强工作
用户需要和屏幕上的信息互动
用某种设备在屏幕上移动[光标]"
1964年，和同事比尔·英格利希的共同努力下
他创造了第一个计算机鼠标，尾部有一根线
看起来很像老鼠 \N 因此"鼠标"这个名字沿用了下来
谢了思想泡泡！
1968年 恩格尔巴特 \N 在"秋季计算机联合会议"展示了他的系统
这次演示 被视为如今所有演示的祖先
演示有90分钟 \N 展现了现代计算机的许多功能：
包括 位图图像
视频会议
文字处理
和 实时协作编辑文件
还有现代图形界面的原型  比如鼠标和多窗口
- 不过窗口不能重叠
远远先于那个时代
就像其它"跨时代"的产品一样，它最终失败了
至少商业上是这样
但它对当时的计算机研究者影响巨大
恩格尔巴特 因此获得1997年图灵奖
政府资金在 1970 年代初开始减少
我们在两集前说过\N（第24集：冷战和消费主义）
那时，恩格尔巴特团队里的许多人，包括比尔·英格利希
去了施乐公司新成立的"帕洛阿尔托研究中心"
更为人熟知的名字是 Xerox PARC
他们在这里开发了第一台带真正 GUI 的计算机：
施乐奥托  于1973年完成
为了让计算机易于使用，需要的不只是花哨的图形
还要借助一些人们已经熟悉的概念
让人们不用培训 就能很快明白如何使用
施乐的答案是将2D屏幕当作"桌面"
就像桌面上放很多文件一样
用户可以打开多个程序 \N 每个程序都在一个框里，叫"窗口"
就像桌上的文件一样
窗口可以重叠，挡住后面的东西
还有桌面配件，比如计算器和时钟
用户可以把配件在屏幕上四处移动
它不是现实桌面的完美复制，而是用桌面这种隐喻
因此叫"桌面隐喻"
有很多方法来设计界面 \N 但 Alto 团队用窗口，图标，菜单和指针来做
- 因此叫 WIMP 界面
如今大部分图形界面都用这个
它还提供了一套基本部件
可复用的基本元素 \N 比如按钮，打勾框，滑动条和标签页
这些也来自现实世界，让人们有熟悉感
GUI 程序就是这些小组件组成的
让我们试着写一个简单例子
首先，我们必须告诉操作系统 \N 为程序创建一个窗口
我们通过 GUI API 实现 \N 需要指定窗口的名字和大小
假设是 500×500 像素
现在再加一些小组件，一个文本框和一个按钮
创建它们需要一些参数
首先要指定出现在哪个窗口 \N 因为程序可以有多个窗口
还要指定默认文字\N 窗口中的 X,Y 位置  以及宽度和高度
好，现在我们有个 \N 看起来像 GUI 程序的东西
但它还没有功能
如果点 Roll 按钮，什么也不会发生
在之前的例子中，代码是从上到下执行的
但 GUI 是 "事件驱动编程"
代码可以在任意时间执行 以响应事件
这里是用户触发事件 \N 比如点击按钮，选一个菜单项，或滚动窗口
或一只猫踩过键盘
就会一次触发好多事件！
假设当用户点 Roll 按钮
我们产生1到20之间的随机数
然后在文本框中，显示这个数字
我们可以写一个函数来做
我们还可以让它变有趣些，假设随机数是 20 \N 就把背景颜色变成血红色！
最后，把代码与"事件"相连 \N 每次点按钮时  都触发代码
那么，要设置事件触发时 \N 由哪个函数来处理
我们可以在初始化函数中，加一行代码来实现
我们要处理的，是"点击"事件 \N 然后函数会处理这个事件
现在完成了
可以点按钮点上一整天 \N 每次都会执行 rollD20 函数
这就是程序背后的原理
在编辑器里点 粗体  或菜单里选 关机 \N 一个处理该事件的函数会触发
希望不会随机到 20
啊！！！
好，现在回到施乐奥托！
大约制作了2000台奥托\N 有的在施乐公司内部用，有的送给大学实验室
从来没有商业出售过
然而，PARC 团队不断完善硬件和软件
最终于1981年发布了 施乐之星系统
施乐之星扩展了"桌面隐喻"
现在文件看起来就像一张纸 \N 还可以存在文件夹里
这些都可以放桌面上，或数字文件柜里
这样来隐喻底层的文件系统
从用户角度来看，是一层新抽象！
施乐卖的是印刷机 \N 但在文本和图形制作工具领域也有领先
例如，他们首先使用了\N  "剪切""复制""粘贴"这样的术语
这个比喻来自编辑打字机文件
真的是剪刀"剪切" \N 然后胶水"粘贴" 到另一个文件
然后再复印一次，新文件就是一层了
看不出编辑的痕迹
感谢计算机的出现！
文字处理软件出现后 \N 这种手工做法就消失了
Apple II 和 Commodore PET 上有文字处理软件
但施乐在这点上走的更远
无论你在计算机上做什么 \N 文件打印出来应该长得一样
他们叫这个"所见即所得"
不幸的是，就像恩格尔巴特的 oN-Line System
施乐之星也领先于那个时代，销售量不高
因为在办公室里配一个，相当如今20万美元
IBM 同年推出了 IBM PC
之后便宜的"IBM兼容"计算机席卷市场
但 PARC 研究人员花了十几年做的这些 \N 没有被浪费
1979年12月，施乐之星出货前一年半
有个人去施乐公司参观 \N 你可能听说过这个人：史蒂夫·乔布斯
这次参观有很多传闻
许多人认为\N 乔布斯和苹果偷走了施乐的创意
但那不是事实
事实上是施乐公司主动找苹果，希望合作
最终施乐还买了苹果的一百万美元股份
在苹果备受瞩目的 首次公开募股(IPO) 前买的
但一个额外条款是：
"公布一切施乐研究中心正在进行的酷工作"
史蒂夫知道他们很厉害
但他完全没预想到这些
其中有个演示是
一个清晰的位图显示器上，运行着施乐公司的图形界面 \N 操作全靠鼠标直观进行
史蒂夫后来说："就像拨开了眼前的一层迷纱
我可以看到计算机产业的未来"
史蒂夫和随行的工程师回到苹果公司，开始开发新功能
比如菜单栏和垃圾桶，垃圾桶存删除文件
满了甚至会膨胀 - 再次使用了隐喻
苹果第一款有图形界面和鼠标的产品
是 1983 年发行的 Apple Lisa
一台超级先进的机器，标了"超级先进"的价格
- 差不多是如今的 25000 美元
虽然比施乐之星便宜不少
但在市场上同样失败
幸运的是，苹果还有另一个项目：
Macintosh，于 1984 年发布
价格大约是如今的6000美元 - Lisa 的四分之一
它成功了，开售100天就卖了7万台
但在最初的狂潮后，销售额开始波动
苹果公司卖的 Apple II 比 Mac 多
一个大问题是：没人给这台新机器做软件
之后情况变得更糟，竞争对手赶上来了
不久，其它价格只有 Mac 几分之一的个人计算机 \N 有了原始但可用的图形界面
消费者认可它们， PC 软件开发者也认可
随着苹果的财务状况日益严峻 \N 以及和苹果新 CEO 约翰·斯卡利 的关系日益紧张
史蒂夫乔布斯被赶出了苹果公司
几个月后，微软发布了 Windows 1.0
它也许不如 Mac OS 漂亮
但让微软在市场中站稳脚跟 \N 奠定了统治地位
十年内，95％的个人计算机上都有微软的 Windows
最初，Mac OS 的爱好者还可以说\N  Mac 有卓越的图形界面和易用性
Windows 早期版本都是基于 DOS \N 而 DOS 设计时 没想过运行图形界面
但 Windows 3.1 之后
微软开始开发新的，\N 面向消费者的 GUI 操作系统
叫 Windows 95
这是一个意义非凡的版本 \N 不仅提供精美的界面
还有 Mac OS 没有的高级功能
比如"多任务"和"受保护内存"
Windows 95 引入了许多 \N 如今依然见得到的 GUI 元素
比如开始菜单，任务栏和 Windows 文件管理器
不过微软也失败过
为了让桌面更简单友好 \N 微软开发了一个产品叫 Microsoft Bob
将比喻用到极致
现在屏幕上有了一个虚拟房间
程序是物品，可以放在桌子和书架上
甚至还有噼啪作响的壁炉 \N 和提供帮助的虚拟狗狗
你看到那边的门没？
是的，那些门通往不同房间 \N 房间里有不同程序
你可能猜到了，它没有获得成功
这是一个好例子，说明如今的用户界面
是自然选择后的结果
无论你用的是 \N Windows，Mac，Linux 或其他 GUI
几乎都是施乐奥托 WIMP 的变化版
一路上，人们试了各种做法并失败了
一切都必须发明，测试，改进，适应或抛弃
如今，图形界面无处不在 \N 使用体验一般只是可以接受，而不是非常好
你肯定体验过差劲的设计
比如下载了很烂的 App，用过别人糟糕的手机
或者看到过很差的网站，因此
计算机科学家和界面设计师 \N 会继续努力工作
做出更好更强大的界面
朝着恩格尔巴特"增强人类智能"的愿景努力
我们下周见

在过去五集
我们从基于电传打字机的命令行界面 \N 讲到图形怎么显示到屏幕上
再到上集的 图形用户界面（GUI）
以及图形界面的美味
之前的例子都是2D, 但我们生活的世界是3D的
我也是个三维 girl~
所以今天，我们讲3D图形的基础知识
以及如何渲染 3D 图形到 2D 屏幕上
24集中说过 \N 可以写一个函数，从A到B画一条线
通过控制 A 和 B 的(X,Y)坐标，可以控制一条线
在3D图像中, 点的坐标不再是两点, 而是三点, X,Y,Z
或读"Zee"，但我之后会读成"Zed"
当然，2D的电脑屏幕上\N不可能有 XYZ 立体坐标轴
所以有图形算法 \N 负责把3D坐标"拍平"显示到2D屏幕上
这叫"3D投影"
所有的点都从3D转成2D后
就可以用画2D线段的函数 来连接这些点
这叫 "线框渲染"
想象用筷子做一个立方体，然后用手电筒照它
墙上的影子就是投射，是平的
如果旋转立方体
投影看起来会像 3D 物体，尽管是投影面是平的
电脑也是这样3D转2D
只不过用大量数学，而不是筷子
3D投影有好几种
你现在看到的，叫 正交投影
立方体的各个边，在投影中互相平行
在真实3D世界中,平行线段会在远处收敛于一点
就像远处的马路汇聚到一点
这叫 透视投射
过程是类似的，只是数学稍有不同
有时你想要透视投影，有时不想
具体取决于开发人员
如果想画立方体这种简单图形，直线就够了
但更复杂的图形，三角形更好
在3D图形学中 \N 我们叫三角形"多边形"(Polygons)
看看这个多边形组成的 漂亮茶壶
一堆多边形的集合叫 网格
网格越密，表面越光滑，细节越多
但意味着更多计算量
游戏设计者要平衡角色的真实度 \N 和多边形数量
如果数量太多 \N 帧率会下降到肉眼可感知，用户会觉得卡
因此有算法用来简化网格
之所以三角形更常用 \N 而不是用正方形，或其它更复杂的图形
是因为三角形的简单性
空间中  三点定义一个平面
如果给3个3D点，我能画出一个平面
而且只有这一个答案
4个或多于4个点就不一定了
而2个点不够定义平面，只能定义线段
所以3是最完美的数字，三角形万岁
线框渲染 虽然很酷，但3D图像需要填充
填充图形的经典算法叫 扫描线渲染 (Scanline Rendering) \N 于1967年诞生在犹他州大学
为了例子简单，我们只看一个多边形
我们要思考 \N 这个多边形如何转成一块填满像素的区域
我们先铺一层像素网格
扫描线算法 先读多边形的3个点
找最大和最小的Y值，只在这两点间工作
然后算法从上往下，一次处理一行
计算每一行和多边形相交的2个点
因为是三角形,如果相交一条边, 必然相交另一条
扫描线算法 会填满2个相交点之间的像素
来看个具体例子
第一行 相交于这里和这里
算法把两点间填满颜色
然后下一行，再下一行，所以叫 扫描..线..渲染
扫到底部就完成了
填充的速度叫 fillrate（填充速率）
当然 这样的三角形比较丑，边缘满是锯齿
当像素较小时 就不那么明显
但尽管如此 \N 你肯定在游戏里见过这种效果，特别是低配电脑
一种减轻锯齿的方法叫\N  抗锯齿(Antialiasing)
与其每个像素都涂成一样的颜色
可以判断多边形切过像素的程度，来调整颜色
如果像素在多边形内部，就直接涂颜色
如果多边形划过像素，颜色就浅一些
这种边缘羽化的效果 看着更舒服些
抗锯齿 被广泛使用，比如字体和图标
如果你把脸贴近屏幕
近点..再近点
你能看到浏览器里字体是抗锯齿的，超平滑
在3D场景中，多边形到处都是
但只有一部分能看见
因为其它的被挡住了
这叫 遮挡
最直接的处理办法是用排序算法
从远到近排列，然后从远到近渲染
这叫 画家算法 因为画家也是先画背景
然后再画更近的东西
看这个例子，有3个重叠的多边形
为了简单，我们画成不同颜色
同时，假设3个多边形都和屏幕平行
但在实际应用中, 比如游戏里\N多边形可能是倾斜的
3个多边形A,B,C，距离20,12,14
画家算法的第一件事，是从远到近排序
现在有序了，我们可以用 扫描线算法 填充多边形，一次填一个
我们从最远的A开始
然后重复这个过程，填充第二远的C
然后是 B
现在完成了，可以看到顺序是对的，近的多边形在前面！
还有一种方法叫 深度缓冲
它和之前的算法做的事情一样，但方法不同
我们回到之前的例子，回到排序前的状态
因为这个算法不用排序，所以速度更快
简而言之，Z-buffering 算法会记录
场景中每个像素和摄像机的距离
在内存里存一个数字矩阵
首先，每个像素的距离被初始化为"无限大"
然后 Z-buffering 从列表里第一个多边形开始处理，也就是A
它和扫描线算法逻辑相同，但不是给像素填充颜色
而是把多边形的距离\N和 Z-Buffer 里的距离进行对比
它总是记录更低的值
A距离20，20小于"无限大"，所以缓冲区记录20
算完A之后算下一个，以此类推
因为没对多边形排序
所以后处理的多边形并不总会覆盖前面的
对于多边形C
缓冲区里只有一部分值会被多边形C的距离值覆盖
Z缓冲区完成后，会和"扫描线"算法的改进高级版配合使用
不仅可以勘测到线的交叉点
还可以知道某像素是否在最终场景中可见
如果不可见，扫描线算法会跳过那个部分
当两个多边形距离相同时 \N 会出现一个有趣问题
比如多边形 A 和 B 距离都是 20, 哪个画上面?
多边形会在内存中移来移去，访问顺序会不断变化
另外,计算浮点数有舍入误差
所以哪一个画在上面, 往往是不可预测的
导致出现 Z-fighting 效果 \N 如果你玩过3D游戏，肯定见过
说起 故障，3D游戏中有个优化叫 背面剔除
你想想,三角形有两面,正面和背面
游戏角色的头部或地面，只能看到朝外的一面
所以为了节省处理时间，会忽略多边形背面
减了一半多边形面数
这很好,但有个bug是 如果进入模型内部往外看
头部和地面会消失
继续，我们讲灯光，也叫 明暗处理
因为3D场景中, 物体表面应该有明暗变化
我们回到之前的茶壶网格
用"扫描线"算法渲染所有多边形后，茶壶看起来像这样
没什么 3D 感
我们来加点灯光，提高真实感
为了举例，我们从茶壶上挑3个不同位置的多边形
和之前的例子不同，这次要考虑这些多边形面对的方向
它们不平行于屏幕，而是面对不同方向
他们面对的方向叫 " 表面法线 "
我们可以用一个垂直于表面的小箭头\N来显示这个方向
现在加个光源
每个多边形被照亮的程度不同 有的更亮
因为面对的角度\N导致更多光线反射到观察者
举个例子，底部的多边形向下倾斜
远离光源，所以更暗一些
类似的，最右的多边形更背对光源
所以只有部分照亮
最后是左上角的多边形
因为它面对的角度  意味着会把光线反射到我们这里
所以会显得更亮
如果对每个多边形执行同样的步骤，看上去会更真实!
这叫 平面着色，是最基本的照明算法
不幸的是，这使多边形的边界非常明显，看起来不光滑
因此开发了更多算法
比如 高洛德着色 和 冯氏着色
不只用一种颜色给整个多边形上色
而是以巧妙的方式改变颜色
得到更好的效果
我们还要说下" 纹理 "
纹理在图形学中指外观，而不是手感
就像照明算法一样，\N 纹理也有多种算法，来做各种花哨效果
最简单的是 纹理映射
为了理解纹理映射，回到单个多边形
用"扫描线算法"填充时
可以看看内存内的纹理图像 决定像素用什么颜色
为了做到这点，\N 需要把多边形坐标和纹理坐标对应起来
我们来看看"扫描线算法"要填充的第一个像素
纹理算法会查询纹理
从相应区域取平均颜色，并填充多边形
重复这个过程，就可以获得纹理
如果结合这集提到的所有技巧 \N 会得到一个精美的小茶壶
这个茶壶可以放进更大的场景里 \N 场景由上百万个多边形组成
渲染这样的场景需要大量计算
但重要的是，再大的场景，过程都是一样的 \N 一遍又一遍，处理所有多边形
扫描线填充, 抗锯齿, 光照, 纹理化
然而，有几种方法可以加速渲染
首先，我们可以为这种特定运算 \N 做专门的硬件来加快速度，让运算快如闪电
其次，我们可以把3D场景分解成多个小部分
然后并行渲染，而不是按顺序渲染
CPU不是为此设计的，因此图形运算不快
所以，计算机工程师为图形做了专门的处理器
叫 GPU "图形处理单元"
GPU 在显卡上，周围有专用的 RAM
所有网格和纹理都在里面
让 GPU 的多个核心可以高速访问
现代显卡，如 GeForce GTX 1080 TI
有3584个处理核心，提供大规模并行处理
每秒处理上亿个多边形！
好了，本集对3D图形的介绍到此结束
下周我们聊全新的主题
我到时会 ping 你~

互联网太棒啦
键盘敲几下就能在 Youtube 直播--哈喽！
在维基百科上阅读文章
在亚马逊买东西  和朋友视频  发一条天气推特
毫无疑问，\N 用户在全球网络中发送和接收信息的能力
永远改变了这个世界
150年前 发一封信件从伦敦到加州 要花2~3周
而且还是特快邮件
如今 电子邮件只要几分之一秒.
"时延"改善了上百万倍 \N (时延指传播一条信息所需的时间)
振兴了全球经济 \N 帮助现代世界在遍布全球的光纤中快速发展
你可能觉得计算机和网络密切相关，但事实上，
1970年以前 大多数计算机是独立运行的
然而 因为大型计算机开始随处可见
廉价机器开始出现在书桌上
分享数据和资源渐渐变得有用起来
首个计算机网络出现了
今天起，我们花3集视频讲网络是如何发展成现在的样子
以及支撑它们的基础原理和技术
第一个计算机网络出现在1950~1960年代
通常在公司或研究室内部使用，为了方便信息交换
比把纸卡或磁带送到另一栋楼里更快速可靠
这叫"球鞋网络"
第二个好处是能共享物理资源
举个例子，与其每台电脑配一台打印机
大家可以共享一台联网的打印机
早期网络也会共享存储空间
因为每台电脑都配存储器太贵了
计算机近距离构成的小型网络 \N 叫局域网， 简称LAN
局域网能小到是同一个房间里的两台机器
或大到校园里的上千台机器
尽管开发和部署了很多不同 LAN 技术
其中最著名和成功的是"以太网"  , 开发于1970年代 \N 在施乐的"帕洛阿尔托研究中心"诞生, 今日仍被广泛使用
以太网的最简单形式是：一条以太网电线连接数台计算机
当一台计算机要传数据给另一台计算机时
它以电信号形式，将数据传入电缆
当然 因为电缆是共享的  \N 连在同一个网络里的其他计算机也看得到数据
但不知道数据是给它们的，还是给其他计算机的
为了解决这个问题 以太网需要每台计算机有唯一的 \N 媒体访问控制地址 简称 MAC地址
这个唯一的地址放在头部，作为数据的前缀发送到网络中
所以，计算机只需要监听以太网电缆 \N 只有看到自己的 MAC 地址，才处理数据
这运作得很好 现在制造的每台计算机都自带唯一的MAC地址
用于以太网和无线网络
多台电脑共享一个传输媒介，\N 这种方法叫 "载波侦听多路访问" 简称"CSMA"
载体(carrier)指运输数据的共享媒介
以太网的"载体"是铜线 \N  WiFi 的"载体"是传播无线电波的空气
很多计算机同时侦听载体
所以叫"侦听"和"多路访问"
而载体传输数据的速度 叫"带宽"
不幸的是 使用共享载体有个很大的弊端
当网络流量较小时 计算机可以等待载体清空
然后传送数据
但随着网络流量上升 两台计算机想同时写入数据的概率也会上升
这叫冲突 数据全都乱套了
就像两个人同时在电话里讲话
幸运的是 计算机能够通过监听电线中的信号检测这些冲突
最明显的解决办法是停止传输
等待网络空闲, 然后再试一遍
问题是 其他计算机也打算这样做
其他等着的计算机可能在任何停顿间隙闯入
导致越来越多冲突
很快，每个人都一个接一个地讲话 而且有一堆事要说
就像在家庭聚餐中和男朋友分手一样
馊主意！
以太网有个超简单有效的解决方法
当计算机检测到冲突 就会在重传之前等待一小段时间
因为要举例，假设是 1 秒好了
当然 如果所有计算机用同样的等待时间 是不行的
它们会在一秒后再次冲突
所以加入一个随机时间 一台计算机可能等1.3秒
另一台计算机等待1.5秒
要是运气好 等1.3秒的计算机会醒来
发现载体是空闲的 然后开始传输
当1.5秒的计算机醒来后 会发现载体被占用 \N 会等待其他计算机完成
这有用 但不能完全解决问题 所以要用另一个小技巧
正如我刚才说的 \N如果一台计算机在传输数据期间检测到冲突
会等一秒+随机时间
然而 如果再次发生冲突 表明有网络拥塞
这次不等1秒，而是等2秒
如果再次发生冲突 等4秒 然后8秒 16秒等等
直到成功传输
因为计算机的退避 冲突次数降低了 \N 数据再次开始流动起来 网络变得顺畅
家庭晚餐有救啦！
这种指数级增长等待时间的方法叫：
指数退避
以太网和WiFi都用这种方法 很多其他传输协议也用
但即便有了"指数退避"这种技巧
想用一根网线链接整个大学的计算机还是不可能的
为了减少冲突+提升效率
我们需要减少同一载体中设备的数量 \N 载体和其中的设备总称 "冲突域"
让我们回到之前以太网的例子  一根电缆连6台计算机
也叫一个冲突域
为了减少冲突  我们可以用交换机把它拆成两个冲突域
交换机位于两个更小的网络之间 \N 必要时才在两个网络间传数据
交换机会记录一个列表 \N 写着哪个 MAC 地址在哪边网络
如果A想传数据给C \N 交换机不会把数据转发给另一边的网络
没必要
如果E想同一时间传数据给F，网络仍然是空的
两个传输可以同时发生
但如果F想发数据给A  数据会通过交换机
两个网络都会被短暂占用
大的计算机网络也是这样构建的
包括最大的网络 - 互联网
也是多个连在一起的稍小一点网络
使不同网络间可以传递信息
这些大型网络有趣之处是
从一个地点到另一个地点通常有多条路线
这就带出了另一个话题 路由
连接两台相隔遥远的计算机或网路，最简单的办法 \N 是分配一条专用的通信线路
早期电话系统就是这样运作的
假设"印第安纳波利斯"和"米苏拉"之间，有五条电话线
如果在1910年代，John 想打电话给 Hank
John要告诉操作员他想打到什么地方
然后工作人员手动将 John 的电话连到 \N 通往米苏拉的未使用线路
通话期间 这条线就被占用了 如果五条线都被占用了 \N John 要等待某条线空出来
这叫 "电路交换"\N因为是把电路连接到正确目的地
能用倒是能用 \N 但不灵活而且价格昂贵 因为总有闲置的线路
好处是 如果有一条专属于自己的线路 \N 你可以最大限度地随意使用，无需共享
因此军队, 银行和其他一些机构
依然会购买专用线路来连接数据中心
传输数据的另一个方法是 "报文交换"
"报文交换" 就像邮政系统一样
不像之前A和B有一条专有线路 \N 消息会经过好几个站点
如果 John 写一封信给 Hank
信件可能从"印第安纳波利斯"到"芝加哥"
然后"明尼阿波利斯" 然后"比林斯" 最后到"米苏拉"
每个站点都知道下一站发哪里 \N 因为站点有表格，记录到各个目的地，信件该怎么传
报文交换的好处是 可以用不同路由 \N 使通信更可靠更能容错
回到邮件的例子
如果"明尼阿波利斯"有暴风雪中断了通信 \N "芝加哥"可以传给"奥马哈"
在这个例子里，城市就像路由器一样
消息沿着路由跳转的次数 \N 叫"跳数"(hop count)
记录跳数很有用，因为可以分辨出路由问题
举例，假设芝加哥认为 \N 去米苏拉的最快路线是 奥马哈
但奥马哈认为 \N 去米苏拉的最快路线是 芝加哥
这就糟糕了\N 因为2个城市看到目的地是米苏拉
结果报文会在2个城市之间\N不停传来传去
不仅浪费带宽 而且这个路由错误需要修复!
这种错误会被检测到，因为跳数记录在消息中 \N 而且传输时会更新跳数
如果看到某条消息的跳数很高 \N 就知道路由肯定哪里错了
这叫"跳数限制"
报文交换的缺点之一是有时候报文比较大
会堵塞网络 因为要把整个报文从一站传到下一站后 \N 才能继续传递其他报文
传输一个大文件时  整条路都阻塞了
即便你只有一个1KB的电子邮件要传输 \N 也只能等大文件传完，或是选另一条效率稍低的路线
这就糟了
解决方法是 将大报文分成很多小块，叫"数据包"
就像报文交换 每个数据包都有目标地址 \N 因此路由器知道发到哪里
报文具体格式由"互联网协议"定义，简称 IP \N 这个标准创建于 1970 年代
每台联网的计算机都需要一个IP地址
你可能见过，以点分隔的4组数字
例如 172.217.7.238 是 Google 其中一个服务器的IP地址
数百万台计算机在网络上不断交换数据 \N 瓶颈的出现和消失是毫秒级的
路由器会平衡与其他路由器之间的负载 \N 以确保传输可以快速可靠，这叫"阻塞控制"
有时，同一个报文的多个数据包 \N 会经过不同线路
到达顺序可能会不一样，这对一些软件是个问题
幸运的是，在 IP 之上还有其他协议
比如 TCP/IP, 可以解决乱序问题
我们下周会讲
将数据拆分成多个小数据包，然后通过灵活的路由传递
非常高效且可容错，如今互联网就是这么运行的
这叫"分组交换"
有个好处是 它是去中心化的
没有中心权威机构  没有单点失败问题
事实上 因为冷战期间有核攻击的威胁，所以创造了分组交换
如今，全球的路由器协同工作，找出最高效的线路
用各种标准协议运输数据
比如 "因特网控制消息协议"(ICMP)
和 "边界网关协议"(BGP)
世界上第一个分组交换网络
以及现代互联网的祖先是 ARPANET
名字来源于赞助这个项目的机构，美国高级研究计划局
这是 1974 年整个 ARPANET 的样子
每个小圆表示一个地点 \N 比如大学或实验室，那里运行着一个路由器
并且有一台或多台计算机
能看到 "PDP-1" 和"IBM 360系统"
甚至还有一个伦敦的 ATLAS \N 是通过卫星连到网络里的
显然 互联网在这几十年间发展迅速
如今不再只有几十台计算机联网 \N 据估计 有接近100亿台联网设备
而且互联网会继续快速发展
特别是如今各种智能设备层出不穷 \N 比如联网冰箱，恒温器
以及其他智能家电，它们组成了"物联网"
第一部分到此结束  \N 我们对计算机网络进行了概览
网络是一堆管子组成的吗？
额 算是吧
下周我们会讨论一些高级传输协议
然后讲万维网
到时见啦

上集讲到，你的计算机和一个巨大的分布式网络连在一起
这个网络叫互联网
你现在就在网上看视频呀
互联网由无数互联设备组成，而且日益增多
计算机为了获取这个视频 \N 首先要连到局域网，也叫 LAN
你家 WIFI 路由器连着的所有设备，组成了局域网.
局域网再连到广域网，广域网也叫 WAN
WAN 的路由器一般属于你的"互联网服务提供商"，简称 ISP
比如 Comcast，AT&T 和 Verizon 这样的公司
广域网里，先连到一个区域性路由器，这路由器可能覆盖一个街区。
然后连到一个更大的 WAN，可能覆盖整个城市
可能再跳几次，但最终会到达互联网主干
互联网主干由一群超大型、带宽超高路由器组成
为了从 YouTube 获得这个视频，
数据包（packet）要先到互联网主干
沿着主干到达有对应视频文件的 YouTube 服务器
数据包从你的计算机跳到 Youtube 服务器，可能要跳个10次，
先跳4次到互联网主干，2次穿过主干，\N主干出来可能再跳4次，然后到 Youtube 服务器
如果你在用 Windows, Mac OS 或 Linux系统，可以用 traceroute 来看跳了几次
更多详情看视频描述（YouTube原视频下）
我们在"印第安纳波利斯"的 Chad&Stacy Emigholz 工作室，\N 访问加州的 DFTBA 服务器，
经历了11次中转
从 192.168.0.1 出发，这是我的电脑在 局域网（LAN）里的 IP 地址
然后到工作室的 WIFI 路由器
然后穿过一个个地区路由器，到达主干.
然后从主干出来，又跳了几次，到达"DFTBA.com”的服务器
IP 地址是 104.24.109.186.
但数据包*到底*是怎么过去的？
如果传输时数据包被弄丢了，会发生什么？
如果在浏览器里输 "DFTBA.com"，浏览器怎么知道服务器的地址多少？
我们今天会讨论这些话题.
上集说过，互联网是一个巨型分布式网络 \N 会把数据拆成一个个数据包来传输
如果要发的数据很大，比如邮件附件 \N 数据会被拆成多个小数据包
举例，你现在看的这个视频 \N 就是一个个到达你电脑的数据包
而不是一整个大文件发过来
数据包（packet）想在互联网上传输 \N 要符合"互联网协议"的标准，简称 IP
就像邮寄手写信一样，邮寄是有标准的\N 每封信需要一个地址，而且地址必须是独特的
并且大小和重量是有限制的
违反这些规定，信件就无法送达.
IP 数据包也是如此
因为 IP 是一个非常底层的协议
数据包的头部（或者说前面）只有目标地址
头部存 "关于数据的数据" \N 也叫 元数据(metadata)
这意味着当数据包到达对方电脑 \N 对方不知道把包交给哪个程序，是交给 Skype 还是使命召唤？
因此需要在 IP 之上，开发更高级的协议.
这些协议里 \N 最简单最常见的叫"用户数据报协议"，简称 UDP
UDP 也有头部，这个头部位于数据前面
头部里包含有用的信息
信息之一是端口号
每个想访问网络的程序 \N 都要向操作系统申请一个端口号.
比如 Skype 会申请端口 3478
当一个数据包到达时 \N 接收方的操作系统会读 UDP 头部，读里面的端口号
如果看到端口号是 3478，就把数据包交给 Skype
总结：\NIP 负责把数据包送到正确的计算机 \N UDP 负责把数据包送到正确的程序
UDP 头部里还有"校验和"，用于检查数据是否正确
正如"校验和"这个名字所暗示的 \N 检查方式是把数据求和来对比
以下是个简单例子
假设 UDP 数据包里 \N 原始数据是 89 111 33 32 58 41
在发送数据包前 \N 电脑会把所有数据加在一起，算出"校验和"
89+111+33+... 以此类推
得到 364，这就是"校验和".
UDP 中，\N"校验和"以 16 位形式存储 (就是16个0或1)
如果算出来的和，超过了 16 位能表示的最大值 \N 高位数会被扔掉，保留低位
当接收方电脑收到这个数据包
它会重复这个步骤 \N 把所有数据加在一起，89+111+33... 以此类推
如果结果和头部中的校验和一致 \N 代表一切正常
如果不一致，数据肯定坏掉了
也许传输时碰到了功率波动，或电缆出故障了
不幸的是，UDP 不提供数据修复或数据重发的机制
接收方知道数据损坏后，一般只是扔掉.
而且，UDP 无法得知数据包是否到达.
发送方发了之后，无法知道数据包是否到达目的地
这些特性听起来很糟糕，但是有些程序不在意这些问题
因为 UDP 又简单又快.
拿 Skype 举例 \N 它用 UDP 来做视频通话，能处理坏数据或缺失数据
所以网速慢的时候 Skype 卡卡的 \N 因为只有一部分数据包到了你的电脑
但对于其他一些数据，这个方法不适用.
比如发邮件，\N 邮件不能只有开头和结尾 没有中间.
邮件要完整到达收件方
如果"所有数据必须到达" \N 就用"传输控制协议"，简称 TCP
TCP 和 UDP 一样，头部也在存数据前面
因此，人们叫这个组合 TCP/IP
就像 UDP ，TCP 头部也有"端口号"和"校验和"
但 TCP 有更高级的功能，我们这里只介绍重要的几个
1. TCP 数据包有序号
15号之后是16号，16号之后是17号，以此类推 \N 发上百万个数据包也是有可能的.
序号使接收方可以把数据包排成正确顺序，即使到达时间不同.
哪怕到达顺序是乱的，TCP 协议也能把顺序排对
2. TCP 要求接收方的电脑收到数据包 \N 并且"校验和"检查无误后（数据没有损坏）\N 给发送方发一个确认码，代表收到了
"确认码" 简称 ACK \N 得知上一个数据包成功抵达后，发送方会发下一个数据包
假设这次发出去之后，没收到确认码 \N 那么肯定哪里错了
如果过了一定时间还没收到确认码 \N 发送方会再发一次
注意 数据包可能的确到了
只是确认码延误了很久，或传输中丢失了
但这不碍事 因为收件方有序列号
如果收到重复的数据包就删掉
还有，TCP 不是只能一个包一个包发
可以同时发多个数据包，收多个确认码 \N 这大大增加了效率，不用浪费时间等确认码
有趣的是，确认码的成功率和来回时间 \N 可以推测网络的拥堵程度
TCP 用这个信息，调整同时发包数量，解决拥堵问题
简单说，TCP 可以处理乱序和丢失数据包，丢了就重发.
还可以根据拥挤情况自动调整传输率
相当厉害！
你可能会奇怪，既然 TCP 那么厉害，还有人用 UDP 吗？
TCP 最大的缺点是 \N 那些"确认码"数据包把数量翻了一倍
但并没有传输更多信息
有时候这种代价是不值得的 \N 特别是对时间要求很高的程序，比如在线射击游戏
如果你玩游戏很卡，你也会觉得这样不值!
当计算机访问一个网站时 \N 需要两个东西：1.IP地址 2.端口号
例如 172.217.7.238 的 80 端口 \N 这是谷歌的 IP 地址和端口号
事实上，你可以输到浏览器里，然后你会进入谷歌首页
有了这两个东西就能访问正确的网站 \N 但记一长串数字很讨厌
google.com 比一长串数字好记
所以互联网有个特殊服务 \N 负责把域名和 IP 地址一一对应
就像专为互联网的电话簿 \N 它叫"域名系统"，简称 DNS
它的运作原理你可能猜到了
在浏览器里输 youtube.com \N 浏览器会去问 DNS 服务器，它的 IP 地址是多少
一般 DNS 服务器 \N 是互联网供应商提供的
DNS 会查表，如果域名存在，就返回对应 IP 地址.
如果你乱敲键盘加个.com 然后按回车
你很可能会看到 DNS 错误
因为那个网站不存在，所以 DNS 无法返回给你一个地址
如果你输的是有效地址，比如 youtube.com \N DNS 按理会返回一个地址
然后浏览器会给这个 IP 地址 \N 发 TCP 请求
如今有三千万个注册域名，所以为了更好管理
DNS 不是存成一个超长超长的列表，而是存成树状结构
顶级域名（简称 TLD）在最顶部，比如 .com 和 .gov
下一层是二级域名，比如 .com 下面有 \N google.com 和 dftba.com
再下一层叫子域名，\N 比如 images.google.com, store.dftba.com
这个树超！级！大！
我前面说的"三千万个域名"只是二级域名 \N 不是所有子域名
因此，这些数据散布在很多 DNS 服务器上
不同服务器负责树的不同部分
好了 我知道你肯定在等这个梗：
我们到了一层新抽象！
过去两集里 \N 我们讲了线路里的电信号，以及无线网络里的无线信号
这些叫"物理层"
而"数据链路层"负责操控"物理层"，\N 数据链路层有：媒体访问控制地址（MAC），碰撞检测，
指数退避，以及其他一些底层协议
再上一层是"网络层"
负责各种报文交换和路由
而今天，我们讲了"传输层"里一大部分， 比如 UDP 和 TCP 这些协议,
负责在计算机之间进行点到点的传输
而且还会检测和修复错误
我们还讲了一点点"会话层"
"会话层"会使用 TCP 和 UDP 来创建连接，传递信息，然后关掉连接
这一整套叫"会话"
查询 DNS 或看网页时，就会发生这一套流程
这是 开放式系统互联通信参考模型(OSI) 的底下5层
这个概念性框架 把网络通信划分成多层
每一层处理各自的问题
如果不分层 \N 直接从上到下捏在一起实现网络通信，是完全不可能的
抽象使得科学家和工程师能分工同时改进多个层 \N 不被整体复杂度难倒.
而且惊人的是！我们还没讲完呢！
OSI 模型还有两层，"表示层"和"应用程序层"
其中有浏览器，Skype，HTML解码，在线看电影等
我们下周说，到时见

前两集我们深入讨论了电线 信号 交换机 数据包 \N 路由器以及协议，它们共同组成了互联网.
今天我们向上再抽象一层，来讨论万维网
万维网(World Wide Web) \N 和互联网(Internet)不是一回事
尽管人们经常混用这两个词
万维网在互联网之上运行
互联网之上还有 Skype, Minecraft 和 Instagram
互联网是传递数据的管道，各种程序都会用，
其中传输最多数据的程序是万维网
分布在全球数百万个服务器上
可以用"浏览器"来访问万维网
这集我们会深入讲解万维网
万维网的最基本单位，是单个页面
页面有内容，也有去往其他页面的链接 \N 这些链接叫"超链接"
你们都见过：可以点击的文字或图片，把你送往另一个页面
这些超链接形成巨大的互联网络
这就是"万维网"名字的由来
现在说起来觉得很简单，但在超链接做出来之前
计算机上每次想看另一个信息时
你需要在文件系统中找到它 \N 或是把地址输入搜索框
有了超链接，你可以在相关主题间轻松切换
超链接的价值早在 1945 年 \N 就被 Vannevar Bush 意识到了
在第 24 集中我们说过，他发过一篇文章 \N 描述一个假想的机器 Memex
Bush的形容是"关联式索引.. 选一个物品会引起
另一个物品被立即选中"
他解释道："将两样东西联系在一起的过程十分重要
在任何时候，当其中一件东西进入视线
只需点一下按钮，立马就能回忆起另一件"
1945年的时候计算机连显示屏都没有，\N 所以这个想法非常超前！
因为文字超链接是如此强大
它得到了一个同样厉害的名字："超文本"！
如今超文本最常指向的，是另一个网页
然后网页由浏览器渲染，我们待会会讲
为了使网页能相互连接，每个网页需要一个唯一的地址
这个地址叫 "统一资源定位器"，简称 URL
一个网页URL的例子是 "thecrashcourse.com/courses"
就像上集讨论的，当你访问一个网站时
计算机首先会做"DNS查找"
"DNS查找"的输入是一个域名 \N 比如 thecrashcourse.com
DNS 会输出对应的IP地址
现在有了IP地址 \N 你的浏览器会打开一个 TCP 连接到这个 IP 地址
这个地址运行着"网络服务器"
网络服务器的标准端口是 80 端口
这时，你的计算机连到了 \N thecrashcourse.com 的服务器
下一步是向服务器请求"courses"这个页面
这里会用"超文本传输协议"(HTTP)
HTTP的第一个标准，HTTP 0.9，创建于1991年
只有一个指令，"GET" 指令
幸运的是，对当时来说也够用
因为我们想要的是"courses"页面
我们向服务器发送指令:"GET /courses"
该指令以"ASCII编码"发送到服务器
服务器会返回该地址对应的网页 \N 然后浏览器会渲染到屏幕上
如果用户点了另一个链接，计算机会重新发一个GET请求
你浏览网站时，这个步骤会不断重复
在之后的版本，HTTP添加了状态码
状态码放在请求前面
举例，状态码 200 代表 "网页找到了,给你"
状态码400~499代表客户端出错
比如网页不存在，就是可怕的404错误
"超文本"的存储和发送都是以普通文本形式
举个例子，编码可能是 ASCII 或 UTF-16  \N 我们在第4集和第20集讨论过
因为如果只有纯文本 \N 无法表明什么是链接，什么不是链接
所以有必要开发一种标记方法
因此开发了 超文本标记语言（HTML)
HTML 第一版的版本号是 0.8，创建于 1990 年
有18种HTML指令
仅此而已
我们来做一个网页吧！
首先，给网页一个大标题
我们输 h1 代表一级标题，然后用<>括起来
这就是一个HTML标签
然后输入想要的标题
我们不想一整页都是标题 \N 所以加 </h1> 作为结束标签
现在来加点内容
读者可能不知道"克林贡"是什么，所以我们给这个词
加一个超链接到"克林贡语言研究院"
我们用 <a> 标签来做，它有一个 href 属性
说明链接指向哪里，当点击链接时就会进入那个网页
最后用 </a> 关闭标签
接下来用 <h2> 标签做二级标题
HTML也有做列表的标签
我们先写<ol> \N 代表 有序列表（ordered list）
然后想加几个列表项目  就加几个 \N 用 <li> 包起来就行
读者可能不知道Bat'leth是什么，那么也加上超链接
最后，为了保持良好格式，用</ol>代表列表结束
这就完成了 - 一个很简单的网页！
如果把这些文字存入记事本或文本编辑器，\N 然后文件取名"test.html"
就可以拖入浏览器打开
当然，如今的网页更复杂一些
最新版的 HTML，HTML5，有100多种标签
图片标签，表格标签，表单标签，按钮标签，等等
还有其他相关技术就不说了\N 比如 层叠样式表 (CSS)
和 JavaScript，这俩可以加进网页，做一些更厉害的事
让我们回到浏览器
网页浏览器可以和网页服务器沟通
浏览器不仅获取网页和媒体，获取后还负责显示.
第一个浏览器和服务器
是 Tim Berners-Lee 在 1990 年写的，一共花了2个月
那时候他在瑞士的"欧洲核子研究所"工作
为了做出来，他同时建立了几个最基本的网络标准
URL, HTML 和 HTTP.
两个月能做这些很不错啊！
不过公平点说，他研究超文本系统已经有十几年了
和同事在 CERN 内部使用一阵子后
在 1991 年发布了出去
万维网就此诞生
重要的是，万维网有开放标准
大家都可以开发新服务器和新浏览器
因此"伊利诺伊大学香槟分校"的一个小组
在 1993 年做了 Mosaic 浏览器
第一个可以在文字旁边显示图片的浏览器
之前浏览器要单开一个新窗口显示图片
还引进了书签等新功能，界面友好，使它很受欢迎
尽管看上去硬邦邦的，但和如今的浏览器长的差不多
1990年代末有许多浏览器面世
也有很多服务器面世
比如 Apache 和 微软互联网信息服务(IIS)
每天都有新网站冒出来，如今的网络巨头
比如亚马逊和 eBay，创始于 1990 年代中期
那是个黄金时代！
随着万维网日益繁荣，人们越来越需要搜索
如果你知道网站地址 \N 比如 ebay.com，直接输入浏览器就行
如果不知道地址呢？
比如想找可爱猫咪的图片
现在就要！
去哪里找呢？
起初人们会维护一个目录，链接到其他网站
其中最有名的叫"Jerry和David的万维网指南"
1994年改名为Yahoo
随着网络越来越大，人工编辑的目录变得不便利
所以开发了搜索引擎
让我们进入思想泡泡!
长的最像现代搜索引擎的最早搜素引擎，叫JumpStation
由Jonathon Fletcher于1993年在斯特林大学创建
它有 3 个部分
第一个是爬虫，一个跟着链接到处跑的软件
每当看到新链接，就加进自己的列表里
第二个部分是不断扩张的索引
记录访问过的网页上，出现过哪些词
最后一个部分，是查询索引的搜索算法
举个例子，如果我在 JumpStation 输入"猫"
每个有"猫"这个词的网页都会出现
早期搜索引擎的排名方式 非常简单
取决于 搜索词在页面上的出现次数
刚开始还行，直到有人开始钻空子
比如在网页上写几百个"猫"，把人们吸引过来
谷歌成名的一个很大原因是 \N 创造了一个聪明的算法来规避这个问题
与其信任网页上的内容 \N 搜索引擎会看其他网站 有没有链接到这个网站
如果只是写满"猫"的垃圾网站，没有网站会指向它
如果有关于猫的有用内容，有网站会指向它
所以这些"反向链接"的数量，特别是有信誉的网站
代表了网站质量
Google 一开始时是 1996 年斯坦福大学 \N 一个叫 BackRub 的研究项目
两年后分离出来，演变成如今的谷歌
谢谢思想泡泡！
最后 我想讲一个词，你最近可能经常听到
网络中立性
现在你对数据包，路由和万维网，有了个大体概念
足够你理解这个争论的核心点，至少从技术角度
简单说"网络中立性"是
应该平等对待所有数据包
不论这个数据包是我的邮件，或者是你在看视频
速度和优先级应该是一样的
但很多公司会乐意让它们的数据优先到达
拿 Comcast 举例，它们不但是大型互联网服务提供商\N 而且拥有多家电视频道
比如 NBC 和 The Weather Channel，可以在线看.
我不是特意找Comcast麻烦 \N 但要是没有网络中立性
Comcast 可以让自己的内容优先到达 \N 节流其他线上视频
节流(Throttled) 意思是故意给更少带宽和更低优先级
再次重申，这只是举例，不是说 Comcast 很坏
支持网络中立性的人说 \N 没有中立性后，服务商可以推出提速的"高级套餐"
给剥削性商业模式埋下种子
互联网服务供应商成为信息的"守门人"，\N 它们有着强烈的动机去碾压对手
另外，Netflix和Google这样的大公司可以花钱买特权
而小公司，比如刚成立的创业公司，\N 会处于劣势，阻止了创新
另一方面，从技术原因看
也许你会希望不同数据传输速度不同
你希望Skype的优先级更高，邮件晚几秒没关系
而反对"网络中立性"的人认为，市场竞争会阻碍不良行为
如果供应商把客户喜欢的网站降速 \N 客户会离开供应商
这场争辩还会持续很久，\N 就像我们在 Crash Course 其他系列中说过
你应该自己主动了解更多信息
因为"网络中立性"的影响十分复杂而且广泛
我们下周再见

过去3集 我们讲了计算机如何互连
让我们能瞬时跨全球沟通
但不是每个使用网络的人都会规规矩矩  不损害他人利益
就像现实世界中我们用锁和栅栏保证物理安全
有警察减少犯罪
我们需要网络安全减少虚拟世界中的犯罪
计算机没有道德观念
只要给计算机写清具体问题  它们很乐意地闪电般算出答案
破坏医院计算机系统的代码 和 保持病人心跳的代码 \N 对计算机来说没有区别
就像"原力"一样 \N 计算机可以被拉到"光明面"或"黑暗面"
网络安全就像 绝地武士团 \N 给网络世界带来和平与正义
计算机安全的范围，和计算能力的发展速度一样快
我们可以把计算机安全，看成是保护系统和数据的：
保密性，完整性和可用性
我们逐个细说：
"保密性"是只有有权限的人 \N 才能读取计算机系统和数据
黑客泄露别人的信用卡信息，就是攻击保密性.
"完整性"是只有有权限的人 \N 才能使用和修改系统和数据
黑客知道你的邮箱密码，假冒你发邮件\N 就是攻击"完整性"
"可用性"是有权限的人 \N 应该随时可以访问系统和数据
拒绝服务攻击(DDOS) 就是黑客
发大量的假请求到服务器，让网站很慢或者挂掉
这就是攻击"可用性"
为了实现这三个目标，安全专家会从 \N 抽象层面想象"敌人"可能是谁，这叫"威胁模型分析"
模型会对攻击者有个大致描述：\N 能力如何，目标可能是什么，可能用什么手段
攻击手段又叫"攻击矢量"
"威胁模型分析"让你能为特定情境做准备
不被可能的攻击手段数量所淹没 \N 因为手段实在有太多种了
假设你想确保笔记本计算机的"物理安全" \N 你的威胁模型是"好管闲事的室友"
为了保证保密性，完整性和可用性 \N 你可以藏在脏兮兮的洗衣篮里
但如果威胁模型是调皮的兄弟姐妹，知道你喜欢藏哪里
那么你需要更多保护：比如锁在保险箱里
换句话说，要怎么保护，具体看对抗谁
当然，威胁模型通常比"好管闲事的室友"更正式一些
通常威胁模型分析里 会以能力水平区分
比如"某人可以物理接触到笔记本计算机，而且时间无限"
在给定的威胁模型下，安全架构师要
提供解决方案，保持系统安全
只要某些假设不被推翻
比如没人会告诉攻击者密码
保护计算机系统，网络和数据的方法有很多
很多安全问题可以总结成2个问题：
你是谁？你能访问什么？
权限应该给合适的人，拒绝错误的人
比如银行员工可以打开取款机来补充现金。\N 但我不应该有权限打开
因为我会把钱拿走 全拿走！
陶瓷猫收藏品可不会从天上掉下来哟！
所以，为了区分谁是谁，\N 我们用 "身份认证"(authentication)
- 让计算机得知使用者是谁
身份认证有三种，各有利弊：
你知道什么
你有什么
你是什么
"你知道什么" 是基于某个秘密
只有用户和计算机知道
比如 用户名和密码
这是如今使用最广泛的，因为最容易实现
但如果黑客通过猜测或其他方式，知道你的密码，就惨了
有些密码很容易猜中，比如12356或qwerty
但有些密码对计算机很容易
比如PIN码：2580
看起来很难猜中 - 起码对人类来说是这样
但4位数字，只有一万种可能
一台计算机可以尝试0000，然后0001，然后0002，
然后到9999，不到一秒内试完
这叫"暴力攻击"，因为只是试遍一切可能
这种算法没什么聪明的地方
如果你错误尝试3次，\N 有些系统会阻止你继续尝试，或让你等一会儿
这个策略普遍而且合理
对于一般的攻击者确实很难
但假设黑客控制了
数以万计的计算机，形成一个僵尸网络
用这么多计算机尝试密码 2580
同时尝试很多银行账户
即使每个账户只试一次，也很可能
碰到某个账户刚好用这个 PIN
事实上，看视频的某人可能刚好用这个 PIN
增加密码长度有帮助
但即使8位数字的PIN码也很容易破解
这就是为什么现在很多网站 要求大写+小写字母
还有特殊符号等，大大增加可能的密码
8位数字的PIN只有一亿种组合
对计算机轻而易举
但包含各种字符的8位长度密码
有超过600万亿种组合
当然，这些密码会难以记住，
所以更好的方法是 选一些更好记的东西
比如三个单词连在一起：
"格林兄弟好厉害"或"披萨尝起来好好吃"
英文大约有10万个单词
所以三个单词连一起大概有
1亿亿种可能，想猜中的话，祝你好运！
另外使用不在字典内的单词
被猜中的可能性更低
但我们没时间细说这个
Computerphile 频道有个视频讲怎么选择好密码 - \N 链接请看 Youtube 描述
"你有什么"这种验证方式
是基于用户有特定物体
比如钥匙和锁
如果你有钥匙，就能开门
这避免了被人"猜中"的问题
而且通常需要人在现场
所以远程攻击就更难了
另一个国家的人，得先来佛罗里达州
才能到你家前门
但如果攻击者离你比较近，那么也不安全
钥匙可以被复制，手机可能被偷，锁可以撬开
最后，"你是什么"这种验证，是基于你
把特征展示给计算机进行验证
生物识别验证器，\N 比如指纹识别器和虹膜扫描仪就是典型例子
这些非常安全，但最好的识别技术仍然很贵
而且，来自传感器的数据每次会不同
"你知道什么"和"你有什么"。这两种验证是"确定性"的
- 要么正确，要么错误
如果你知道密码，或有钥匙，那么100％能获得访问权限
如果没有，就绝对进不去
但"生物识别"是概率性的，系统有可能认不出你
可能你戴了帽子，或者光线不好
更糟的是，系统可能把别人错认成你
比如你的邪恶双胞胎
当然，在现实世界中几率很低，但不是零
生物认证的另一个问题是无法重设
你只有这么多手指，如果攻击者拿到你的指纹数据怎么办
你一辈子都麻烦了
最近还有研究人员表示，拍个照都有可能伪造虹膜
所以也不靠谱
所有认证方法都有优缺点，
它们都可以被攻破
所以，对于重要账户，\N 安全专家建议用两种或两种以上的认证方式
这叫"双因素"或"多因素"认证
攻击者可能猜出你密码，或偷走你的手机：
但两个都做到，会比较难
"身份验证"后，就来到了"访问控制"
一旦系统知道你是谁，它需要知道你能访问什么，
因此应该有个规范，\N 说明谁能访问什么，修改什么，使用什么。
这可以通过"权限"或"访问控制列表"（ACL）来实现
其中描述了用户对每个文件，文件夹和程序的访问权限
"读"权限允许用户查看文件内容，
"写"权限允许用户修改内容，
"执行"权限允许用户运行文件，比如程序
有些组织需要不同层级的权限
比如间谍机构，"访问控制列表"的正确配置非常重要
以确保保密性，完整性和可用性
假设我们有三个访问级别：公开，机密，绝密
第一个普遍的好做法是，\N 用户不能"读上", 不能读等级更高的信息
如果用户能读"机密"文件\N 那么不应该有权限读"绝密"文件
但能访问"机密"和"公开"文件
第二个法则是用户不能"写下"
如果用户等级是"绝密"
那么能写入或修改"绝密"文件，\N 但不能修改"机密"或"公共"文件
听起来好像很奇怪 \N 有最高等级也不能改等级更低的文件
但这样确保了"绝密" \N 不会意外泄露到"机密"文件或"公共"文件里
这个"不能向上读，不能向下写"的方法\N 叫 Bell-LaPadula 模型
它是为美国国防部"多层安全政策"制定的
还有许多其他的访问控制模型 - 比如"中国墙"模型和"比伯"模型
哪个模型最好，取决于具体情况
"身份验证"和"访问控制"帮助计算机知道"你是谁"
以及"你可以访问什么"，
但做这些事情的软硬件必须是可信的
这个依赖很重要
如果攻击者给计算机装了恶意软件
- 控制了计算机的操作系统
我们怎么确定安全程序没有给攻击者留后门？
短回答是...无法确定
我们仍然无法保证程序或计算机系统的安全
因为安全软件在理论上可能是"安全的"
实现时可能会不小心留下漏洞
但我们有办法减少漏洞出现的可能性
比如一找到就马上修复
以及当程序被攻破时尽可能减少损害
大部分漏洞都是具体实现的时候出错了
为了减少执行错误，减少执行
系统级安全的圣杯之一是"安全内核"
或"可信计算基础"：一组尽可能少的操作系统软件
安全性都是接近可验证的
构建安全内核的挑战在于 决定内核应该有什么
记住，代码越少越好！
在最小化代码数量之后，\N 要是能"保证"代码是安全的，会非常棒
正式验证代码的安全性 是一个活跃的研究领域
我们现在最好的手段，叫"独立安全检查和质量验证"
让一群安全行业内的软件开发者来审计代码
这就是为什么安全型代码几乎都是开源的
写原始代码的人通常很难找到错误
但外部开发人员有新鲜的眼光 \N和不同领域的专业知识，可以发现问题.
另外还有一些安全大会，安全专家可以相互认识，分享想法.
一年一次在拉斯维加斯举办的 DEF CON \N 是全球最大的安全大会
最后，即便尽可能减少代码 并进行了安全审计
聪明的攻击者还是会找到方法入侵
因为如此，优秀的开发人员
应该计划当程序被攻破后，\N如何限制损害，控制损害的最大程度
并且不让它危害到计算机上其他东西
这叫"隔离"
要实现隔离，我们可以"沙盒"程序
这好比把生气的小孩放在沙箱里，
他们只能摧毁自己的沙堡，不会影响到其他孩子
操作系统会把程序放到沙盒里
方法是给每个程序独有的内存块，其他程序不能动
一台计算机可以运行多个虚拟机
虚拟机模拟计算机，每个虚拟机都在自己的沙箱里
如果一个程序出错，最糟糕的情况是它自己崩溃
或者搞坏它处于的虚拟机
计算机上其他虚拟机是隔离的，不受影响
好，一些重要安全概念的概览 \N 我们到此就介绍完了
我都还没讲网络安全，比如防火墙
下集我们会讨论  黑客侵入系统的一些方法
然后我们学加密
在此之前，别忘了加强你的密码，打开两步验证
永远不要点可疑邮件
我们下周见

上集我们讲了计算机安全的基础知识，
包括各种原则和技术
但尽管尽了最大努力，新闻上还是各种 \N 个人，公司，政府被黑客攻击的故事
那些黑客凭技术知识 闯入计算机系统
不是所有黑客都是坏人
有些黑客会寻找并修复软件漏洞 \N 让系统更安全
他们经常被公司和政府雇来做安全评估
这些黑客叫"白帽子"，他们是好人
另一方面，也有"黑帽"黑客，他们窃取，
利用和销售计算机漏洞和数据
黑客的动机有很多种
有些是好玩和好奇
而网络罪犯一般是为了钱
还有的叫"黑客行动主义者"，\N 通过黑客手段影响社会或达到政治目的
这只是冰山一角
一般对黑客的刻板印象是 \N 某个不受欢迎的小孩在黑暗的房间里
到处都是吃完的比萨盒，这个印象是错的，\N形容约翰·格林的宿舍还更贴切些
今天，我们不会教你如何成为黑客
而是讨论一些入侵原理，给你一个大概概念
黑客入侵最常见的方式
不是通过技术，而是欺骗别人
这叫"社会工程学"，欺骗别人让人泄密信息
或让别人配置电脑系统，变得易于攻击
最常见的攻击是网络钓鱼，你可能见过
银行发邮件叫你点邮件里的链接，登陆账号
然后你会进入一个像官网的网站
但实际上是个假网站
当你输入用户名和密码时，信息会发给黑客，
然后黑客就可以假扮你登陆网站
坏消息！
即使成功率只有1/1000，发一百万封钓鱼邮件
也有一千个帐户中招
另一种方法叫 假托(Pretexting)，\N 攻击者给某个公司打电话
假装是IT部门的人
攻击者的第一通电话一般会叫人转接
这样另一个人接的时候，电话看起来像内部的
然后让别人把电脑配置得容易入侵
或让他们泄露机密信息，比如密码或网络配置
不好意思，等一下
嘿，我是 IT 部门的苏珊
我们遇到一些网络问题，你能帮我检查一个配置吗？
然后就开始了
只要预先做一点研究，攻击者可以装得很像真的
比如关键员工的名字
也许要10通电话才能找到一个受害者，\N 但只要一个人上当就够了
邮件里带"木马"也是常见手段
木马会伪装成无害的东西，比如照片或发票
但实际上是恶意软件
恶意软件有很多种
有的会偷数据，比如银行凭证
有的会加密文件，交赎金才解密，也就是"勒索软件"
如果攻击者无法用木马或电话欺骗
攻击者只能被迫用其他手段
方法之一是暴力尝试，我们上集讨论过
尝试所有可能的密码，直到进入系统
大多数现代系统会加长等待时间，来抵御这种攻击
每次失败就加长等待时间
甚至失败超过一定次数后，完全锁住
最近出现一种攻破方法叫 "NAND镜像"
如果能物理接触到电脑
可以往内存上接几根线
复制整个内存
复制之后，暴力尝试密码，直到设备让你等待
这时只要把复制的内容覆盖掉内存
本质上重置了内存，就不用等待，可以继续尝试密码了
这项方法在 iPhone 5C 上管用
更新的设备有机制阻止这种攻击
如果你无法物理接触到设备
就必须远程攻击，比如通过互联网.
远程攻击一般需要攻击者利用系统漏洞
来获得某些能力或访问权限，这叫"漏洞利用"(Exploit)
一种常见的漏洞利用叫"缓冲区溢出"
"缓冲区"是一种概称，指预留的一块内存空间
我们在第23集，讨论过存像素数据的视频缓冲区
举个简单例子，假设我们在系统登陆界面
要输入用户名和密码
在幕后，系统用缓冲区存输入的值
假设缓冲区大小是10
两个文本缓冲区看起来会像这样：
当然，操作系统记录的远不止用户名和密码
所以缓冲区前后 肯定有其他数据
当用户输入用户名和密码时，这些值会复制到缓冲区
然后验证是否正确
"缓冲区溢出"正如名字所暗示的：它会溢出缓冲区
在这个例子中，超过十个字符的密码
会覆盖掉相邻的数据
有时只会让程序或系统崩溃，
因为重要值被垃圾数据覆盖了
系统崩溃是坏事
但也许恶作剧黑客就只是想系统崩溃，当个讨厌鬼
但攻击者可以更巧妙地利用这个漏洞(bug)，\N 注入有意义的新值
到程序的内存中，比如把"is_admin"的值改成true
有了任意修改内存的能力，
黑客可以绕过"登录"之类的东西，
甚至使用那个程序劫持整个系统
有很多方法阻止缓冲区溢出
最简单的方法是，复制之前先检查长度，
这叫 "边界检查"
许多现代编程语言自带了边界检查
程序也会随机存放变量在内存中的位置，
比如我们之前假设的"is_admin"
这样黑客就不知道应该覆盖内存的哪里
导致更容易让程序崩溃，而不是获得访问权限
程序也可以在缓冲区后，留一些不用的空间
然后跟踪里面的值，看是否发生变化
如果发生了变化，说明有攻击者在乱来
这些不用的内存空间叫"金丝雀"，因为以前矿工会带
金丝雀下矿，金丝雀会警告危险
另一种经典手段叫"代码注入"
最常用于攻击用数据库的网站，
几乎所有大网站都用数据库
我们这个系列中不会讲解数据库，
所以以下是个简单例子
我们会用"结构化查询语言"，也叫SQL，\N 一种流行的数据库API
假设网页上有登录提示
当用户点击"登录"时，值会发到服务器
服务器会运行代码，检查用户名是否存在，\N 如果存在，看密码是否匹配
为了做检查，服务器会执行一段叫 "SQL查询" 的代码
看起来像这样
首先，语句要指定从数据库里查什么数据
在这个例子中，我们想查的是密码 (password)  \N (SELECT password)
还要指定从哪张表查数据 \N (FROM users)
在这个例子里，\N 我们假设所有用户数据都存在 "users" 表里
最后，服务器不想每次取出一个巨大密码列表，\N 包含所有用户密码
所以用 username = '用户名'\N 代表只要这个用户
用户输的值会复制到"SQL查询"
所以实际发到 SQL 数据库的命令，是这样的.
还要注意，SQL命令以分号结尾
那怎么破解这个？
做法是把"SQL命令"输入到用户名里！
比如我们可以发这个奇怪的用户名：
当服务器把值复制到SQL查询中，会变成这样：
正如之前提的，分号用于分隔命令，
所以第一条被执行的命令是：
如果有个用户叫"whateer"，数据库将返回密码
当然，我们不知道密码是什么
所以会出错，服务器会拒绝我们
如果没有一个用户叫"whatever"，数据库会返回 \N 空密码或直接错误，服务器也会拒绝我们
总之 我们不在乎，\N 我们感兴趣的是下一个SQL命令：
"drop table users" - 我们注入的命令
这条命令的意思是  删掉 users 这张表
全删干净！
这会造成很多麻烦，不管是银行或什么其他地方
注意，我们甚至不需要侵入系统
我们没有猜到正确的用户名和密码
即使没有正式访问权限，还是可以利用 bug 来制造混乱
这是代码注入的一个简单例子，
如今几乎所有服务器都会防御这种手段
如果指令更复杂一些，也许可以添加新记录到数据库
- 比如一个新管理员帐户 -
甚至可以让数据库泄露数据，使得黑客
窃取信用卡号码，社会安全号码
以及各种其他信息
但我们不会教你具体怎么做
就像缓冲区溢出攻击一样，应该总是假设外部数据
是危险的，应该好好检查
很多用户名和密码表单，不让你输入
特殊字符，比如分号或者括号，作为第一道防御
好的服务器也会清理输入
比如修改或删除特殊字符，然后才放到数据库查询语句里
管用的漏洞利用(Exploits)一般会在网上贩卖或分享
如果漏洞很流行，或造成的危害很大
价格会越高，或者名气越大
有时甚至政府也会买漏洞利用
让他们侵入系统做间谍工作
当软件制造者不知道软件有新漏洞被发现了
那么这个漏洞叫 "零日漏洞"
黑帽黑客经常赶时间，抢在白帽程序员做出补丁之前
尽可能利用漏洞
所以保持系统更新非常重要
很多更新都是安全性补丁
如果有足够多的电脑有漏洞
让恶意程序可以在电脑间互相传播
那么叫"蠕虫"
如果黑客拿下大量电脑，这些电脑可以组成
"僵尸网络"
可以用于很多目的，比如发大量垃圾邮件，
用别人电脑的计算能力和电费挖 Bitcoin，
或发起"拒绝服务攻击"简称DDoS，攻击服务器
DDoS 就是僵尸网络里的所有电脑发一大堆垃圾信息
堵塞服务器，要么迫使别人交钱消灾
或纯粹为了作恶
尽管白帽黑客非常努力工作，漏洞利用的文档都在网上，
编写软件有很多"最佳实践"，网络攻击每天都在发生
每年损害全球经济差不多5000亿
并且随着我们越来越依赖计算机系统，这个数字只会增加.
这使得政府非常担心，因为基础设施越来越电脑化
比如电力厂，电网，交通灯，水处理厂，炼油厂
空管，还有很多其他关键系统
很多专家预测下一次大战会主要是网络战争
国家不是被物理攻击打败
而是因为网络战争导致经济和基础设施崩溃
也许不会发射一颗子弹，但是人员伤亡的可能性依然很高
甚至可能高于传统战争
所以大家都应该知道一些方法保证网络安全
全球社区因为互联网而互相连接，
我们应该确保自己的电脑安全
抵御其他想做坏事的人
也许不要再忽略更新提示？
我们下周见

在过去两集，我们聊了很多计算机安全话题
但事实是 世上不存在100%安全的系统
总会有漏洞存在，而且安全专家知道这一点
所以系统架构师会部署"多层防御"
用多层不同的安全机制来阻碍攻击者
有点像城堡的设计一样
首先要避开弓箭手
穿过护城河,翻过城墙,避开热油,打败守卫
才能达到王座
不过我们这里要说的是，计算机安全中最常见的防御形式
密码学
密码学(cryptography) 一词 \N 来自 crypto 和 graphy，大致翻译成"秘密写作"
为了加密信息，要用加密算法(Cipher) 把明文转为密文
除非你知道如何解密，不然密文看起来只是一堆乱码
把明文转成密文叫"加密"(encryption)
把密文恢复回明文叫"解密"(decryption)
加密算法早在计算机出现前就有了
朱利叶斯·凯撒 用如今我们叫"凯撒加密"的方法 来加密私人信件
他会把信件中的字母 向前移动三个位置
所以A会变成D，brutus变成euxwxv
为了解密，接收者要知道 \N 1. 用了什么算法 2. 要偏移的字母位数
有一大类算法叫"替换加密"，凯撒密码是其中一种
算法把每个字母替换成其他字母
但有个巨大的缺点是，字母的出现频率是一样的
举个例子，E在英语中是最常见的字母
如果把E加密成X
那么密文中 X 的出现频率会很高
熟练的密码破译师可以从统计数据中发现规律，进而破译密码
1587年，正因为一个"替换加密"的密文被破译，\n导致杀伊丽莎白女王的阴谋暴露，使得玛丽女王被处决
另一类加密算法叫 "移位加密"
我们来看一个简单例子叫 "列移位加密"
我们把明文填入网格
网格大小我们这里选择 5x5
为了加密信息，我们换个顺序来读
比如从左边开始，从下往上，一次一列。
加密后字母的排列不同了
解密的关键是，知道读取方向和网格大小是5x5
就像之前，如果接收者知道密文和加密方法 \N 才能解密得到原始消息
到了1900年代，人们用密码学做了加密机器
其中最有名的是德国的英格玛（Enigma）\N 纳粹在战时用英格玛加密通讯信息
正如第15集中说过，Enigma 是一台像打字机的机器，\N 有键盘和灯板，两者都有完整的字母表
而且它有一系列"转子"(rotros) ，是加密的关键
首先，我们只看一个转子
它一面有26个接触点，代表26个字母
然后线会连到另一面，替换字母
如果输入'H'，'K'会从另一边出来
如果输入'K'，'F'会从另一边出来，以此类推
这个字母替换过程你应该听起来很熟悉：它是"替换加密"!
但英格玛(Enigma)更复杂一些，因为它有3个或更多转子，\N 一个转子的输出作为下一个转子的输入。
转子还有26个起始位置
还可以按不同顺序放入转子，提供更多字母替换映射
转子之后是一个叫"反射器"的特殊电路
它每个引脚会连到另一个引脚
并把信号发回给转子
最后，机器前方有一个插板
可以把输入键盘的字母预先进行替换
又加了一层复杂度
让我们用这里的简化版电路，加密一些字母
如果我们按下"H"键，电流会先通过插板，然后通过转子
到达反射器，然后回来转子，回来插板，并照亮键盘灯板的字母"L"。
H 就加密成了 L
注意, 电路是双向的
所以如果我们按下 L，H 会亮起来
换句话说，加密和解密的步骤是一样的
你只需要确保 发送机和接收机的初始配置一样就行
如果你有仔细观察，会注意到字母加密后一定会变成另一个字母
之后这成为最大的弱点
最后，为了让英格玛不只是简单的"替换加密"
每输入一个字母，转子会转一格，有点像汽车里程表。
如果你输入A-A-A，可能会变成B-D-K，\n映射会随着每次按键而改变
英格玛当然是一块难啃的骨头
但正如我们第15集中说的，艾伦·图灵和同事
破解了英格玛加密，并把大部分破解流程做成了自动化
但随着计算机出现，加密从硬件转往软件
早期加密算法中，应用最广泛的
是 IBM 和 NSA 于1977年开发的"数据加密标准"
DES最初用的是56 bit长度的二进制密钥，
意味着有2的56次方，或大约72千万亿个不同密钥
在1977年时，也许 NSA 有这能力，
但没有其他人有足够计算能力 来暴力破解所有可能密钥。
但到1999年，一台25万美元的计算机能在两天内 \N 把 DES 的所有可能密钥都试一遍，让 DES 算法不再安全
因此 2001 年出了：高级加密标准（AES）
AES 用更长的密钥 - 128位/192位/256位 - 让暴力破解更加困难
128位的密钥，哪怕用现在地球上的所有计算机\N 也要上万亿年才能试遍所有组合
你最好赶紧开始!
AES将数据切成一块一块，每块16个字节，\N 然后用密钥进行一系列替换加密和移位加密
再加上一些其他操作，进一步加密信息
每一块数据，会重复这个过程10次或以上
你可能想知道：为什么只重复10次？
为什么用128位密钥，而不是10000位？
这其实是基于性能的权衡
如果要花几小时加密和发邮件，或几分钟载入网站，没人愿意用
AES 在性能和安全性间取得平衡
如今AES被广泛使用，比如iPhone上加密文件
用 WPA2 协议在 WiFi 中访问 HTTPS 网站
到目前为止 我们讨论过的加密技术\N 依赖于发送者和接收者都知道密钥
发件人用密钥加密，收件人用相同的密钥解密
以前，密钥可以口头约定，或依靠物品
比如德国人给英格玛配了密码本，上面有每天的配置
但互联网时代没法这样做
你能想象 要打开密码本才能访问 YouTube 吗？
我们需要某种方法 在公开的互联网上传递密钥给对方
这看起来好像不安全，如果密钥被黑客拦截了
黑客不就能解密通信了吗？
解决方案是 "密钥交换"！
密钥交换是一种不发送密钥，\N 但依然让两台计算机在密钥上达成共识的算法
我们可以用"单向函数"来做
单项函数是一种数学操作，很容易算出结果，\N 但想从结果逆向推算出输入非常困难
为了让你明白单项函数，我们拿颜色作比喻
将颜色混合在一起很容易，
但想知道混了什么颜色很难
要试很多种可能才知道
用这个比喻，那么我们的密钥是一种独特的颜色
首先，有一个公开的颜色，所有人都可以看到
然后，约翰和我各自选一个秘密颜色，只有自己知道.
为了交换密钥，我把我的 秘密颜色 和 公开颜色 混在一起
然后发给约翰，可以写信发，用信鸽发，什么方式都行.
约翰也这样做，把他的秘密颜色和公开颜色混在一起，然后发我
我收到约翰的颜色之后，把我的秘密颜色加进去，\N  现在3种颜色混合在一起
John 也一样做
瞧!
我们有了一样的颜色
我们可以把这个颜色当密钥，尽管我们从来没有给对方发过这颜色
外部窥探者可以知道部分信息，但无法知道最终颜色
当然，计算机要传输数据时，混合颜料和发颜料不太合适
但幸运的是，数学单向函数是完美的
我们可以用 "迪菲-赫尔曼密钥交换"
在 Diffie-Hellman 中，单向函数是模幂运算
意思是先做幂运算，拿一个数字当底数，拿一个数字当指数，比如 A
然后除以第三个数字，最后拿到我们想要的余数
举个例子，假设我们想算3的5次方，模31
我们先算3的5次方，得到243
\N然后除31，取余数，得到26
重点是  如果只给余数和基数。很难得知指数是多少
如果我告诉你，3的某次方 模31，余数是7
你要试很多次，才能知道次方是多少
如果把数字变长一些，比如几百位长
想找到秘密指数是多少，几乎是不可能的。
现在我们来讨论 Diffie-Hellman 是怎么
用模幂运算 算出双方共享的密钥
首先，我们有公开的值 - 基数和模数
就像公开的油漆颜色，所有人都看的到，甚至坏人!
为了安全向 John 发信息，我选一个秘密指数：X
然后算  B^X mod M 的结果
然后把这个大数字发给 John.
John 也一样做，选一个秘密指数Y，然后把 B^Y mod M 的结果发我
为了算出 双方共用的密钥
我把 John 给我的数，用我的秘密指数 X，进行模幂运算 (看上图)
数学上相等于  B的XY次方 模M
John也一样做，拿我给他的数 进行模幂运算，最终得到一样的数
双方有一样的密钥，即使我们从来没给对方发过各自的秘密指数
我们可以用这个大数字当密钥，用 AES 之类的加密技术来加密通信
"Diffie-Hellman 密钥交换"是建立共享密钥的一种方法。
双方用一样的密钥加密和解密消息，这叫"对称加密", 因为密钥一样
凯撒加密，英格玛，AES 都是"对称加密"
还有"非对称加密"，有两个不同的密钥
一个是公开的，另一个是私有的
人们用公钥加密消息 \N 只有有私钥的人能解密
换句话说，知道公钥只能加密但不能解密 \N - 它是"不对称"的！
想象一个可以锁上的盒子
为了收到安全的信息，我们可以给别人箱子和锁
别人把信息放箱子，然后锁起来
把盒子寄回给我，只有我的钥匙能打开
上锁后，如果发件人或其他人想打开盒子 \N 除了暴力尝试没有其他办法.
和盒子例子一样，公钥加密后只能私钥来解密.
反过来也是可以的：私钥加密后 用公钥解密
这种做法用于签名，服务器可以用私钥加密，
任何人都可以用服务器的公钥解密
就像一个不可伪造的签名
因为只有私钥的持有人 能加密
这能证明数据来自正确的服务器或个人，而不是某个假冒者
目前最流行的"非对称加密"技术是 RSA
名字来自发明者： Rivest, Shamir, Adleman.
现在你学会了现代密码学的所有"关键"部分：
对称加密，密钥交换，公钥密码学
当你访问一个安全的网站，比如银行官网
绿色锁图标代表 用了公钥密码学
验证服务器的密钥，然后建立临时密钥
然后用对称加密保证通信安全
不管你是网上购物，发邮件给朋友，还是看猫咪视频
密码学都在保护你的隐私和安全
谢啦密码学！

我们之前说过 \N 计算机很擅长存放，整理，获取和处理大量数据
很适合有上百万商品的电商网站
或是存几十亿条健康记录，方便医生看.
但如果想根据数据做决定呢？
这是机器学习的本质
机器学习算法让计算机可以从数据中学习，\N 然后自行做出预测和决定
能自我学习的程序很有用 \N 比如判断是不是垃圾邮件
这人有心律失常吗？
YouTube 的下一个视频该推荐哪个？
虽然有用，但我们不会说它有人类一般的智能
虽然 AI 和 ML 这两词经常混着用
大多数计算机科学家会说 \N机器学习是为了实现人工智能这个更宏大目标的技术之一
人工智能简称 AI
机器学习和人工智能算法一般都很复杂
所以我们不讲具体细节  重点讲概念
我们从简单例子开始：
判断飞蛾是"月蛾"还是"帝蛾"
这叫"分类"
做分类的算法叫 "分类器"
虽然我们可以用 照片和声音 来训练算法
很多算法会减少复杂性
把数据简化成 "特征"
"特征"是用来帮助"分类"的值
对于之前的飞蛾分类例子\N 我们用两个特征:"翼展"和"重量"
为了训练"分类器"做出好的预测，
我们需要"训练数据"
为了得到数据
我们派昆虫学家到森林里 收集"月蛾"和"帝蛾"的数据
专家可以认出不同飞蛾，
所以专家不只记录特征值，还会把种类也写上
这叫 "标记数据"
因为只有两个特征
很容易用散点图把数据视觉化
红色标了100个帝蛾\N 蓝色标了100个月蛾
可以看到大致分成了两组
但中间有一定重叠
所以想完全区分两个组比较困难
所以机器学习算法登场
- 找出最佳区分
我用肉眼大致估算下
然后判断 翼展小于45毫米的 很可能是帝蛾
可以再加一个条件，重量必须小于.75
才算是帝蛾。
这些线叫 "决策边界"
如果仔细看数据
86只帝蛾在正确的区域
但剩下14只在错误的区域
另一方面，82只月蛾在正确的区域
18个在错误的区域
这里有个表 记录正确数和错误数
这表叫"混淆矩阵"
"黑客帝国三部曲"的后两部也许该用这个标题
注意我们没法画出 100% 正确分类的线
降低翼展的决策边界，会把更多"帝蛾"误分类成"月蛾"
如果提高，会把更多月蛾分错类.
机器学习算法的目的
是最大化正确分类 + 最小化错误分类
在训练数据中，有168个正确，32个错误
平均准确率84％
用这些决策边界
如果我们进入森林，碰到一只不认识的飞蛾，
我们可以测量它的特征, 并绘制到决策空间上
这叫 "未标签数据"
决策边界可以猜测飞蛾种类
这里我们预测是"月蛾"
这个把决策空间 切成几个盒子的简单方法
可以用"决策树"来表示
画成图像，会像左侧 \N 用 if 语句写代码，会像右侧
生成决策树的 机器学习算法
需要选择用什么特征来分类
每个特征用什么值
"决策树"只是机器学习的一个简单例子
如今有数百种算法，而且新算法不断出现
一些算法甚至用多个"决策树"来预测
计算机科学家叫这个"森林"，因为有多颗树嘛
也有不用树的方法，比如"支持向量机"
本质上是用任意线段来切分"决策空间"
不一定是直线
可以是多项式或其他数学函数
就像之前，机器学习算法负责
找出最好的线，最准的决策边界
之前的例子只有两个特征，人类也可以轻松做到
如果加第3个特征，比如"触角长度"
那么2D线段，会变成3D平面
在三个维度上做决策边界
这些平面不必是直的
而且 真正有用的分类器 会有很多飞蛾种类
你可能会同意 现在变得太复杂了
但这也只是个简单例子
- 只有3个特征和5个品种
我们依然可以用 3D散点图 画出来
不幸的是，一次性看4个或20个特征，没有好的方法
更别说成百上千的特征了
但这正是机器学习要面临的问题
你能想象靠手工 在一个上千维度的决策空间里
给超平面(Hyperplane)找出一个方程吗
大概不行
但聪明的机器学习算法可以做到
Google，Facebook，微软和亚马逊的计算机里\N 整天都在跑这些算法
"决策树"和"支持向量机"这样的技术 \N 发源自统计学
统计学早在计算机出现前，就在用数据做决定
有一大类机器学习算法用了统计学
但也有不用统计学的算法
其中最值得注意的是 人工神经网络
灵感来自大脑里的神经元
想学习神经元知识的人，可以看这3集
神经元是细胞
用电信号和化学信号 来处理和传输消息
它从其他细胞 得到一个或多个输入
然后处理信号并发出信号
形成巨大的互联网络，能处理复杂的信息
就像你的大脑 在看这个视频
人造神经元很类似
可以接收多个输入，然后整合并发出一个信号
它不用电信号或化学信号
而是吃数字进去，吐数字出来
它们被放成一层层
形成神经元网络，因此得名神经网络
回到飞蛾例子，看如何用神经网络分类
我们的第一层 - 输入层 -
提供需要被分类的单个飞蛾数据
同样，这次也用重量和翼展
另一边是输出层，有两个神经元：
一个是帝蛾，一个是月蛾
2个神经元里最兴奋的 就是分类结果
中间有一个隐藏层
负责把输入变成输出，负责干分类这个重活
为了看看它是如何分类的
我们放大"隐藏层"里的一个神经元
神经元做的第一件事  \N 是把每个输入乘以一个权重
假设2.8是第一个输入，0.1是第二个输入。
然后它会相加输入
总共是9.74
然后对这个结果，用一个偏差值处理
意思是 加或减一个固定值
比如-6，得到3.74
做神经网络时，这些偏差和权重，\N一开始会设置成随机值
然后算法会调整这些值 来训练神经网络
使用"标记数据"来训练和测试
逐渐提高准确性
- 很像人类学习的过程
最后，神经元有激活函数，它也叫传递函数，
会应用于输出，对结果执行最后一次数学修改
例如，把值限制在-1和+1之间
或把负数改成0
我们用线性传递函数，它不会改变值
所以3.74还是3.74
所以这里的例子
输入0.55和82，输出3.74
这只是一个神经元，
但加权，求和，偏置，激活函数
会应用于一层里的每个神经元
并向前传播，一次一层
数字最高的就是结果：
月蛾
重要的是，隐藏层不是只能有一层，可以有很多层
"深度学习"因此得名
训练更复杂的网络 需要更多的计算量和数据
尽管神经网络50多年前就发明了
深层神经网络直到最近才成为可能
感谢强大的处理器和超快的GPU
感谢游戏玩家对帧率的苛刻要求！
几年前，Google和Facebook
展示了深度神经网络 \N 在照片中识别人脸的准确率，和人一样高
- 人类可是很擅长这个的！
这是个巨大的里程碑
现在有深层神经网络开车，翻译，诊断医疗状况等等
这些算法非常复杂，但还不够"聪明"
它们只能做一件事，分类飞蛾，找人脸，翻译
这种AI叫"弱AI"或"窄AI"，只能做特定任务
但这不意味着它没用
能自动做出诊断的医疗设备，
和自动驾驶的汽车真是太棒了！
但我们是否需要这些计算机来创作音乐
在空闲时间找美味食谱呢？
也许不要
如果有的话 还挺酷的
真正通用的，像人一样聪明的AI，叫 "强AI"
目前没人能做出来 接近人类智能的 AI
有人认为不可能做出来
但许多人说 数字化知识的爆炸性增长
- 比如维基百科，网页和Youtube视频 -
是"强 AI"的完美引燃物
你一天最多只能看24小时的 YouTube \N 计算机可以看上百万小时
比如，IBM 的沃森吸收了 2 亿个网页的内容
包括维基百科的全文
虽然不是"强AI" 但沃森也很聪明 \N 在2011年的知识竞答中碾压了人类
AI不仅可以吸收大量信息 \N 也可以不断学习进步，而且一般比人类快得多
2016 年 Google 推出 AlphaGo
一个会玩围棋的窄AI
它和自己的克隆版下无数次围棋 \N 从而打败最好的人类围棋选手
学习什么管用，什么不管用 \N 自己发现成功的策略
这叫 "强化学习" 是一种很强大的方法
和人类的学习方式非常类似
人类不是天生就会走路，是上千小时的试错学会的
计算机现在才刚学会反复试错来学习
对于很多狭窄的问题，强化学习已被广​​泛使用
有趣的是，如果这类技术可以更广泛地应用
创造出类似人类的"强AI" \N 能像人类小孩一样学习，但学习速度超快
如果这发生了，对人类可能有相当大的影响
- 我们以后会讨论
感谢收看.  我们下周见

今天 我们来思考视觉的重要性
大部分人靠视觉来做饭
越过障碍
读路牌
看视频
以及无数其它任务
视觉是信息最多的感官 \N 比如周围的世界是怎样的，如何和世界交互
因此半个世纪来\N 计算机科学家一直在想办法让计算机有视觉
因此诞生了"计算机视觉"这个领域
目标是让计算机理解图像和视频
用过相机或手机的都知道 \N 可以拍出有惊人保真度和细节的照片
- 比人类强得多
但正如计算机视觉教授 李飞飞 最近说的
"听到"不等于"听懂"
"看到"不等于"看懂"
复习一下，图像是像素网格
每个像素的颜色  通过三种基色定义：红，绿，蓝
通过组合三种颜色的强度 \N 可以得到任何颜色, 也叫 RGB 值
最简单的计算机视觉算法
最合适拿来入门的
是跟踪一个颜色物体，比如一个粉色的球
首先，我们记下球的颜色，保存最中心像素的 RGB 值
然后给程序喂入图像，让它找最接近这个颜色的像素
算法可以从左上角开始，逐个检查像素
计算和目标颜色的差异
检查了每个像素后，最贴近的像素，很可能就是球
不只是这张图片 \N 我们可以在视频的每一帧图片跑这个算法
跟踪球的位置
当然，因为光线，阴影和其它影响
球的颜色会有变化，不会和存的 RGB 值完全一样
但会很接近
如果情况更极端一些 \N 比如比赛是在晚上，追踪效果可能会很差
如果球衣的颜色和球一样，算法就完全晕了
因此很少用这类颜色跟踪算法
除非环境可以严格控制
颜色跟踪算法是一个个像素搜索 \N 因为颜色是在一个像素里
但这种方法 不适合占多个像素的特征
比如物体的边缘，是多个像素组成的.
为了识别这些特征，算法要一块块像素来处理
每一块都叫"块"
举个例子，找垂直边缘的算法
假设用来帮无人机躲避障碍
为了简单，我们把图片转成灰度 \N 不过大部分算法可以处理颜色
放大其中一个杆子，看看边缘是怎样的
可以很容易地看到 杆子的左边缘从哪里开始
因为有垂直的颜色变化
我们可以弄个规则说
某像素是垂直边缘的可能性 \N 取决于左右两边像素的颜色差异程度
左右像素的区别越大，这个像素越可能是边缘
如果色差很小，就不是边缘
这个操作的数学符号 看起来像这样
这叫"核"或"过滤器"
里面的数字用来做像素乘法
总和 存到中心像素里
我们来看个实际例子
我已经把所有像素转成了灰度值
现在把"核"的中心，对准感兴趣的像素
这指定了每个像素要乘的值
然后把所有数字加起来
在这里，最后结果是 147
成为新像素值
把 核 应用于像素块，这种操作叫"卷积"
现在我们把"核"应用到另一个像素
结果是 1
色差很小，不是边缘
如果把"核"用于照片中每个像素
结果会像这样
垂直边缘的像素值很高
注意，水平边缘（比如背景里的平台）
几乎看不见
如果要突出那些特征
要用不同的"核"
用对水平边缘敏感的"核"
这两个边缘增强的核叫"Prewitt 算子"
以发明者命名
这只是众多"核"的两个例子
"核"能做很多种图像转换
比如这个"核"能锐化图像
这个"核"能模糊图像
"核"也可以像饼干模具一样，匹配特定形状
之前做边缘检测的"核"
会检查左右或上下的差异
但我们也可以做出 擅长找线段的"核"
或者包了一圈对比色的区域
这类"核"可以描述简单的形状
比如鼻梁往往比鼻子两侧更亮
所以线段敏感的"核"对这里的值更高
眼睛也很独特
- 一个黑色圆圈被外层更亮的一层像素包着
有其它"核"对这种模式敏感
当计算机扫描图像时，最常见的是用一个窗口来扫
可以找出人脸的特征组合
虽然每个"核"单独找出脸的能力很弱 \N 但组合在一起会相当准确
不是脸但又有一堆脸的特征在正确的位置，\N 这种情况不太可能
这是一个早期很有影响力的算法的基础
叫 维奥拉·琼斯 人脸检测算法
如今的热门算法是 "卷积神经网络"
我们上集谈了神经网络，如果需要可以去看看
总之，神经网络的最基本单位，是神经元
它有多个输入，然后会把每个输入 乘一个权重值
然后求总和
听起来好像挺耳熟，因为它很像"卷积"
实际上，如果我们给神经元输入二维像素
完全就像"卷积"
输入权重等于"核"的值
但和预定义"核"不同
神经网络可以学习对自己有用的"核"
来识别图像中的特征
"卷积神经网络"用一堆神经元处理图像数据
每个都会输出一个新图像，\N 本质上是被不同的"核"处理了
输出会被后面一层神经元处理
卷积卷积再卷积
第一层可能会发现"边缘"这样的特征
单次卷积可以识别出这样的东西，之前说过
下一层可以在这些基础上识别
比如由"边缘"组成的角落
然后下一层可以在"角落"上继续卷积
下一些可能有识别简单物体的神经元
比如嘴和眉毛
然后不断重复，逐渐增加复杂度
直到某一层把所有特征放到一起：
眼睛，耳朵，嘴巴，鼻子
然后说："啊哈，这是脸！"
"卷积神经网络"不是非要很多很多层
但一般会有很多层，来识别复杂物体和场景
所以算是"深度学习"
"维奥拉·琼斯"和"卷积神经网络"\N 不只是认人脸，还可以识别手写文字
在 CT 扫描中发现肿瘤，监测马路是否拥堵
但我们这里接着用人脸举例
不管用什么算法，识别出脸之后
可以用更专用的计算机视觉算法 \N 来定位面部标志
比如鼻尖和嘴角
有了标志点，判断眼睛有没有张开就很容易了
只是点之间的距离罢了
也可以跟踪眉毛的位置
眉毛相对眼睛的位置  可以代表惊喜或喜悦
根据嘴巴的标志点，检测出微笑也很简单
这些信息可以用"情感识别算法"来识别
让电脑知道你是开心，忧伤，沮丧，困惑等等
然后计算机可以做出合适的行为.
比如当你不明白时 给你提示
你心情不好时，就不弹更新提示了
这只是计算机通过视觉感知周围的一个例子
不只是物理环境 - 比如是不是在上班，或是在火车上
还有社交环境 - 比如是朋友的生日派对，还是正式商务会议
你在不同环境会有不同行为，计算机也应如此
如果它们够聪明的话...
面部标记点 也可以捕捉脸的形状
比如两只眼睛之间的距离，以及前额有多高
做生物识别
让有摄像头的计算机能认出你
不管是手机解锁 还是政府用摄像头跟踪人
人脸识别有无限应用场景
另外  跟踪手臂和全身的标记点，最近也有一些突破
让计算机理解用户的身体语言
比如用户给联网微波炉的手势
正如系列中常说的，抽象是构建复杂系统的关键
计算机视觉也是一样
硬件层面，有工程师在造更好的摄像头 \N 让计算机有越来越好的视力
我自己的视力却不能这样
用来自摄像头的数据  可以用视觉算法找出脸和手
然后可以用其他算法接着处理，解释图片中的东西
比如用户的表情和手势
有了这些，人们可以做出新的交互体验
比如智能电视和智能辅导系统 \N 会根据用户的手势和表情来回应
这里的每一层都是活跃的研究领域
每年都有突破，这只是冰山一角
如今 计算机视觉无处不在
- 商店里扫条形码 \N 等红灯的自动驾驶汽车
或是 Snapchat 里添加胡子的滤镜
令人兴奋的是  一切才刚刚开始
最近的技术发展，比如超快的GPU，\N 会开启越来越多可能性
视觉能力达到人类水平的计算机 \N 会彻底改变交互方式
当然，如果计算机能听懂我们然后回话，就更好了
我们下周讨论  到时见

上集我们讨论了计算机视觉 - 让电脑能看到并理解
今天我们讨论  怎么让计算机理解语言
你可能会说：计算机已经有这个能力了
在第9和第12集
我们聊了机器语言和更高层次的编程语言
虽然从定义来说 它们也算语言
但词汇量一般很少，而且非常结构化
代码只能在拼写和语法完全正确时，编译和运行
当然，这和人类语言完全不同 \N - 人类语言叫"自然语言"
自然语言有大量词汇
有些词有多种含义
不同口音
以及各种有趣的文字游戏
人们在写作和说话时也会犯错
比如单词拼在一起发音 \N 关键细节没说 导致意思模糊两可
以及发错音
但大部分情况下，另一方能理解
人类有强大的语言能力
因此，让计算机拥有语音对话的能力
这个想法从构思计算机时就有了
"自然语言处理"因此诞生，简称 NLP
结合了计算机科学和语言学的 一个跨学科领域
单词组成句子的方式有无限种
我们没法给计算机一个字典，包含所有可能句子
让计算机理解人类在嘟囔什么
所以 NLP 早期的一个基本问题是 \N 怎么把句子切成一块块
这样更容易处理
上学时，老师教你 英语单词有九种基本类型：
名词，代词，冠词，动词，形容词
副词，介词，连词和感叹词
这叫"词性"
还有各种子类，比如
单数名词 vs 复数名词 \N 副词最高级 vs 副词比较级
但我们不会深入那些.
了解单词类型有用
但不幸的是，很多词有多重含义 比如 rose 和 leaves
可以用作名词或动词
仅靠字典，不能解决这种模糊问题
所以电脑也要知道语法
因此开发了 "短语结构规则" 来代表语法规则
例如，英语中有一条规则
句子可以由一个名词短语和一个动词短语组成
名词短语可以是冠词，如 the
然后一个名词，或一个形容词后面跟一个名词
你可以给一门语言制定出一堆规则
用这些规则，可以做出"分析树"
它给每个单词标了可能是什么词性
也标明了句子的结构
数据块更小 更容易处理
每次语音搜索，都有这样的流程
比如 "最近的披萨在哪里"
计算机能明白这是"哪里"（where）的问题
知道你想要名词"披萨"（pizza）
而且你关心的维度是"最近的"（nearest）
"最大的长颈鹿是什么？"或"Thriller是谁唱的？" \N 也是这样处理
把语言像乐高一样拆分，方便计算机处理
计算机可以回答问题 以及处理命令
比如"设 2:20 的闹钟"
或"用 Spotify 播放 T-Swizzle"
但你可能体验过，如果句子复杂一点
计算机就没法理解了
嘿Siri ...... 俺觉得蒙古人走得太远了
在这个最温柔的夏日的日子里，你觉得怎么样？
Siri：我没明白
还有，"短语结构规则"和其他把语言结构化的方法
可以用来生成句子
数据存在语义信息网络时，这种方法特别有效
实体互相连在一起
提供构造句子的所有成分
Siri：Thriller 于1983年发行，由迈克尔杰克逊演唱
Google 版的叫"知识图谱"
在2016年底
包含大概七百亿个事实，以及不同实体间的关系
处理, 分析, 生成文字 \N 是聊天机器人的最基本部件
- 聊天机器人就是能和你聊天的程序
早期聊天机器人大多用的是规则.
专家把用户可能会说的话，和机器人应该回复什么，\N 写成上百个规则
显然，这很难维护，而且对话不能太复杂.
一个著名早期例子叫 Eliza\N 1960年代中期 诞生于麻省理工学院
一个治疗师聊天机器人
它用基本句法规则 来理解用户打的文字
然后向用户提问
有时候会感觉像和人类沟通一样
但有时会犯简单 甚至很搞笑的错误
聊天机器人和对话系统
在过去五十年发展了很多，如今可以和真人很像!
如今大多用机器学习
用上GB的真人聊天数据 来训练机器人
现在聊天机器人已经用于客服回答
客服有很多对话可以参考
人们也让聊天机器人互相聊天
在 Facebook 的一个实验里，\N 聊天机器人甚至发展出自己的语言
很多新闻把这个实验 报导的很吓人
但实际上只是计算机 \N 在制定简单协议来帮助沟通
这些语言不是邪恶的，而是为了效率
但如果听到一个句子
- 计算机怎么从声音中提取词汇？
这个领域叫"语音识别"
这个领域已经重点研究了几十年
贝尔实验室在1952年推出了第一个语音识别系统
绰号 Audrey，自动数字识别器
如果你说得够慢，它可以识别全部十位数字
这个项目没有实际应用，因为手输快得多
十年后，1962年的世界博览会上
IBM展示了一个鞋盒大小的机器，能识别16个单词
为了推进"语音识别"领域的研究
DARPA 在1971年启动了一项雄心勃勃的五年筹资计划
之后诞生了卡内基梅隆大学的 Harpy
Harpy 是第一个可以识别1000个单词以上的系统
但那时的电脑
语音转文字，经常比实时说话要慢十倍或以上
幸运的是，1980,1990年代 计算机性能的大幅提升
实时语音识别变得可行
同时也出现了处理自然语言的新算法
不再是手工定规则
而是用机器学习
从语言数据库中学习
如今准确度最高的语音识别系统 用深度神经网络
我们在第34集讲过
为了理解原理
我们来看一些对话声音
先看元音
比如 a 和 e
这是两个声音的波形
我们在第21集（文件格式）说过
这个信号来自 麦克风内部隔膜震动的频率
在这个视图中，横轴是时间
竖轴是隔膜移动的幅度，或者说振幅
虽然可以看到2个波形有区别
但不能看出
"啊！这个声音肯定是 e"
为了更容易识别，我们换个方式看：
谱图
这里横轴还是时间
但竖轴不是振幅
而是不同频率的振幅
颜色越亮，那个频率的声音越大
这种波形到频率的转换 是用一种很酷的算法做的
快速傅立叶变换（FFT）
如果你盯过立体声系统的 EQ 可视化器
它们差不多是一回事
谱图是随着时间变化的
你可能注意到，信号有种螺纹图案
那是我声道的回声
为了发出不同声音
我要把声带，嘴巴和舌头变成不同形状
放大或减少不同的共振
可以看到有些区域更亮，有些更暗
如果从底向上看，标出高峰
- 叫"共振峰"  -
可以看到有很大不同
所有元音都是如此
这让计算机可以识别元音
然后识别出整个词
让我们看一个更复杂的例子
当我说"她..很开心"的时候
可以看到 e 声，和 a 声
以及其它不同声音
比如 she 中的 shh 声
was 中的 wah 和 sss，等等
这些构成单词的声音片段
叫"音素"
语音识别软件 知道这些音素
英语有大概44种音素
所以本质上变成了音素识别
还要把不同的词分开
弄清句子的开始和结束点
最后把语音转成文字
使这集视频开头里讨论的那些技术成为可能
因为口音和发音错误等原因
人们说单词的方式略有不同
所以结合语言模型后，语音转文字的准确度会大大提高
里面有单词顺序的统计信息
比如："她"后面很可能跟一个形容词，\N 比如"很开心"
"她"后面很少是名词
如果不确定是 happy 还是 harpy，会选 happy
因为语言模型认为可能性更高
最后, 我们来谈谈 "语音合成"
让计算机输出语音
它很像语音识别，不过反过来
把一段文字，分解成多个声音
然后播放这些声音
早期语音合成技术，可以清楚听到音素是拼在一起的
比如这个1937年贝尔实验室的手动操作机器
不带感情的说"她看见了我"
她看见了我
现在回答问题
谁看见你了？
她看到了谁？
她看到你还是听到你说话了？
到了1980年代，技术改进了很多
但音素混合依然不够好，产生明显的机器人声
Thriller 于1983年发行，迈克尔·杰克逊 演唱.
如今，电脑合成的声音，比如 Siri, Cortana, Alexa
好了很多，但还不够像人
但我们非常非常接近了
这个问题很快会被解决
现在语音界面到处都是，手机里
汽车里，家里，也许不久之后耳机也会有.
这创造一个正反馈循环
人们用语音交互的频率会提高
这又给了谷歌，亚马逊，微软等公司
更多数据来训练语音系统.
提高准确性
准确度高了，人们更愿意用语音交互
越用越好，越好越用
很多人预测，语音交互会越来越常见
就像如今的屏幕，键盘，触控板等设备
这对机器人发展是个好消息
机器人就不用走来走去时  带个键盘和人类沟通
下周我们讲机器人.  到时见

今天 我们要讨论机器人
你脑中冒出来的第一个印象估计是 类人机器人
经常在电视剧和电影里看到.
有时候它们是朋友和同事
但更常见的是阴险无情，身经百战
我们经常把机器人看成未来科技
但事实是：机器人时代已经来临了
- 它们是同事
帮我们把困难的工作，做得更快更好
机器人的定义有很多种，但总的来说，
机器人由计算机控制，可以自动执行一系列动作的机器
外观并不重要
可以是给汽车喷漆的机械臂
无人机，或辅助外科医生的蛇状机器人
以及人形机器人
有时我们叫虚拟人物"机器人"
但叫 bot 甚至 agent 会更合适
因为"机器人"的潜在含义是  存在于现实世界中的机器
robot (机器人) 一词 \N 首次出现在1920年的一部捷克戏剧
代表人造的类人角色
robot 源于斯拉夫语词汇 robota  \N 代表强迫劳动
代表农民在十九世纪 \N 欧洲封建社会的强迫劳动
戏剧没讲太多技术细节
但即使一个世纪后，这种描述依然很普遍：
机器人都是大规模生产，高效不知疲倦，看起来像人的东西
但毫无情感，不会保护自己，没有创造力
更广义的自动运行机器，早在1920年代前就有了
很多古代发明家 \N 发明了能自动运行的机械装置
比如计时和定时敲钟
有很多装置 有动物和人类的形象 \N 能跳舞，唱歌，打鼓等
这些不用电，而且肯定没有电子部件的机器，叫"自动机"
举个例子 \N 1739年法国人 Jacques de Vaucans 做了个自动机
法语叫 Canard Digerateur，翻译过来是 "吃饭鸭"
一个像鸭子的机器，能吃东西然后排便
伏尔泰在1739年写
"如果没有吃饭鸭的声音
还有什么能提醒你法国的荣光呢？"
一个名声很臭的例子是"土耳其行棋傀儡"
一个能下国际象棋的人形机器人
在1770年建造完成后，就在欧洲各地展览
好棋艺惊叹观众
像某种机械人工智能
不幸的是，这是个骗局 - 机器里有人控制
第一台计算机控制的机器，出现在1940年代晚期
这些计算机数控的机器，简称 CNC 机器
可以执行一连串 程序指定的操作
精细的控制 让我们能生产之前很难做的物品
比如从一整块铝 加工出复杂的螺旋桨
- 这用普通机械工具很难做到
并且误差容忍度很小，无法手工加工
CNC 机器大大推进了制造业
不仅提高了制造能力和精确度 还降低了生产成本
- 我们之后会深入讨论这个（第40集）
第一个商业贩卖的 可编程工业机器人
叫 Unimate，于1960年卖给通用汽车公司
它可以把压铸机做出来的热金属成品提起来，然后堆起来
机器人行业由此开始
很快，机器人开始堆叠货盘，焊接，给汽车喷漆等等
对于简单运动 - 比如机器爪子 在轨道上来回移动
可以指示它移动到特定位置
它会一直朝那个方向移动，直到到达 \N 然后停下来
这种行为 可以用简单控制回路做
首先，判断机器人的位置
我们到了吗？
没有
那么继续前进
再次判断位置
没有，所以继续前进
是的!
现在可以停下来了，别问了！
因为我们在不断缩小 当前位置和目标位置的距离
这个控制回路 更准确的叫"负反馈回路"
负反馈回路 有三个重要部分
首先是一个传感器，可以测量现实中的东西
比如水压，马达位置，气温，
或任何你想控制的东西
根据传感器，计算和目标值相差多大
得到一个"错误"
然后"控制器"会处理这个"错误"
决定怎么减小错误
然后用泵，电机，加热元件，或其他物理组件来做出动作
在严格控制的环境中，这种简单控制回路也够用了
但在很多现实应用中，情况复杂得多
假设爪子很重，哪怕控制回路叫停了
惯性让爪子超过了预期位置
然后控制回路又开始运行
叫爪子移动回去
一个糟糕的控制回路 可能会让爪子不断来回移动
甚至永远循环
更糟糕的是，现实世界中
机器人会受到各种外力影响
比如摩擦力，风，等等
为了处理这些外力，我们需要更复杂的控制逻辑
一个使用广泛的机制，有控制回路和反馈机制。
叫 "比例-积分-微分控制器"
这个有点绕口，所以一般简称 "PID控制器"
它以前是机械设备，现在全是纯软件了
想象有一个机器人，端咖啡给客人
设计目标是 每秒两米的速度在顾客间穿行
这个速度是理想速度
安全又合适
当然，环境是会变化的
有时候有风，有时候有上坡下坡
以及其他影响机器人速度的因素
所以，给马达的动力要加大或减少，以保持目标速度
用机器人的速度传感器，我们可以
把当前速度和目标速度画张图
PID 控制器根据这些数据，算出3个值
首先是"比例值"，就是"实际值"和"理想值"差多少
"实际值"可能有一定滞后，或者是实时的。
之前的简单控制回路，用的就是这个值
"实际值"和"理想值"的差距越大，
就越用力
换句话说，它是"比例控制"的
接下来，算"积分值"
就是一段时间内 误差的总和
比如最近几秒
帮助弥补误差
比如上坡时可能就会产生误差
如果这个值很大，说明比例控制不够，
要继续用力前进
最后有"导数值"
是期望值与实际值之间的变化率
有助于解决 未来可能出现的错误，
有时也叫"预期控制"
比如前进的太快
要稍微放松一点，避免冲过头
这三个值会一起使用，它们有不同权重
然后用来控制系统
PID 控制器到处都是
比如汽车里的巡航控制
无人机调整螺旋桨速度，以保持水平
以及一些更奇怪的机器人，
比如这个用球来平衡和移动的机器人
更高级的机器人一般需要多个控制回路同时运行
来保持机器人平衡，调整肢体位置，等等
之前说过，控制回路负责
把机器人的属性（比如当前位置）变成期望值
你可能好奇这些值 是哪里来的
这是更高层软件的责任
软件负责做出计划 并让机器人执行动作，
比如制定一条路线来绕过障碍物，或者把任务分成一步步
比如把拿起一个球，分解成一个个简单连续动作
用这些技术，机器人已经取得不少令人印象深刻的成就
- 它们潜到了海洋最深处
在火星上跑了十几年
但有趣的是，许多对人类来说很简单的任务
对机器人很困难：
比如两条腿走路，开门，拿东西时不要捏碎了
或是穿T恤，或是摸狗
这些你可能想都不用想
但有超级计算机能力的机器人却做不到
机器人研究领域在全力解决这些问题
我们前几集聊过的 人工智能
最有可能解决这些问题
例如，谷歌在进行一项实验
让一堆机器人手臂把各种东西
从一个盒子拿到另一个盒子，不断试错学习
经过数千小时的练习，机器人把错误率降低了一半
不像人类，机器人可以24小时全天运行
而且多个手臂同时练习
所以机器人擅长抓东西只是时间问题
但现在，小婴儿都比机器人更会抓东西
近年最大的突破之一
是无人驾驶汽车
如果你仔细想想，汽车没几个输入
- 只是加速减速，左转右转
难的问题是 判断车道，理解路标
预测车流，车流中穿行，留心行人和骑自行车的。
以及各种障碍
车上布满了传感器
无人驾驶汽车非常依赖
计算机视觉算法，我们在第35集讨论过
现在也开始出现类人机器人
- 外貌和行为像人类的机器人
不过现在两个目标都没接近（外貌和行为）
因为看起来一般怪怪的，行为也怪怪的.
但至少有《西部世界》可以看看
无论如何，对机器人研究者来说，把各种技术结合起来
比如人工智能，计算机视觉和自然语言处理
来让机器人越来越像人，是个诱人的目标
至于人类为什么如此着迷 做出和我们一样的机器人
你得去看《哲学速成课》
在未来好一段时间里
和人类一样的机器人 依然只能存在科幻小说里。
军队也对机器人很有兴趣 -
因为机器人可以替换，
而且力量，耐力，注意力，准确性可以远超人类
拆弹机器人和无人侦察机如今很常见
但完全自主决定，全副武装的机器人也在慢慢出现
比如韩国的三星 SGR-A1 哨兵炮
有智力并且可以杀人的机器人
叫 "致命自主武器"
这种武器是复杂又棘手的问题
毫无疑问，它们可以把士兵从战场带离 挽救生命
甚至阻止战争的发生
值得注意的是 人们对炸药和核弹也说过一样的话
另一方面，我们可能会不小心创造出 \N 无情又高效的杀人机器
没有人类般的判断力和同情心
战争的硝烟会变得更加黑暗和复杂
机器人会接受命令并高效执行
但有时人类的命令是错的
这场辩论会持续很长时间，
而且随着机器人技术的进步，两边的辩论会越来越激烈
这也是个老话题了
科幻作家 艾萨克·阿西莫夫 早预见了这种危险
他在1942年短篇小说 Runaround 中写了"机器人三定律"
之后又加了"定律0"
简单说 这些定律指导机器人的行为准则 或者说道德指南
让机器人不要伤害，特别是不要伤害人类
这些规则实践起来相当不足，并且有很多模糊的地方
但阿西莫夫三定律 激发了大量科幻小说讨论和学术讨论，
如今有专门讨论机器人伦理的会议
重要的是，阿西莫夫写这些虚构规则
是为了反对 "机器人都很邪恶" 这种常见描述
他童年读的小说里，这样的场景很常见
机器人脱离控制，然后伤害甚至毁灭创造者
阿西莫夫认为 机器人有用，可靠，甚至可以让人喜爱
我想让你思考这种两面性
我们讨论过的许多技术，有好的一面也有坏的一面
我们要认真思考计算机的潜力和危害
来改善这个世界
而机器人最能提醒我们这一点了
我 们 下 周 见

在这个系列中，
我们聊的话题几乎全是计算机-比如电路和算法
毕竟这是*计算机*速成课
但归根结底，计算机只是给人用的工具
而人类有点... 乱
人类不是被工程师设计的，没有具体性能规格
我们一会儿是理性的，一会儿是不理性的
你有没有对导航生过气？或是漫无目的的刷维基百科？
求浏览器加载快点？
给扫地机器人取名？
这些是人类行为！
为了做出使用愉快的计算机
我们需要了解计算机和人类的优缺点
优秀的系统设计师在创造软件时
会运用社会心理学，认知心理学，\N 行为心理学，感知心理学的原理
你肯定见过难用的物理界面/计算机界面 \N 阻碍你做事
甚至糟糕到放弃使用
那个界面的"易用度"很差
"易用度"指的是人造物体，比如软件 \N 达到目的的效率有多高
为了帮助人类工作，我们需要了解人类 \N  - 怎么看，思考，反应和互动
举个例子，心理学家已经对 \N 人类的视觉系统做了全面的研究
我们知道人类擅长给颜色强度排序
这里有三个颜色
你能从浅色到深色排序吗？
你可以轻易做到
所以颜色强度很适合显示连续值
另一方面，人类很不擅长排序颜色
这是另一个例子
把橙色放到蓝色前面还是后面？绿色放哪里？
你可能想通过光的波长排序 \N 就像彩虹一样，但这样太累了
大部分人会很慢而且容易出错
由于视觉系统天生是这样
所以用不同颜色显示连续性数据，是个糟糕的选择
你得经常看表格来对比数据
然而，如果数据没有顺序，用不同颜色就很合适
比如分类数据
也许这些看起来很明显 \N 但你会惊讶有多少设计把这些基本事情搞错
除了视觉 \N 理解人类的认知系统能帮我们设计更好的界面
比如，如果信息分块了 \N 会更容易读，更容易记
分块是指把信息分成更小，更有意义的块
人类的短期记忆能记住5到9个东西
保守一点，分组一般是5个或更少
所以电话号码一般分块，比如 317-555-3897
10个连续数可能会忘，分成3块更好记
从计算机的角度来看，分块更费时费空间
效率更低
但这对人类更有效率
- 碰到这种抉择时，我们总是以人类优先
现在我们还是老大.. 暂时啦
界面设计用了分块 \N 比如下拉菜单 和带按钮的菜单栏
对电脑来说，全部挤在一起更有效率
分块浪费内存 浪费屏幕
但这样设计更容易扫视，记住和访问
界面设计中另一个重点概念是"直观功能"
Don Norman 让这个词在计算机界流行起来，根据他的说法
"直观功能 为如何操作物体提供线索
平板用来推
旋钮用来转
插槽用来插东西
[...]直观功能做的好，用户只需要看一眼就知道怎么做：
不需要图片，标签或指南来说明"
如果你拉过门把手打不开，然后意识到要推开才对
那么你发现了一个坏掉的"直观功能"
平板是更好的设计
因为只能推开
门是简单的东西，如果你要贴指示让人们明白怎么用.
那么也许你应该重新设计
"直观功能"广泛用于图形界面
我们在第26集讨论过
这是图形界面比命令行更容易用的原因之一
你不用猜测屏幕上什么东西是可点的，\N 可点的会看起来像按钮
他们弹出来，只是等着你压他们！
我最喜欢的"直观功能"之一，是向用户表明元素是可拖动的
"滚花" - 一种视觉纹理
告诉用户哪里可以拖动
这个点子来自现实世界中的工具
和"直观功能"相关的一个心理学概念是 "认出与回想"
如果你考过试，肯定感受过这个
这就是为什么选择题比填空题容易
一般来说，用感觉来触发记忆会容易得多
比如文字，图片或声音
所以我们用图标代表功能
- 比如"垃圾桶"图标 代表里面放着被删除的文件
我们不用去回想图标的功能是什么，只要能认出来就行了
比命令行好得多
命令行得依靠记忆来输命令
到底是输入"删除""移除""垃圾"还是"射出"？\N 可能是任何命令！
顺带一说，在 Linux 里删除文件的命令是 "rm"
回到正题，\N 让所有菜单选项好找好记，有时候意味着用的时候会慢一些
这与另一个心理学概念冲突："专业知识"
当你用界面熟悉之后，速度会更快一些
建立如何高效完成事情的"心理模型"
所以 好的界面应该提供多种方法来实现目标
一个好例子是复制粘贴，可以在"编辑"的下拉菜单中找到
也可以用快捷键
一种适合新手，一种适合专家，两者都不耽误
鱼和熊掌兼得！
除了让人类做事更高效，
我们也希望电脑能有一点情商
能根据用户的状态做出合适地反应
让使用电脑更加愉快
Rosalind Picard 在 1995 年关于"情感计算"的论文中，阐述了这一愿景
这篇论文开创了心理学，社会科学和计算机科学的跨学科结合
促进了让计算机理解人类情感的研究
这很重要，因为情绪会影响日常活动
比如学习，沟通和决策
情感系统会用传感器，录声音，
录像（你的脸）以及生物指标，比如出汗和心率
得到的数据和计算模型结合使用
模型会写明人类如何表达情感，怎么是快乐 怎么是沮丧
以及社交状态，比如友谊和信任
模型会估算用户的情绪
以及怎样以最好的回应用户
以达到目标
比如让用户冷静下来，建立信任，或帮忙完成作业
Facebook 在 2012 年进行了一项"影响用户"的研究
数据科学家在一个星期内
修改了很多用户 时间线上显示的内容
有些人会看到更多积极向上的内容
有些人会看到更多负面消极的内容
研究人员分析了那一周内人们的发帖
发现看到积极向上内容的用户，
发的帖子往往更正面
另一方面，看到负面内容的用户，发的内容也更负面
显然，Facebook和其他网站向你展示的内容
绝对会对你有影响
作为信息的守门人，这是巨大的机会 同时也是责任
研究结果相当有争议性.
而且它还产生了一个有趣的问题：
计算机程序如何回应人类
如果用户的情绪比较负面，也许电脑不应该
以一种烦人的 "你要振作起来呀" 的态度回答问题.
或者，也许电脑应该试着积极正面的回应用户
即使这有点尴尬.
什么行为是"正确的"，是个开放性的研究问题
既然说到Facebook，\N 这是一个"以计算机为媒介沟通"的好例子，简称 "CMC"
也是一个很大的研究领域
这包括同步通信 - 所有参与者同时在线进行视频通话
以及异步通信 - 比如推特，邮件，
短信，人们可以随时随地回复信息
研究人员还研究用户怎么用表情包，怎么轮换发言，
以及用不同沟通渠道时，用词有什么区别.
一个有趣的发现是，比起面对面沟通，
人们更愿意在网上透露自己的信息
所以如果想知道用户 \N 真正花了多少小时看"大英烘培大赛"(电视节目)
比起做个带脸的虚拟助理 \N 做 聊天机器人 是个更好的选择
心理学研究也表明，如果想说服，讲课，或引起注意 \N 眼神注视非常重要
在谈话时看着别人叫 相互凝视
这被证明可以促进参与感 帮助实现谈话目标，
不管是学习，交朋友，还是谈生意
在录像讲座中，老师很少直视相机 \N 一般是看在场学生
对他们没问题，但这会让在线看视频的人  没什么参与感
为此，研究人员开发了计算机视觉和图形软件 \N 来纠正头部和眼睛
视频时会觉得对方在直视摄像头，看着他们
这叫"增强凝视"
类似技术也用于视频会议
纠正摄像头位置，因为摄像头几乎总在屏幕上方
因为你一般会盯着屏幕上的另一方 \N 而不是盯着摄像头
所以视频里看起来像在向下看
没有相互凝视 - 这会导致各种不幸的副作用，比如权力不平衡
幸运的是  可以用软件修正
看起来像在凝视着对方的眼睛
人类也喜欢"拟人化"的物体，对计算机也不例外
特别是会动的计算机，比如上集说的机器人
在过去一个世纪，除了工业用途机器人
有越来越多机器人用于医疗，教育和娱乐 \N 它们经常和人类互动
人机交互，简称 HRI
- 是一个研究人类和机器人交互的领域，
比如人类如何感受 机器人的不同形式和不同行为
或是机器人如何明白人类暗示来社交，而不是尴尬的互动
正如上集说的，我们有追求
把机器人的外表和行为，做得尽可能像人一样
工程师在1940 1950年代刚开始做机器人时，\N 看起来完全不像人
是完完全全的工业机器
随着时间的推移，工程师越来越擅长做类人机器人
它们有头，而且用两条腿走路
但它们做不到伪装成人类去餐馆点餐
随着机器人可以做得越来越像人类
用人造眼球代替摄像头，用人工肌肉盖住金属骨架
事情会开始变得有些.. 奇怪.. \N 引起一种怪异不安的感觉
这个"几乎像人类"和"真的人类"之间的小曲线，叫 "恐怖谷"
对于机器人是否应该有人类一样的行为，也存在争议
很多证据表明，即使机器人的行为不像人类
人类也会用社交习俗对待它们
而当机器人违反习俗时 - 比如插队或踩了脚不道歉 \N 人们会很生气！
毫无疑问，心理学+计算机科学是强大的组合
可以影响日常生活的巨大潜力
这也带来了很多开放式问题，比如你可能会对计算机撒谎
但计算机应不应该对你撒谎？
如果撒谎能让你更高效更快乐呢？
或社交媒体公司 \N 是否应该精心挑选展示给你的内容
让你在网站上多待一会儿，买更多东西？
顺带一说，他们的确有这样做
这类道德问题不容易回答，但心理学至少可以
帮助我们理解不同选择 带来的影响和意义
但从积极的方面来说，了解设计背后的心理学
能增加易用性
让更多人可以明白和使用电脑，如今计算机比以往更加直观
线上会议和虚拟教室的体验越来越好
随着机器人技术不断提高，互动也会越来越舒适
另外，感谢心理学，让我们能分享对"滚花"的热爱
我们下周见

计算机带来的最大改变之一  \N 是信息的创造和传播能力
目前有13亿个网站在互联网上
仅维基百科就有500万篇英文文章
涵盖从"1518年的舞蹈瘟疫"
到"正确的纸卷方向"
每天，Google提供40亿次搜索来访问这些信息
Youtube上每分钟有350万个视频被观看.
每分钟用户上传400小时的新视频
很多观看量都是 Gangnam Style 和 Despacito
但剩下的 大部分是教育型内容
就像你现在看的这个.
如今只要手机上点几下 就能访问到这些宝藏
任何时间，任何地点
但能获取到信息和学习不是一回事
先说清楚，我们 Crash Course 喜欢互动式课堂学习
课上提问，以及上手实践，它们是很棒的学习途径
但我们也相信教育型技术在课内课外带来的帮助
今天我们要在这个教育型视频里 \N 聊教育型科技
具体讲解计算机怎么帮助我们学习
从纸和笔 到用机器学习的智能系统，
科技几千年来一直在辅助教育
甚至早期人类 在洞穴里画狩猎场景也是为了后代
远距离教育一直推动着教育科技的发展
例如公元50年左右，圣保罗就发书信 \N 给亚洲设立的新教堂提供宗教课程
从那以后，有几大技术浪潮，自称要改变教育
从广播和电视，到DVD和光碟
事实上，在1913年 托马斯·爱迪生 预测说
"书籍很快会过时.. 用影片来教授所有知识是可能的
学校体系将在未来十年彻底改变"
当然，他的预测没有成真
但发布教育视频变得越来越流行
在讨论教育技术可以帮你做什么之前
有研究表明 有些简单事情 \N 可以显著提高学习效率
1. 把速度调整到适合你，YouTube 的速度设置在右下角
让你能理解视频  有足够的时间思考
2. 暂停！在困难的部分暂停
问自己一些问题，看能不能回答
或想想视频接下来可能讲什么 \N 然后继续播放，看猜对没有
3. 做视频中的提供的练习
即使不是程序员，你也可以在纸上写伪代码，或试试学编程
这些主动学习的技巧已被证明 \N 可以把学习效率提升10倍或以上
如果想学学习技巧，有整个系列专门讲这个
把高质量教育内容做成视频传播 \N 在过去一个世纪吸引了很多人
这个老想法的新化身
以"大型开放式在线课程"（MOOC）的形式出现
纽约时报宣称 2012 年是 MOOC 年！
很多早期视频 直接录制著名教授上课
有段时间，有些人以为大学要终结了
不管你是担心还是开心，这暂时还没成为现实
现在热度也淡去了
这可能是因为加大规模时 同时教百万名学生
但老师数量很少，甚至完全没有老师
- 会遇到很多问题
幸运的是，这引起了计算机科学家，\N 或具体一点 "教育科技家"的兴趣
他们在想办法解决这些问题
比如，为了有效学习，学生要及时获得反馈
但如果有几百万学生，只有一名老师，
怎么提供好的反馈？
一个老师怎么给一百万份作业打成绩？
为了解决问题，很多时候需要把科技和人类都用上
一种有用 但有些争议的做法是
学生互相之间提供反馈
不幸的是，学生一般做不好
他们既不是专家也不是老师
但我们可以用技术来帮助他们
比如通过算法，从数百万个选择里 \N 匹配出最完美的学习伙伴
另外，有些部分可以机器打分，剩下的让人类打分
例如，给 SAT 写作部分打分的电脑算法
已被证实和人工打分一样准确
还有些算法提供个性化学习体验
类似于 Netflix 的电影推荐 \N 或 Google 的个性化搜索结果
为了个性化推荐，\N 软件需要了解用户知道什么，不知道什么
在正确的时间提供正确的资料，
让用户练习没理解的难的部分
而不是给出用户已经学会的内容
这种系统一般用 AI 实现
泛称叫法是"智能辅导系统"
我们现在讲一个假想的辅导系统
假设学生在这个假想的辅导系统中，研究一个代数问题
正确的下一步是两边-7
我们可以用 "判断规则" 来表示这一步
用 IF-THEN 语句来描述
伪代码是
*如果* 变量和常数在同一边
*那么* 两侧都减去这个常数
"判断规则" 酷的地方是也可以用来
代表学生的常犯错误
这些"判断规则"叫"错误规则"
例如，学生可能不去减常数
而是去减系数
这不行！
学生做完一个步骤后可能触发多个"判断规则"
系统不能完全弄清 是什么原因让学生选了那个答案
所以"判断规则"会和算法结合使用，判断可能原因
让学生得到有用反馈
"判断规则"+选择算法，组合在一起成为 "域模型"
它给知识，解决步骤和一门学科 比如代数，\N 用一种"正式写法"来表示
域模型可以用来 帮助学习者解决特定问题
但它无法带着学习者 \N 以正确顺序搞定整个学科该上的所有课程
因为域模型不记录进度
因此智能辅导系统 负责创建和维护学生模型
- 记录学生已经掌握的判断规则
以及还需练习的生疏部分
这正是个性化辅导系统需要的。
听起来好像不难，
但只靠学生对一些问题的回答，\N 来弄清学生知道什么，不知道什么，是很大的挑战
"贝叶斯知识追踪" 常用来解决这个问题
这个算法把学生的知识 当成一组隐藏变量
这些变量的值，对外部是不可见的
比如我们的软件
这在现实中也是一样的
老师无法知道 学生是否完全掌握了某个知识点
老师会出考题，测试学生能否答对
同样，"贝叶斯知识追踪" \N 会看学生答题的正确度，更新学生掌握程度的估算值
它会记录四个概率
首先是 "学生已经学会的概率"
比如从代数方程的两边减去常数
假设学生正确将两边-7
做对了
我们可以假设她知道怎么做
但也有可能她是瞎蒙的
没有真的学会怎么解决问题
这叫 "瞎猜的概率"
类似的，如果学生答错了，
你可能会假设她不会做
但她可能知道答案，只是不小心犯了个错
这叫 "失误的概率"
最后一个概率
是学生一开始不会做，\N 但是在解决问题的过程中，学会了怎么做
这叫 "做题过程中学会的概率"
有一组方程，会用这四个概率，更新学生模型
对学生应该学会的每项技能进行持续评估
第一个等式问：
学生已经知道某技能的概率是多少？
等式里有
"之前已经学会的概率"和"做题过程中学会的概率"
就像老师一样，"之前已经学会的概率"
取决于学生回答问题正确与否，
回答正确和错误分别有2个公式
算出结果之后，我们把结果放到第一个方程
更新"之前已经学会的概率"
然后存到学生模型里.
虽然存在其他方法，
但"智能辅导系统"通常用 贝叶斯知识追踪
让学生练习技能，直到掌握
为了高效做到这点，软件要选择合适的问题
呈现给学生，让学生学
这叫：自适应式程序
个性化算法的形式之一
但我们的例子只是一个学生的数据
现在有 App 或网站
让教师和研究人员 收集上百万学习者的数据
从数据中可以发现常见错误\N 一般哪里难倒学生
除了学生的回答，还可以看回答前暂停了多久
哪个部分加速视频，
以及学生如何在论坛和其他人互动
这个领域叫 "教育数据挖掘"
它能用上学生所有的"捂脸"和"啊哈"时刻
帮助改善未来的个性化学习
谈到未来，教育技术人员经常从科幻小说中获得灵感
具体来说，Neal Stephenson 的"钻石时代"这本书\N 激励了很多研究人员
里面说一个年轻女孩从书中学习
书中有一些虚拟助手会和她互动，教她知识
这些助手和她一起成长
直到她学会了什么，以及感觉如何，
给她正确的反馈和支持，帮助她学习
如今 有非科幻小说研究者，比如 贾斯汀卡塞尔，
在制作虚拟教学助手
助手可以"像人类一样沟通 有人类一样的行为
在陪伴过程中和学习者建立信任，
相处融洽，甚至和人类学生成为朋友"
2040年的"速成课" \N 可能会有一个 John Green AI，活在你的 iPhone 30 上
教育科技和设备 \N如今在逐渐扩展到笔记本和台式电脑之外
比如巨大桌面设备，让学生可以团队合作
以及小型移动设备，让学生路上也能学习
"虚拟现实"和"增强现实"也让人们兴奋不已
它们可以为学习者提供全新的体验 -
深潜海洋，探索太空，
漫游人体，或是和现实中难以遇见的生物互动
如果猜想遥远的未来，教育可能会完全消失，
直接在大脑层面进行
把新技能直接下载到大脑
这看起来可能很遥远，
但科学家们已经在摸索 - 比如
仅仅通过检测大脑信号，得知某人是否知道什么
这带来了一个有趣的问题：
如果我们可以把东西下载到大脑里
我们能不能上传大脑里的东西？
下周的最后一集，我们会讨论计算的未来
到时见

我们到了 最后一集！
如果你看了整个系列，
希望你对计算机影响的深度和广度 \N 有全新的认知和欣赏
难以相信 我们从简单的晶体管和逻辑门开始
一直到计算机视觉，机器学习，机器人以及更多
我们站在巨人的肩膀上
Vannevar Bush (Memex) \N  Berners-Lee  (万维网) \N Bill Gates (微软)\N Steve Wozniak (苹果)
和许多其他先驱
我最大的希望是 这些视频能激励你 \N 去了解这些东西如何影响你的人生
甚至开始学编程，或找一份计算机职业
这很棒！
这是未来的技能
我在第一集说过，计算机科学不是魔法\N 但它有点像魔法
学习使用电脑和编程，是21世纪的巫术
只不过用的不是咒语 而是代码
懂得运用的人，能创造出伟大的东西
不仅改善自己的生活，还有当地社区乃至整体人类
计算机会随处可见 -
不仅是放在桌上 带在包里
而是在所有可想象的东西里
厨房用具里，墙里，食物里
编织进衣服里，在你的血液里
这是"普适计算"的愿景
从某种角度来讲 它已经来临了\N 而换一个角度  还要几十年
有些人把这种未来看成 反乌托邦
到处都有监视器，有无数东西想吸引我们的注意力
但 1990 年代提出这个想法的 马克·维泽尔
看到了非常不同的潜力：
"[五十]年来，大多数界面和计算机设计，
都是朝"戏剧性"方向前进
想把计算机做得超好，让人一刻也不想离开
另一条少有人走的路 是"无形"的
把计算机整合到所有东西里 \N 用的时候很自然 完全注意不到
最厉害的科技是看不见的科技
它们融入到日常生活的每一部分 直到无法区分"
如今我们还没达到这样
- 人们在电脑前连续坐好几小时
吃晚餐被手机推送通知打扰
但它可以描述计算的未来 \N  本系列最后一个主题
人们思考计算机的未来时 经常会直接想到人工智能
毫无疑问，接下来几十年人工智能会有巨大进步
但不是所有东西都要做成 AI ，或需要 AI
车有自动驾驶AI，但门锁依然会很简单
人工智能可能只是增强现有设备
比如汽车，AI 带来了一个全新的产品种类
刚出现电力时也是这样，灯泡取代了蜡烛.
但电气化也导致上百种新的电动小工具诞生
当然 我们如今仍然有蜡烛
最可能的情况是 AI 变成 \N 计算机科学家手中的另一门新工具
但真正让人深思和担忧的是
人工智能是否会超越人类智能？
这个问题很难 有多方面原因
比如 "智能的准确定义是什么？"
一方面，有会开车的计算机
几秒就能识别歌的 App
翻译几十种语言，\N 还称霸了一些游戏，比如象棋，知识竞答和围棋
听起来很聪明！
但另一方面，计算机连一些简单事情都做不了
比如走楼梯，叠衣服，
在鸡尾酒派对和人聊天，喂饱自己
人工智能成长到和人类一样通用，还有很长的路
因为"智能"是难以量化的指标
人们更喜欢用处理能力来区分
但这种衡量智能的方法比较"以计算为中心"
但如果把视频中出现过的电脑和处理器 画张图
可以看到 如今的计算能力粗略等同于一只老鼠
公平点说，老鼠也不会叠衣服\N 但如果真的会叠 就太可爱了
人类的计算能力在这儿，多10的5次方
也就是比如今电脑强10万倍
听起来差距很大，但按如今的发展速度，
也许十几年就可以赶上了
虽然现在处理器的速度 不再按摩尔定律增长了
我们在第17集讨论过
假设趋势继续保持下去，在本世纪结束前
计算机的处理能力/智能 会比全人类加起来还多
然后人的参与会越来越少，人工超级智能会开始改造自己
智能科技的失控性发展叫 "奇点"
第10集 约翰·冯·诺伊曼 最早用这个词
他说：
"越来越快的技术发展速度和人类生活方式的改变，
看起来会接近人类历史中某些重要的奇点
这个势头不会永远继续下去"
冯诺依曼在 1950 年代说的这话.
那时计算机比现在慢得多
六十年后的今天，奇点仍然在遥远的地平线上
一些专家认为 发展趋势会更平缓一些
更像是S型，而不是指数型
而随着复杂度增加，进步会越来越难
微软联合创始人 保罗·艾伦 叫这个"复杂度刹车"
但当作思维练习
我们假设 超智能计算机会出现。
这对人类意味着什么，是个讨论激烈的话题
有些人迫不及待
有些人则努力阻止它
最直接的影响可能是"技术性失业"
很多工作被计算机，比如AI和机器人，给代替掉了
它们的效率更高，成本更低
虽然计算机出现没多久，但"技术性失业"不是新事
还记得第10集里 雅卡尔的织布机 吗？
它让1800年代的纺织工人失业，导致了骚乱
当时美国和欧洲 大部分人都是农民
如今农民占人口比例<5％
因为有合成肥料和拖拉机等等技术
时间更近一些的例子是"电话接线员"
在1960年被自动接线板代替了
还有1980年代的"机器喷漆臂"替代了人工喷漆
这样的例子还有很多.
一方面，因为自动化失去了工作
另一方面，我们有大量产品，\N 衣服，食物，自行车，玩具等
因为可以廉价生产
但专家认为人工智能，机器人 以及更广义的计算
比之前更有破坏性
工作可以用两个维度概括
首先，手工型工作，比如组装玩具
- 或思维型工作 - 比如选股票
还有重复性工作，一遍遍做相同的事
或非重复性，需要创造性的解决问题
我们知道 重复性手工工作，可以让机器自动化
现在有些已经替代了，剩下的在逐渐替代
让人担心的是"非重复性手工型工作"
比如厨师，服务员，保安。
思维型工作也一样
比如客服，收银员，银行柜员和办公室助理
剩下一个暂时比较安全的象限
非重复性思维型工作
包括教师和艺术家，
小说家和律师，医生和科学家
这类工作占美国劳动力大概40％
意味着剩下60％工作容易受自动化影响
有人认为这种规模的技术失业
是前所未有的，会导致灾难性的后果，
大部分人会失业
其他人则认为很好，
让人们从无聊工作解脱，去做更好的工作，
同时享受更高生活水平，有更多食物和物品
都是计算机和机器人生产的.
没人知道未来到底会怎样
但如果历史有指导意义，长远看 一切会归于平静
毕竟，现在没人嚷嚷着让90％的人 回归耕田和纺织
政界在讨论的棘手问题是
怎么处理数百万人突然失业 \N 造成的短期经济混乱
除了工作，计算机很可能会改变我们的身体
举个例子, 未来学家 Ray Kurzweil 认为
"奇点会让我们超越 肉体和大脑的局限性
我们能掌控自己的命运
可以想活多久活多久  我们能完全理解并扩展大脑思维
超人类主义者认为会出现"改造人"
人类和科技融合在一起，增强智力和身体
如今已经有脑电接口了
而 Google Glass 和 微软 Hololens \N 这样的穿戴式计算机 也在模糊这条界线
也有人预见到"数字永生"
Jaron Lanier 的说法是
"人类的肉体死去，意识上传到计算机"
从生物体变成数字体 可能是下一次进化跨越
一层新的抽象
其他人则预测  人类大体会保持原样
但超智能电脑会照顾我们，帮我们管农场
治病，指挥机器人收垃圾，
建房子 以及很多其他事情
让我们在这个可爱蓝点上(地球) 好好享受
另一些人对 AI 持怀疑态度 -
为什么超级人工智能 会费时间照顾我们？
人类不也没照顾蚂蚁吗？
也许会像许多科幻电影一样，和计算机开战
我们无法知道未来到底会怎样
但现在已经有相关讨论了，这非常好
所以等这些技术出现后，我们可以更好地计划
不论你把计算机视为未来的朋友或敌人
更有可能的是，它们的存在时间会超过人类
许多未来学家和科幻作家猜测
机器人会去太空殖民
无视时间，辐射 \N 以及一些其他让人类难以长时间太空旅行的因素.
亿万年后太阳燃尽 地球成为星尘 \N 也许我们的机器人孩子 会继续努力探索宇宙每一个角落
以纪念它们的父母，同时让宇宙变得更好，
大胆探索无人深空
与此同时，计算机还有很长的路要走
计算机科学家们在努力推进  过去40集谈到的话题
在接下来的十几年
VR 和 AR，无人驾驶车，无人机，可穿戴计算机，
和服务型机器人 会变得主流
互联网会继续诞生新服务
在线看新媒体. 用新方式连接人们
会出现新的编程语言和范例，帮助创造令人惊叹的新软件
而新硬件能让复杂运算快如闪电 \N 比如神经网络和3D图形
个人电脑也会创新
不像过去40年着重宣传 "桌面" 电脑
而是变成无处不在的虚拟助手
这个系列 我们还有很多话题没谈
比如加密货币，无线通讯，3D打印，生物信息学和量子计算
我们正处于计算机的黄金时代
有很多事情在发生，全部总结是不可能的
但最重要的是 你可以学习计算机 \N 成为这个惊人转型的一部分
把世界变得更好
感谢收看
